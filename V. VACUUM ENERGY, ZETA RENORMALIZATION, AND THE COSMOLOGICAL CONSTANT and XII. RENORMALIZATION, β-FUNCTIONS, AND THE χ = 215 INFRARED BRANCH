# -*- coding: utf-8 -*-
"""IIM.FinalizingtheCosmologicalConstantSolution

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fnntEgbxCY36KjslClBXQyueoq6nZhPj
"""

!pip install --quiet jax jaxlib

import jax
jax.config.update("jax_enable_x64", True)

import jax.numpy as jnp
import numpy as np
from functools import partial
from tqdm import trange
import matplotlib.pyplot as plt

# ------------------------------------------------------
# Manifold configurations (all χ = 215 from your search)
# ------------------------------------------------------
manifolds = {
    "base_WP1114_d172": {
        "weights": (1,1,1,4),
        "degree": 172,
        "chi": 215
    },
    "idx3_WP1136_d204": {
        "weights": (1,1,3,6),
        "degree": 204,
        "chi": 215
    },
    "idx5_WP1163_d204": {
        "weights": (1,1,6,3),
        "degree": 204,
        "chi": 215
    },
    "idx29_WP1631_d204": {
        "weights": (1,6,3,1),
        "degree": 204,
        "chi": 215
    },
    "idx44_WP2211_d172": {
        "weights": (2,2,1,1),
        "degree": 172,
        "chi": 215
    },
    "idx67_WP3261_d210": {
        "weights": (3,2,6,1),
        "degree": 210,
        "chi": 215
    },
    "idx82_WP6132_d210": {
        "weights": (6,1,3,2),
        "degree": 210,
        "chi": 215
    },
}

MANIFOLD_KEY = "base_WP1114_d172"  # change to test others
cfg = manifolds[MANIFOLD_KEY]

print("Using manifold:", MANIFOLD_KEY)
print("weights =", cfg["weights"], " degree =", cfg["degree"], " chi =", cfg["chi"])

# 2D chart domain
Nx = 96
Ny = 96
L  = 10.0  # chart half-size

xs = jnp.linspace(-L, L, Nx)
ys = jnp.linspace(-L, L, Ny)
dx = xs[1] - xs[0]
dy = ys[1] - ys[0]
X, Y = jnp.meshgrid(xs, ys, indexing='ij')

def conformal_factor(x, y, weights):
    """
    Effective conformal factor Ω(x,y) to mimic curvature.
    This is a model, not the exact WP metric.
    """
    r2 = x**2 + y**2
    wsum = sum(weights)
    p = 1.0 + 0.05 * (wsum - 7)  # base case sum=7 → p=1
    return 1.0 / (1.0 + r2)**p

Omega = conformal_factor(X, Y, cfg["weights"])
chi = cfg["chi"]

# IIM-like potential parameters
m2   = 1.0
lam4 = 1.0
g8   = 0.25
kappa_cross = 0.10   # cross-coupling

def V_fields(phi_vec):
    """
    phi_vec: shape (3, Nx, Ny) → 3 real fields (Φ0, Φ1, Φ2)
    V = Σ (m^2 φ_i^2 - λ φ_i^4 + g φ_i^8)
        + κ (φ0^2 φ1^2 + φ1^2 φ2^2 + φ2^2 φ0^2)
    """
    quad  = m2 * jnp.sum(phi_vec**2, axis=0)
    quart = lam4 * jnp.sum(phi_vec**4, axis=0)
    octic = g8   * jnp.sum(phi_vec**8, axis=0)

    phi0, phi1, phi2 = phi_vec
    cross = kappa_cross * (phi0**2 * phi1**2 + phi1**2 * phi2**2 + phi2**2 * phi0**2)
    return quad - quart + octic + cross

def energy(phi_flat):
    phi = phi_flat.reshape((3, Nx, Ny))
    # central differences
    phi_x = jnp.zeros_like(phi)
    phi_y = jnp.zeros_like(phi)

    phi_x = phi_x.at[:,1:-1,:].set(
        (phi[:,2:,:] - phi[:,:-2,:]) / (2.0*dx)
    )
    phi_y = phi_y.at[:,:,1:-1].set(
        (phi[:,:,2:] - phi[:,:,:-2]) / (2.0*dy)
    )

    kin_density = 0.5 * jnp.sum(phi_x**2 + phi_y**2, axis=0)
    Vdens       = V_fields(phi)
    dens        = Omega * (kin_density + Vdens)
    return jnp.sum(dens) * dx * dy

energy_jit = jax.jit(energy)
gradE_jit  = jax.jit(jax.grad(energy))

def initial_phi():
    """
    Kink in φ0, small structure in φ1, φ2.
    """
    phi0 = jnp.tanh(X / 2.0)
    phi1 = 0.1 * jnp.tanh(Y / 2.0)
    phi2 = 0.05 * jnp.tanh((X + Y)/3.0)
    return jnp.stack([phi0, phi1, phi2], axis=0)

phi_vec = initial_phi()
phi_flat = phi_vec.reshape(-1)

lr = 1e-3
num_steps = 2000
smooth_weight = 0.02
E_hist = []

for step in trange(num_steps):
    g = gradE_jit(phi_flat)
    phi_flat = phi_flat - lr * g

    # smoothing
    phi_vec = phi_flat.reshape((3, Nx, Ny))
    phi_vec = phi_vec.at[:,1:-1,1:-1].set(
        (1 - smooth_weight) * phi_vec[:,1:-1,1:-1] +
        0.5 * smooth_weight * (
            phi_vec[:,2:,1:-1] + phi_vec[:,:-2,1:-1] +
            phi_vec[:,1:-1,2:] + phi_vec[:,1:-1,:-2]
        ) / 2.0
    )
    phi_flat = phi_vec.reshape(-1)

    if step % 50 == 0:
        E_hist.append(float(energy_jit(phi_flat)))

final_E = float(energy_jit(phi_flat))
phi_vec_final = phi_flat.reshape((3, Nx, Ny))

print("Final E =", final_E, "  any NaNs?", np.isnan(np.array(phi_vec_final)).any())

plt.figure(figsize=(6,4))
plt.plot(E_hist)
plt.title("Multifield energy descent")
plt.xlabel("checkpoint (every 50 steps)")
plt.ylabel("E")
plt.grid(True)
plt.show()

phi0_final = np.array(phi_vec_final[0])
plt.figure(figsize=(6,5))
plt.imshow(phi0_final.T, origin='lower', extent=[-L,L,-L,L])
plt.colorbar(label='φ₀(x,y)')
plt.title(f"Field φ₀ on {MANIFOLD_KEY}")
plt.xlabel("x"); plt.ylabel("y")
plt.show()

E_total   = final_E
E1_est    = E_total / chi
S_soliton = chi * E1_est  # = E_total in this patch

print("chi =", chi)
print("Estimated E1 =", E1_est)
print("S_soliton =", S_soliton)

import math

rho_Pl  = 1e76
rho_EW  = 3.7e9
rho_QCD = 1e-3

# Use E1_est from above
S_IIM = chi * E1_est
suppression = math.exp(-S_IIM)

rho_bare = rho_Pl + rho_EW + rho_QCD
rho_eff  = rho_bare * suppression

print("S_IIM = chi * E1 =", S_IIM)
print("Suppression factor exp(-S_IIM) =", suppression)
print("Bare rho_vac (sum) =", rho_bare)
print("Effective rho_Lambda_eff =", rho_eff)
print("Target ~ 1e-47 GeV^4")

# ============================================================
# FULL SELF-CONTAINED 1-LOOP + HEAT-KERNEL CELL (FIXED)
# ============================================================
# Assumes:
#   Nx, Ny, dx, dy
#   phi_vec_final (shape 3 x Nx x Ny)
#   m2, lam4, g8, kappa_cross
#   Omega
#   final_E
# ============================================================

# If MANIFOLD_KEY was not defined earlier, define it:
try:
    MANIFOLD_KEY
except NameError:
    MANIFOLD_KEY = "base_WP1114_d172"   # <-- χ = 215 surface in WP^3(1,1,1,4)

import numpy as np
from scipy.sparse import diags
from scipy.sparse.linalg import eigsh

print("Fluctuation + Heat Kernel analysis on:", MANIFOLD_KEY)
print("Grid:", Nx, "x", Ny, "  dx =", float(dx), "dy =", float(dy))

# ------------------------------
# Unpack fields
# ------------------------------
phi0 = np.array(phi_vec_final[0])
phi1 = np.array(phi_vec_final[1])
phi2 = np.array(phi_vec_final[2])

# ------------------------------
# Mass operator M^2(x,y)
# ------------------------------
def mass2_phi0(phi0, phi1, phi2):
    return (
        2.0*m2
        - 12.0*lam4*phi0**2
        + 56.0*g8*phi0**6
        + 2.0*kappa_cross*(phi1**2 + phi2**2)
    )

M2_sol = mass2_phi0(phi0, phi1, phi2)

phi0_vac = np.ones_like(phi0)
phi1_vac = np.zeros_like(phi1)
phi2_vac = np.zeros_like(phi2)

M2_vac = mass2_phi0(phi0_vac, phi1_vac, phi2_vac)

print("Sample M2_sol center =", float(M2_sol[Nx//2, Ny//2]))
print("Sample M2_vac =", float(M2_vac[0,0]))

# ------------------------------
# 2D Laplacian with Dirichlet BC
# ------------------------------
N = Nx * Ny
dx2 = dx*dx
dy2 = dy*dy

main_diag = -2.0/dx2 - 2.0/dy2
off_x = 1.0/dx2
off_y = 1.0/dy2

diag_main = np.full(N, main_diag)
diag_xp = np.zeros(N)
diag_xm = np.zeros(N)
diag_yp = np.zeros(N)
diag_ym = np.zeros(N)

for ix in range(Nx):
    for iy in range(Ny - 1):
        idx = ix*Ny + iy
        diag_xp[idx] = off_x
        diag_xm[idx+1] = off_x

for ix in range(Nx - 1):
    for iy in range(Ny):
        idx = ix*Ny + iy
        diag_yp[idx] = off_y
        diag_ym[idx+Ny] = off_y

L = diags(
    [diag_main, diag_xp, diag_xm, diag_yp, diag_ym],
    [0, 1, -1, Ny, -Ny],
    shape=(N, N),
    format='csr'
)

# ------------------------------
# Build H_sol and H_vac
# ------------------------------
H_sol = -L + diags(M2_sol.ravel(), 0)
H_vac = -L + diags(M2_vac.ravel(), 0)

# ------------------------------
# Eigenvalues
# ------------------------------
k = 40
print("Computing", k, "eigenvalues...")

eig_sol, _ = eigsh(H_sol, k=k, which='SM')
eig_vac, _ = eigsh(H_vac, k=k, which='SM')

eig_sol = np.sort(eig_sol)
eig_vac = np.sort(eig_vac)

print("\nLowest soliton eigenvalues:", eig_sol[:10])
print("Lowest vacuum eigenvalues:", eig_vac[:10])

neg_sol = np.sum(eig_sol < 0)
neg_vac = np.sum(eig_vac < 0)

print("Negative modes (soliton):", neg_sol)
print("Negative modes (vac):", neg_vac)

# ------------------------------
# Heat-Kernel log(det)
# ------------------------------
def heat_kernel_logdet(evals_sol, evals_vac,
                       t_min=1e-3, t_max=1.0, num_t=200):
    ts = np.logspace(np.log10(t_min), np.log10(t_max), num_t)
    HK_vals = []
    for t in ts:
        HK_vals.append(np.sum(np.exp(-t*evals_sol)) -
                       np.sum(np.exp(-t*evals_vac)))

    HK_vals = np.array(HK_vals)
    log_ts = np.log(ts)
    integral = np.trapz(HK_vals, log_ts)
    return integral

HK_delta_logdet = heat_kernel_logdet(eig_sol, eig_vac)

print("\nHeat-kernel Δ log(det) ≈", HK_delta_logdet)
print("Δ log(det) / S_soliton ≈", HK_delta_logdet / final_E)

# ADVANCED: approximate WP(1,1,1,4) metric machinery (to be refined)

def Kahler_WP1114(z):
    return jnp.log(
        jnp.abs(z[0])**2 +
        jnp.abs(z[1])**2 +
        jnp.abs(z[2])**2 +
        jnp.abs(z[3])**(2/4)
    )

def F_hypersurface(z):
    return z[0]**172 + z[1]**172 + z[2]**172 + z[3]**43

def metric_WP(z):
    def K_re(z_re_im):
        N = len(z_re_im)//2
        zc = z_re_im[:N] + 1j*z_re_im[N:]
        return jnp.real(Kahler_WP1114(zc))

    z_re_im = jnp.concatenate([jnp.real(z), jnp.imag(z)])
    H = jax.hessian(K_re)(z_re_im)

    N = 4
    G = H[:N,:N] + H[N:,N:]
    return G

def metric_on_hypersurface(z):
    G  = metric_WP(z)
    dF = jax.grad(lambda zz: jnp.real(F_hypersurface(zz)))(z)
    denom = jnp.sum(jnp.abs(dF)**2)
    return G - jnp.outer(dF, jnp.conj(dF)) / denom

# Placeholder chart embedding: map (x,y) to some z(x,y) in WP
def chart_embedding(x, y):
    # THIS IS A MODEL, NOT EXACT: to be replaced by a true holomorphic chart.
    z0 = 1.0 + 0.1j*x
    z1 = x + 0.1j*y
    z2 = y + 0.1j*x
    z3 = (1.0 - 0.05*(x**2 + y**2)) + 0.1j
    return jnp.array([z0, z1, z2, z3])

# Example: compute metric at center of patch
z_center = chart_embedding(0.0, 0.0)
G_center = metric_on_hypersurface(z_center)
print("Approx metric at center:\n", G_center)

# ============================================
# A–D: IIM-like soliton + 1-loop on χ = 215
# ============================================

!pip install --quiet jax jaxlib

import jax
jax.config.update("jax_enable_x64", True)

import jax.numpy as jnp
import numpy as np
from tqdm import trange
import matplotlib.pyplot as plt
from scipy.sparse import diags
from scipy.sparse.linalg import eigsh
import math

# ------------------------------------------------------
# A. Manifold configurations (all χ = 215 from your scan)
# ------------------------------------------------------
manifolds = {
    "base_WP1114_d172": {
        "weights": (1,1,1,4),
        "degree": 172,
        "chi": 215
    },
    "idx3_WP1136_d204": {
        "weights": (1,1,3,6),
        "degree": 204,
        "chi": 215
    },
    "idx5_WP1163_d204": {
        "weights": (1,1,6,3),
        "degree": 204,
        "chi": 215
    },
    "idx29_WP1631_d204": {
        "weights": (1,6,3,1),
        "degree": 204,
        "chi": 215
    },
    "idx44_WP2211_d172": {
        "weights": (2,2,1,1),
        "degree": 172,
        "chi": 215
    },
    "idx67_WP3261_d210": {
        "weights": (3,2,6,1),
        "degree": 210,
        "chi": 215
    },
    "idx82_WP6132_d210": {
        "weights": (6,1,3,2),
        "degree": 210,
        "chi": 215
    },
}

# Pick one manifold for A–D
MANIFOLD_KEY = "base_WP1114_d172"   # change to test others
cfg = manifolds[MANIFOLD_KEY]

print("Using manifold:", MANIFOLD_KEY)
print("weights =", cfg["weights"], " degree =", cfg["degree"], " chi =", cfg["chi"])

chi = cfg["chi"]

# ---------------------------
# 2D chart and conformal metric
# ---------------------------
Nx = 96
Ny = 96
L  = 10.0

xs = jnp.linspace(-L, L, Nx)
ys = jnp.linspace(-L, L, Ny)
dx = xs[1] - xs[0]
dy = ys[1] - ys[0]
X, Y = jnp.meshgrid(xs, ys, indexing='ij')

def conformal_factor(x, y, weights, degree):
    """
    Model Ω(x,y) ~ (1 + r^2)^{-p} with p depending on weights & degree.
    This mimics curvature of a WP-hypersurface chart, not an exact metric.
    """
    r2 = x**2 + y**2
    wsum = sum(weights)
    # base p set by weights; small tilt by degree relative to 172
    p = 1.0 + 0.05*(wsum - 7) + 0.001*(degree - 172)
    return 1.0 / (1.0 + r2)**p

Omega = conformal_factor(X, Y, cfg["weights"], cfg["degree"])
Omega = jnp.array(Omega)

# ---------------------------
# B. Approximate 2D Ricci scalar for conformal metric
#     g_ij = Ω δ_ij → R = - Ω^{-1} Δ log Ω
# ---------------------------
def compute_ricci_2d(Omega, dx, dy):
    logO = jnp.log(Omega)

    # central differences for Laplacian
    def laplacian(field):
        # pad edges with nearest interior values
        f = field
        lap = jnp.zeros_like(f)
        lap = lap.at[1:-1,1:-1].set(
            (f[2:,1:-1] - 2*f[1:-1,1:-1] + f[:-2,1:-1]) / (dx*dx) +
            (f[1:-1,2:] - 2*f[1:-1,1:-1] + f[1:-1,:-2]) / (dy*dy)
        )
        # copy boundaries from nearest interior
        lap = lap.at[0,:].set(lap[1,:])
        lap = lap.at[-1,:].set(lap[-2,:])
        lap = lap.at[:,0].set(lap[:,1])
        lap = lap.at[:,-1].set(lap[:,-2])
        return lap

    lap_logO = laplacian(logO)
    R = - lap_logO / Omega
    return R

R_2D = compute_ricci_2d(Omega, dx, dy)

print("Ricci stats: min =", float(jnp.min(R_2D)),
      "max =", float(jnp.max(R_2D)),
      "mean =", float(jnp.mean(R_2D)))

# ---------------------------
# A. IIM-style potential with exponential term
# ---------------------------

# parameters (tunable)
m2   = 0.5
lam4 = 0.5
g6   = 0.1
kappa_cross = 0.05

alpha_exp = 0.3    # exponential slope
Lambda0   = 1.0    # vacuum scale (toy)
xi_curv   = 0.1    # curvature coupling strength

def V_fields(phi_vec, R):
    """
    phi_vec: (3, Nx, Ny)
    R: Ricci scalar grid (Nx, Ny)

    V_total = V_local(φ) + V_exp(φ0) + V_curv(φ,R)

    V_local:
      Σ ( m^2 φ_i^2 + λ φ_i^4 + g φ_i^6 )
      + κ (φ0^2 φ1^2 + φ1^2 φ2^2 + φ2^2 φ0^2)

    V_exp (IIM-like exponential):
      Λ0 * (e^{-α φ0} - 1)^2

    V_curv:
      ξ R Σ φ_i^2
    """
    phi0, phi1, phi2 = phi_vec
    phi_sq  = phi_vec**2
    phi_4   = phi_vec**4
    phi_6   = phi_vec**6

    quad    = m2   * jnp.sum(phi_sq, axis=0)
    quart   = lam4 * jnp.sum(phi_4,  axis=0)
    sextic  = g6   * jnp.sum(phi_6,  axis=0)

    cross = kappa_cross * (phi0**2 * phi1**2 +
                           phi1**2 * phi2**2 +
                           phi2**2 * phi0**2)

    # exponential vacuum channel in φ0
    V_exp = Lambda0 * (jnp.exp(-alpha_exp * phi0) - 1.0)**2

    # curvature coupling
    V_curv = xi_curv * R * jnp.sum(phi_sq, axis=0)

    return quad + quart + sextic + cross + V_exp + V_curv

# ---------------------------
# Energy functional E[φ] on curved patch
# ---------------------------
def energy(phi_flat):
    phi = phi_flat.reshape((3, Nx, Ny))

    # central differences
    phi_x = jnp.zeros_like(phi)
    phi_y = jnp.zeros_like(phi)

    phi_x = phi_x.at[:,1:-1,:].set(
        (phi[:,2:,:] - phi[:,:-2,:]) / (2.0*dx)
    )
    phi_y = phi_y.at[:,:,1:-1].set(
        (phi[:,:,2:] - phi[:,:,:-2]) / (2.0*dy)
    )

    kin_density = 0.5 * jnp.sum(phi_x**2 + phi_y**2, axis=0)
    Vdens       = V_fields(phi, R_2D)
    dens        = Omega * (kin_density + Vdens)
    return jnp.sum(dens) * dx * dy

energy_jit = jax.jit(energy)
gradE_jit  = jax.jit(jax.grad(energy))

# ---------------------------
# Initial field configuration
# ---------------------------
def initial_phi():
    """
    Kink in φ0, small structure in φ1, φ2.
    """
    phi0 = jnp.tanh(X / 2.0)
    phi1 = 0.1 * jnp.tanh(Y / 2.0)
    phi2 = 0.05 * jnp.tanh((X + Y)/3.0)
    return jnp.stack([phi0, phi1, phi2], axis=0)

phi_vec = initial_phi()
phi_flat = phi_vec.reshape(-1)

# ---------------------------
# Gradient flow to find soliton
# ---------------------------
lr = 5e-4
num_steps = 2500
smooth_weight = 0.02
E_hist = []

for step in trange(num_steps):
    g = gradE_jit(phi_flat)
    phi_flat = phi_flat - lr * g

    # smoothing
    phi_vec = phi_flat.reshape((3, Nx, Ny))
    phi_vec = phi_vec.at[:,1:-1,1:-1].set(
        (1 - smooth_weight) * phi_vec[:,1:-1,1:-1] +
        0.25 * smooth_weight * (
            phi_vec[:,2:,1:-1]   + phi_vec[:,:-2,1:-1] +
            phi_vec[:,1:-1,2:]   + phi_vec[:,1:-1,:-2]
        )
    )
    phi_flat = phi_vec.reshape(-1)

    if step % 50 == 0:
        E_hist.append(float(energy_jit(phi_flat)))

final_E = float(energy_jit(phi_flat))
phi_vec_final = phi_flat.reshape((3, Nx, Ny))

print("Final E =", final_E, "  any NaNs?", np.isnan(np.array(phi_vec_final)).any())

plt.figure(figsize=(6,4))
plt.plot(E_hist)
plt.title(f"Energy descent on {MANIFOLD_KEY}")
plt.xlabel("checkpoint (every 50 steps)")
plt.ylabel("E")
plt.grid(True)
plt.show()

phi0_final = np.array(phi_vec_final[0])
plt.figure(figsize=(6,5))
plt.imshow(phi0_final.T, origin='lower', extent=[-L,L,-L,L])
plt.colorbar(label='φ₀(x,y)')
plt.title(f"φ₀(x,y) on {MANIFOLD_KEY}")
plt.xlabel("x"); plt.ylabel("y")
plt.show()

# ---------------------------
# Cosmological constant suppression estimate
# ---------------------------
E_total   = final_E
E1_est    = E_total / chi
S_soliton = chi * E1_est  # = E_total in this patch

print("chi =", chi)
print("Estimated E1 (per χ unit) =", E1_est)
print("S_soliton =", S_soliton)

rho_Pl  = 1e76
rho_EW  = 3.7e9
rho_QCD = 1e-3
rho_bare = rho_Pl + rho_EW + rho_QCD

S_IIM = chi * E1_est
suppression = math.exp(-S_IIM)
rho_eff  = rho_bare * suppression

print("S_IIM = chi * E1 =", S_IIM)
print("Suppression factor exp(-S_IIM) =", suppression)
print("Bare rho_vac (sum) =", rho_bare)
print("Effective rho_Lambda_eff =", rho_eff)
print("Target ~ 1e-47 GeV^4")

# ---------------------------
# D. 1-loop fluctuations: H_sol, H_vac, heat-kernel logdet
# ---------------------------

print("\nFluctuation + Heat Kernel analysis on:", MANIFOLD_KEY)
print("Grid:", Nx, "x", Ny, "  dx =", float(dx), "dy =", float(dy))

phi0 = np.array(phi_vec_final[0])
phi1 = np.array(phi_vec_final[1])
phi2 = np.array(phi_vec_final[2])

def mass2_phi0(phi0, phi1, phi2, R):
    """
    Effective mass^2 for φ0, from V(φ) wrt φ0, second derivative (approx):
    m_eff^2 ≈ 2 m^2 + 12 λ φ0^2 + 30 g φ0^4
              + 2 κ (φ1^2 + φ2^2)
              + 2 ξ R
    (Using indicative coefficients; exact d²V/dφ0² can be coded if desired.)
    """
    return (
        2.0*m2
        + 12.0*lam4*phi0**2
        + 30.0*g6*phi0**4
        + 2.0*kappa_cross*(phi1**2 + phi2**2)
        + 2.0*xi_curv*R
    )

M2_sol = mass2_phi0(phi0, phi1, phi2, np.array(R_2D))

phi0_vac = np.zeros_like(phi0)  # exponential term minimum near φ0 ~ 0
phi1_vac = np.zeros_like(phi1)
phi2_vac = np.zeros_like(phi2)

M2_vac = mass2_phi0(phi0_vac, phi1_vac, phi2_vac, np.array(R_2D))

print("Sample M2_sol center =", float(M2_sol[Nx//2, Ny//2]))
print("Sample M2_vac center =", float(M2_vac[Nx//2, Ny//2]))

# 2D Laplacian
N = Nx * Ny
dx2 = float(dx*dx)
dy2 = float(dy*dy)

main_diag = -2.0/dx2 - 2.0/dy2
off_x = 1.0/dx2
off_y = 1.0/dy2

diag_main = np.full(N, main_diag)
diag_xp = np.zeros(N)
diag_xm = np.zeros(N)
diag_yp = np.zeros(N)
diag_ym = np.zeros(N)

for ix in range(Nx):
    for iy in range(Ny - 1):
        idx = ix*Ny + iy
        diag_xp[idx] = off_x
        diag_xm[idx+1] = off_x

for ix in range(Nx - 1):
    for iy in range(Ny):
        idx = ix*Ny + iy
        diag_yp[idx] = off_y
        diag_ym[idx+Ny] = off_y

L = diags(
    [diag_main, diag_xp, diag_xm, diag_yp, diag_ym],
    [0, 1, -1, Ny, -Ny],
    shape=(N, N),
    format='csr'
)

H_sol = -L + diags(M2_sol.ravel(), 0)
H_vac = -L + diags(M2_vac.ravel(), 0)

k = 40
print("Computing", k, "eigenvalues...")

eig_sol, _ = eigsh(H_sol, k=k, which='SM')
eig_vac, _ = eigsh(H_vac, k=k, which='SM')

eig_sol = np.sort(eig_sol)
eig_vac = np.sort(eig_vac)

print("\nLowest soliton eigenvalues:", eig_sol[:10])
print("Lowest vacuum eigenvalues:", eig_vac[:10])

neg_sol = np.sum(eig_sol < 0)
neg_vac = np.sum(eig_vac < 0)

print("Negative modes (soliton):", neg_sol)
print("Negative modes (vac):", neg_vac)

def heat_kernel_logdet(evals_sol, evals_vac,
                       t_min=1e-3, t_max=1.0, num_t=200):
    ts = np.logspace(np.log10(t_min), np.log10(t_max), num_t)
    HK_vals = []
    for t in ts:
        HK_vals.append(np.sum(np.exp(-t*evals_sol)) -
                       np.sum(np.exp(-t*evals_vac)))
    HK_vals = np.array(HK_vals)
    log_ts = np.log(ts)
    integral = np.trapz(HK_vals, log_ts)
    return integral

HK_delta_logdet = heat_kernel_logdet(eig_sol, eig_vac)

print("\nHeat-kernel Δ log(det) ≈", HK_delta_logdet)
print("Δ log(det) / S_soliton ≈", HK_delta_logdet / final_E)

# ============================================
# E: Scan all 7 χ = 215 manifolds
# ============================================

results = []

for key, cfg in manifolds.items():
    print("\n====================================")
    print("Manifold:", key, "weights =", cfg["weights"],
          "deg =", cfg["degree"], "chi =", cfg["chi"])
    print("====================================")

    # rebuild chart (reuse Nx, Ny, L)
    xs = jnp.linspace(-L, L, Nx)
    ys = jnp.linspace(-L, L, Ny)
    dx = xs[1] - xs[0]
    dy = ys[1] - ys[0]
    X, Y = jnp.meshgrid(xs, ys, indexing='ij')

    Omega = conformal_factor(X, Y, cfg["weights"], cfg["degree"])
    Omega = jnp.array(Omega)
    R_2D = compute_ricci_2d(Omega, dx, dy)

    # new closure for V_fields using this R_2D and Omega
    def energy_for_manifold(phi_flat):
        phi = phi_flat.reshape((3, Nx, Ny))

        phi_x = jnp.zeros_like(phi)
        phi_y = jnp.zeros_like(phi)

        phi_x = phi_x.at[:,1:-1,:].set(
            (phi[:,2:,:] - phi[:,:-2,:]) / (2.0*dx)
        )
        phi_y = phi_y.at[:,:,1:-1].set(
            (phi[:,:,2:] - phi[:,:,:-2]) / (2.0*dy)
        )

        kin_density = 0.5 * jnp.sum(phi_x**2 + phi_y**2, axis=0)
        Vdens       = V_fields(phi, R_2D)
        dens        = Omega * (kin_density + Vdens)
        return jnp.sum(dens) * dx * dy

    energy_m = jax.jit(energy_for_manifold)
    gradE_m  = jax.jit(jax.grad(energy_for_manifold))

    # initial field
    phi_vec0 = initial_phi()
    phi_flat0 = phi_vec0.reshape(-1)

    lr_scan = 5e-4
    steps_scan = 1500
    phi_flat_scan = phi_flat0
    E_hist_scan = []

    for step in trange(steps_scan):
        g = gradE_m(phi_flat_scan)
        phi_flat_scan = phi_flat_scan - lr_scan * g

        phi_scan = phi_flat_scan.reshape((3, Nx, Ny))
        phi_scan = phi_scan.at[:,1:-1,1:-1].set(
            (1 - smooth_weight) * phi_scan[:,1:-1,1:-1] +
            0.25 * smooth_weight * (
                phi_scan[:,2:,1:-1]   + phi_scan[:,:-2,1:-1] +
                phi_scan[:,1:-1,2:]   + phi_scan[:,1:-1,:-2]
            )
        )
        phi_flat_scan = phi_scan.reshape(-1)

        if step % 100 == 0:
            E_hist_scan.append(float(energy_m(phi_flat_scan)))

    final_E_m = float(energy_m(phi_flat_scan))
    chi_m = cfg["chi"]

    E1_m = final_E_m / chi_m
    S_m  = chi_m * E1_m
    S_IIM_m = S_m
    suppression_m = math.exp(-S_IIM_m)

    rho_Pl  = 1e76
    rho_EW  = 3.7e9
    rho_QCD = 1e-3
    rho_bare = rho_Pl + rho_EW + rho_QCD
    rho_eff_m = rho_bare * suppression_m

    print(f"Final E[{key}] =", final_E_m)
    print("E1 =", E1_m, " S =", S_m)
    print("exp(-S) =", suppression_m)
    print("rho_eff ≈", rho_eff_m)

    results.append((key, final_E_m, E1_m, S_m, suppression_m, rho_eff_m))

print("\n=== Summary over 7 manifolds ===")
for (key, Efin, E1, S, sup, rhoeff) in results:
    print(f"{key:20s}  E={Efin:.4f}  E1={E1:.4f}  S={S:.4f}  exp(-S)={sup:.2e}  rho_eff={rhoeff:.2e}")

# ============================================================
# CELL 1 — A–D: Soliton, Energy, 1-loop, Heat Kernel
# ============================================================

import numpy as np
import jax
jax.config.update("jax_enable_x64", True)
import jax.numpy as jnp

from tqdm import trange
from scipy.sparse import diags
from scipy.sparse.linalg import eigsh
import matplotlib.pyplot as plt

# ============================================================
# Manifold config (χ = 215)
# ============================================================
manifolds = {
    "base_WP1114_d172": {"weights": (1,1,1,4), "degree": 172, "chi": 215},
}

MANIFOLD_KEY = "base_WP1114_d172"
cfg = manifolds[MANIFOLD_KEY]

print("\nUsing manifold:", MANIFOLD_KEY)
print("weights =", cfg["weights"], "degree =", cfg["degree"], "chi =", cfg["chi"])

# ============================================================
# 2D conformal geometry model (no WP metric — just curvature proxy)
# ============================================================
Nx = 96
Ny = 96
L  = 10.0

xs = jnp.linspace(-L, L, Nx)
ys = jnp.linspace(-L, L, Ny)
dx = xs[1] - xs[0]
dy = ys[1] - ys[0]

X, Y = jnp.meshgrid(xs, ys, indexing='ij')

def conformal_factor(x, y, weights):
    r2 = x**2 + y**2
    wsum = sum(weights)      # (1+1+1+4)=7 base case
    p = 1.0 + 0.05*(wsum-7)  # p=1 for base manifold
    return 1.0/(1.0+r2)**p

Omega = conformal_factor(X, Y, cfg["weights"])
chi = cfg["chi"]

# ============================================================
# Potential and energy
# ============================================================
m2   = 1.0
lam4 = 1.0
g8   = 0.25
kappa_cross = 0.10

def V_fields(phi):
    phi0, phi1, phi2 = phi
    quad  = m2 * (phi0**2 + phi1**2 + phi2**2)
    quart = lam4 * (phi0**4 + phi1**4 + phi2**4)
    octic = g8   * (phi0**8 + phi1**8 + phi2**8)
    cross = kappa_cross * (phi0**2*phi1**2 + phi1**2*phi2**2 + phi2**2*phi0**2)
    return quad - quart + octic + cross

def energy(phi_flat):
    phi = phi_flat.reshape((3, Nx, Ny))

    # central differences
    dphi_x = jnp.zeros_like(phi)
    dphi_y = jnp.zeros_like(phi)

    dphi_x = dphi_x.at[:,1:-1,:].set((phi[:,2:,:]-phi[:,:-2,:])/(2*dx))
    dphi_y = dphi_y.at[:,:,1:-1].set((phi[:,:,2:]-phi[:,:,:-2])/(2*dy))

    kin = 0.5*jnp.sum(dphi_x**2 + dphi_y**2, axis=0)
    pot = V_fields(phi)

    dens = Omega * (kin + pot)
    return jnp.sum(dens)*dx*dy

energy_jit = jax.jit(energy)
gradE_jit  = jax.jit(jax.grad(energy))

# ============================================================
# Initial field
# ============================================================
phi0 = jnp.tanh(X/2)
phi1 = 0.1*jnp.tanh(Y/2)
phi2 = 0.05*jnp.tanh((X+Y)/3)
phi_flat = jnp.stack([phi0,phi1,phi2]).reshape(-1)

# ============================================================
# Gradient descent
# ============================================================
lr = 1e-3
smooth = 0.02
E_hist = []

for step in trange(2500):
    g = gradE_jit(phi_flat)
    phi_flat = phi_flat - lr*g

    # smoothing
    phi = phi_flat.reshape((3,Nx,Ny))
    phi = phi.at[:,1:-1,1:-1].set(
        (1-smooth)*phi[:,1:-1,1:-1] +
        0.5*smooth*(phi[:,2:,1:-1]+phi[:,:-2,1:-1]+phi[:,1:-1,2:]+phi[:,1:-1,:-2])/2
    )
    phi_flat = phi.reshape(-1)

    if step%50==0:
        E_hist.append(float(energy_jit(phi_flat)))

final_E = float(energy_jit(phi_flat))
phi_vec_final = np.array(phi_flat.reshape((3, Nx, Ny)))

print("\nFinal E =", final_E)

plt.figure(figsize=(6,4))
plt.plot(E_hist)
plt.title(f"Energy descent on {MANIFOLD_KEY}")
plt.xlabel("checkpoint (50 steps)")
plt.ylabel("E")
plt.grid()
plt.show()

# ============================================================
# 1-loop: build fluctuation operators
# ============================================================
phi0 = phi_vec_final[0]
phi1 = phi_vec_final[1]
phi2 = phi_vec_final[2]

def mass2_phi0(a,b,c):
    return 2*m2 - 12*lam4*a**2 + 56*g8*a**6 + 2*kappa_cross*(b**2+c**2)

M2_sol = mass2_phi0(phi0,phi1,phi2)
M2_vac = mass2_phi0(np.ones_like(phi0),0,0)

N = Nx*Ny
dx2 = float(dx*dx)
dy2 = float(dy*dy)

main = -2/dx2 - 2/dy2
ox = 1/dx2
oy = 1/dy2

d0 = np.full(N, main)
dxp = np.zeros(N)
dxm = np.zeros(N)
dyp = np.zeros(N)
dym = np.zeros(N)

for ix in range(Nx):
    for iy in range(Ny-1):
        idx = ix*Ny+iy
        dxp[idx] = ox
        dxm[idx+1] = ox

for ix in range(Nx-1):
    for iy in range(Ny):
        idx = ix*Ny+iy
        dyp[idx] = oy
        dym[idx+Ny] = oy

L = diags([d0,dxp,dxm,dyp,dym],[0,1,-1,Ny,-Ny],shape=(N,N))

H_sol = -L + diags(M2_sol.ravel(),0)
H_vac = -L + diags(M2_vac.ravel(),0)

eig_sol,_ = eigsh(H_sol,k=40,which='SM')
eig_vac,_ = eigsh(H_vac,k=40,which='SM')

eig_sol = np.sort(eig_sol)
eig_vac = np.sort(eig_vac)

print("\nLowest soliton evals:", eig_sol[:8])
print("Lowest vacuum evals:",  eig_vac[:8])

def heat_kernel_logdet(ev_sol, ev_vac):
    ts = np.logspace(-3,0,200)
    diff = [np.sum(np.exp(-t*ev_sol))-np.sum(np.exp(-t*ev_vac)) for t in ts]
    return np.trapezoid(diff, x=np.log(ts))

HK = heat_kernel_logdet(eig_sol,eig_vac)

print("\nHeat-kernel Δ log(det) =", HK)
print("Δ / S_soliton =", HK/final_E)

# ============================================================
# CELL 2 — E (Geometry-only; NumPy-safe)
# ============================================================

import numpy as np

print("\n====================================")
print("Manifold:", MANIFOLD_KEY, "weights =", cfg["weights"],
      "deg =", cfg["degree"], "chi =", cfg["chi"])
print("====================================")

# A completely JAX-free placeholder WP(1,1,1,4) metric model
def Kahler_model(z):
    """Simple positive-definite Kähler-ish model — NO complex Hessians."""
    r = np.sum(np.abs(z)**2)
    return np.log(1 + r)

def chart_embedding_np(x,y):
    return np.array([
        1 + 0.1*x,
        x + 0.1*y,
        y + 0.1*x,
        1 - 0.05*(x*x+y*y)
    ])

# Compute numerical Hessian
def numerical_hessian(f, z, eps=1e-4):
    n = len(z)
    H = np.zeros((n,n))
    for i in range(n):
        for j in range(n):
            dz_i = np.zeros(n); dz_j = np.zeros(n)
            dz_i[i] = eps; dz_j[j] = eps
            H[i,j] = (
                f(z+dz_i+dz_j) - f(z+dz_i-dz_j)
                - f(z-dz_i+dz_j) + f(z-dz_i-dz_j)
            )/(4*eps*eps)
    return H

z0 = chart_embedding_np(0,0)
G0 = numerical_hessian(Kahler_model, z0)

print("\nApproximate metric at patch center:")
print(G0)

# ============================================
# A–D: IIM-like soliton + 1-loop on χ = 215
# ============================================

!pip install --quiet jax jaxlib

import jax
jax.config.update("jax_enable_x64", True)

import jax.numpy as jnp
import numpy as np
from tqdm import trange
import matplotlib.pyplot as plt
from scipy.sparse import diags
from scipy.sparse.linalg import eigsh
import math

# ------------------------------------------------------
# A. Manifold configurations (all χ = 215 from your scan)
# ------------------------------------------------------
manifolds = {
    "base_WP1114_d172": {
        "weights": (1,1,1,4),
        "degree": 172,
        "chi": 215
    },
    "idx3_WP1136_d204": {
        "weights": (1,1,3,6),
        "degree": 204,
        "chi": 215
    },
    "idx5_WP1163_d204": {
        "weights": (1,1,6,3),
        "degree": 204,
        "chi": 215
    },
    "idx29_WP1631_d204": {
        "weights": (1,6,3,1),
        "degree": 204,
        "chi": 215
    },
    "idx44_WP2211_d172": {
        "weights": (2,2,1,1),
        "degree": 172,
        "chi": 215
    },
    "idx67_WP3261_d210": {
        "weights": (3,2,6,1),
        "degree": 210,
        "chi": 215
    },
    "idx82_WP6132_d210": {
        "weights": (6,1,3,2),
        "degree": 210,
        "chi": 215
    },
}

# Pick one manifold for A–D
MANIFOLD_KEY = "base_WP1114_d172"   # change to test others
cfg = manifolds[MANIFOLD_KEY]

print("Using manifold:", MANIFOLD_KEY)
print("weights =", cfg["weights"], " degree =", cfg["degree"], " chi =", cfg["chi"])

chi = cfg["chi"]

# ---------------------------
# 2D chart and conformal metric
# ---------------------------
Nx = 96
Ny = 96
L  = 10.0

xs = jnp.linspace(-L, L, Nx)
ys = jnp.linspace(-L, L, Ny)
dx = xs[1] - xs[0]
dy = ys[1] - ys[0]
X, Y = jnp.meshgrid(xs, ys, indexing='ij')

def conformal_factor(x, y, weights, degree):
    """
    Model Ω(x,y) ~ (1 + r^2)^{-p} with p depending on weights & degree.
    This mimics curvature of a WP-hypersurface chart, not an exact metric.
    """
    r2 = x**2 + y**2
    wsum = sum(weights)
    # base p set by weights; small tilt by degree relative to 172
    p = 1.0 + 0.05*(wsum - 7) + 0.001*(degree - 172)
    return 1.0 / (1.0 + r2)**p

Omega = conformal_factor(X, Y, cfg["weights"], cfg["degree"])
Omega = jnp.array(Omega)

# ---------------------------
# B. Approximate 2D Ricci scalar for conformal metric
#     g_ij = Ω δ_ij → R = - Ω^{-1} Δ log Ω
# ---------------------------
def compute_ricci_2d(Omega, dx, dy):
    logO = jnp.log(Omega)

    # central differences for Laplacian
    def laplacian(field):
        # pad edges with nearest interior values
        f = field
        lap = jnp.zeros_like(f)
        lap = lap.at[1:-1,1:-1].set(
            (f[2:,1:-1] - 2*f[1:-1,1:-1] + f[:-2,1:-1]) / (dx*dx) +
            (f[1:-1,2:] - 2*f[1:-1,1:-1] + f[1:-1,:-2]) / (dy*dy)
        )
        # copy boundaries from nearest interior
        lap = lap.at[0,:].set(lap[1,:])
        lap = lap.at[-1,:].set(lap[-2,:])
        lap = lap.at[:,0].set(lap[:,1])
        lap = lap.at[:,-1].set(lap[:,-2])
        return lap

    lap_logO = laplacian(logO)
    R = - lap_logO / Omega
    return R

R_2D = compute_ricci_2d(Omega, dx, dy)

print("Ricci stats: min =", float(jnp.min(R_2D)),
      "max =", float(jnp.max(R_2D)),
      "mean =", float(jnp.mean(R_2D)))

# ---------------------------
# A. IIM-style potential with exponential term
# ---------------------------

# parameters (tunable)
m2   = 0.5
lam4 = 0.5
g6   = 0.1
kappa_cross = 0.05

alpha_exp = 0.3    # exponential slope
Lambda0   = 1.0    # vacuum scale (toy)
xi_curv   = 0.1    # curvature coupling strength

def V_fields(phi_vec, R):
    """
    phi_vec: (3, Nx, Ny)
    R: Ricci scalar grid (Nx, Ny)

    V_total = V_local(φ) + V_exp(φ0) + V_curv(φ,R)

    V_local:
      Σ ( m^2 φ_i^2 + λ φ_i^4 + g φ_i^6 )
      + κ (φ0^2 φ1^2 + φ1^2 φ2^2 + φ2^2 φ0^2)

    V_exp (IIM-like exponential):
      Λ0 * (e^{-α φ0} - 1)^2

    V_curv:
      ξ R Σ φ_i^2
    """
    phi0, phi1, phi2 = phi_vec
    phi_sq  = phi_vec**2
    phi_4   = phi_vec**4
    phi_6   = phi_vec**6

    quad    = m2   * jnp.sum(phi_sq, axis=0)
    quart   = lam4 * jnp.sum(phi_4,  axis=0)
    sextic  = g6   * jnp.sum(phi_6,  axis=0)

    cross = kappa_cross * (phi0**2 * phi1**2 +
                           phi1**2 * phi2**2 +
                           phi2**2 * phi0**2)

    # exponential vacuum channel in φ0
    V_exp = Lambda0 * (jnp.exp(-alpha_exp * phi0) - 1.0)**2

    # curvature coupling
    V_curv = xi_curv * R * jnp.sum(phi_sq, axis=0)

    return quad + quart + sextic + cross + V_exp + V_curv

# ---------------------------
# Energy functional E[φ] on curved patch
# ---------------------------
def energy(phi_flat):
    phi = phi_flat.reshape((3, Nx, Ny))

    # central differences
    phi_x = jnp.zeros_like(phi)
    phi_y = jnp.zeros_like(phi)

    phi_x = phi_x.at[:,1:-1,:].set(
        (phi[:,2:,:] - phi[:,:-2,:]) / (2.0*dx)
    )
    phi_y = phi_y.at[:,:,1:-1].set(
        (phi[:,:,2:] - phi[:,:,:-2]) / (2.0*dy)
    )

    kin_density = 0.5 * jnp.sum(phi_x**2 + phi_y**2, axis=0)
    Vdens       = V_fields(phi, R_2D)
    dens        = Omega * (kin_density + Vdens)
    return jnp.sum(dens) * dx * dy

energy_jit = jax.jit(energy)
gradE_jit  = jax.jit(jax.grad(energy))

# ---------------------------
# Initial field configuration
# ---------------------------
def initial_phi():
    """
    Kink in φ0, small structure in φ1, φ2.
    """
    phi0 = jnp.tanh(X / 2.0)
    phi1 = 0.1 * jnp.tanh(Y / 2.0)
    phi2 = 0.05 * jnp.tanh((X + Y)/3.0)
    return jnp.stack([phi0, phi1, phi2], axis=0)

phi_vec = initial_phi()
phi_flat = phi_vec.reshape(-1)

# ---------------------------
# Gradient flow to find soliton
# ---------------------------
lr = 5e-4
num_steps = 2500
smooth_weight = 0.02
E_hist = []

for step in trange(num_steps):
    g = gradE_jit(phi_flat)
    phi_flat = phi_flat - lr * g

    # smoothing
    phi_vec = phi_flat.reshape((3, Nx, Ny))
    phi_vec = phi_vec.at[:,1:-1,1:-1].set(
        (1 - smooth_weight) * phi_vec[:,1:-1,1:-1] +
        0.25 * smooth_weight * (
            phi_vec[:,2:,1:-1]   + phi_vec[:,:-2,1:-1] +
            phi_vec[:,1:-1,2:]   + phi_vec[:,1:-1,:-2]
        )
    )
    phi_flat = phi_vec.reshape(-1)

    if step % 50 == 0:
        E_hist.append(float(energy_jit(phi_flat)))

final_E = float(energy_jit(phi_flat))
phi_vec_final = phi_flat.reshape((3, Nx, Ny))

print("Final E =", final_E, "  any NaNs?", np.isnan(np.array(phi_vec_final)).any())

plt.figure(figsize=(6,4))
plt.plot(E_hist)
plt.title(f"Energy descent on {MANIFOLD_KEY}")
plt.xlabel("checkpoint (every 50 steps)")
plt.ylabel("E")
plt.grid(True)
plt.show()

phi0_final = np.array(phi_vec_final[0])
plt.figure(figsize=(6,5))
plt.imshow(phi0_final.T, origin='lower', extent=[-L,L,-L,L])
plt.colorbar(label='φ₀(x,y)')
plt.title(f"φ₀(x,y) on {MANIFOLD_KEY}")
plt.xlabel("x"); plt.ylabel("y")
plt.show()

# ---------------------------
# Cosmological constant suppression estimate
# ---------------------------
E_total   = final_E
E1_est    = E_total / chi
S_soliton = chi * E1_est  # = E_total in this patch

print("chi =", chi)
print("Estimated E1 (per χ unit) =", E1_est)
print("S_soliton =", S_soliton)

rho_Pl  = 1e76
rho_EW  = 3.7e9
rho_QCD = 1e-3
rho_bare = rho_Pl + rho_EW + rho_QCD

S_IIM = chi * E1_est
suppression = math.exp(-S_IIM)
rho_eff  = rho_bare * suppression

print("S_IIM = chi * E1 =", S_IIM)
print("Suppression factor exp(-S_IIM) =", suppression)
print("Bare rho_vac (sum) =", rho_bare)
print("Effective rho_Lambda_eff =", rho_eff)
print("Target ~ 1e-47 GeV^4")

# ---------------------------
# D. 1-loop fluctuations: H_sol, H_vac, heat-kernel logdet
# ---------------------------

print("\nFluctuation + Heat Kernel analysis on:", MANIFOLD_KEY)
print("Grid:", Nx, "x", Ny, "  dx =", float(dx), "dy =", float(dy))

phi0 = np.array(phi_vec_final[0])
phi1 = np.array(phi_vec_final[1])
phi2 = np.array(phi_vec_final[2])

def mass2_phi0(phi0, phi1, phi2, R):
    """
    Effective mass^2 for φ0, from V(φ) wrt φ0, second derivative (approx):
    m_eff^2 ≈ 2 m^2 + 12 λ φ0^2 + 30 g φ0^4
              + 2 κ (φ1^2 + φ2^2)
              + 2 ξ R
    """
    return (
        2.0*m2
        + 12.0*lam4*phi0**2
        + 30.0*g6*phi0**4
        + 2.0*kappa_cross*(phi1**2 + phi2**2)
        + 2.0*xi_curv*R
    )

M2_sol = mass2_phi0(phi0, phi1, phi2, np.array(R_2D))

phi0_vac = np.zeros_like(phi0)
phi1_vac = np.zeros_like(phi1)
phi2_vac = np.zeros_like(phi2)

M2_vac = mass2_phi0(phi0_vac, phi1_vac, phi2_vac, np.array(R_2D))

print("Sample M2_sol center =", float(M2_sol[Nx//2, Ny//2]))
print("Sample M2_vac center =", float(M2_vac[Nx//2, Ny//2]))

# 2D Laplacian
N = Nx * Ny
dx2 = float(dx*dx)
dy2 = float(dy*dy)

main_diag = -2.0/dx2 - 2.0/dy2
off_x = 1.0/dx2
off_y = 1.0/dy2

diag_main = np.full(N, main_diag)
diag_xp = np.zeros(N)
diag_xm = np.zeros(N)
diag_yp = np.zeros(N)
diag_ym = np.zeros(N)

for ix in range(Nx):
    for iy in range(Ny - 1):
        idx = ix*Ny + iy
        diag_xp[idx] = off_x
        diag_xm[idx+1] = off_x

for ix in range(Nx - 1):
    for iy in range(Ny):
        idx = ix*Ny + iy
        diag_yp[idx] = off_y
        diag_ym[idx+Ny] = off_y

L_op = diags(
    [diag_main, diag_xp, diag_xm, diag_yp, diag_ym],
    [0, 1, -1, Ny, -Ny],
    shape=(N, N),
    format='csr'
)

H_sol = -L_op + diags(M2_sol.ravel(), 0)
H_vac = -L_op + diags(M2_vac.ravel(), 0)

k = 40
print("Computing", k, "eigenvalues...")

eig_sol, _ = eigsh(H_sol, k=k, which='SM')
eig_vac, _ = eigsh(H_vac, k=k, which='SM')

eig_sol = np.sort(eig_sol)
eig_vac = np.sort(eig_vac)

print("\nLowest soliton eigenvalues:", eig_sol[:10])
print("Lowest vacuum eigenvalues:", eig_vac[:10])

neg_sol = np.sum(eig_sol < 0)
neg_vac = np.sum(eig_vac < 0)

print("Negative modes (soliton):", neg_sol)
print("Negative modes (vac):", neg_vac)

def heat_kernel_logdet(evals_sol, evals_vac,
                       t_min=1e-3, t_max=1.0, num_t=200):
    ts = np.logspace(np.log10(t_min), np.log10(t_max), num_t)
    HK_vals = []
    for t in ts:
        HK_vals.append(np.sum(np.exp(-t*evals_sol)) -
                       np.sum(np.exp(-t*evals_vac)))
    HK_vals = np.array(HK_vals)
    log_ts = np.log(ts)
    integral = np.trapz(HK_vals, log_ts)
    return integral

HK_delta_logdet = heat_kernel_logdet(eig_sol, eig_vac)

print("\nHeat-kernel Δ log(det) ≈", HK_delta_logdet)
print("Δ log(det) / S_soliton ≈", HK_delta_logdet / final_E)

# ============================================
# E: Scan all 7 χ = 215 manifolds
# ============================================

results = []

for key, cfg in manifolds.items():
    print("\n====================================")
    print("Manifold:", key, "weights =", cfg["weights"],
          "deg =", cfg["degree"], "chi =", cfg["chi"])
    print("====================================")

    # rebuild chart (reuse Nx, Ny, L)
    xs = jnp.linspace(-L, L, Nx)
    ys = jnp.linspace(-L, L, Ny)
    dx = xs[1] - xs[0]
    dy = ys[1] - ys[0]
    X, Y = jnp.meshgrid(xs, ys, indexing='ij')

    Omega = conformal_factor(X, Y, cfg["weights"], cfg["degree"])
    Omega = jnp.array(Omega)
    R_2D = compute_ricci_2d(Omega, dx, dy)

    # new closure for V_fields using this R_2D and Omega
    def energy_for_manifold(phi_flat):
        phi = phi_flat.reshape((3, Nx, Ny))

        phi_x = jnp.zeros_like(phi)
        phi_y = jnp.zeros_like(phi)

        phi_x = phi_x.at[:,1:-1,:].set(
            (phi[:,2:,:] - phi[:,:-2,:]) / (2.0*dx)
        )
        phi_y = phi_y.at[:,:,1:-1].set(
            (phi[:,:,2:] - phi[:,:,:-2]) / (2.0*dy)
        )

        kin_density = 0.5 * jnp.sum(phi_x**2 + phi_y**2, axis=0)
        Vdens       = V_fields(phi, R_2D)
        dens        = Omega * (kin_density + Vdens)
        return jnp.sum(dens) * dx * dy

    energy_m = jax.jit(energy_for_manifold)
    gradE_m  = jax.jit(jax.grad(energy_for_manifold))

    # initial field
    phi_vec0 = initial_phi()
    phi_flat0 = phi_vec0.reshape(-1)

    lr_scan = 5e-4
    steps_scan = 1500
    phi_flat_scan = phi_flat0
    E_hist_scan = []

    for step in trange(steps_scan):
        g = gradE_m(phi_flat_scan)
        phi_flat_scan = phi_flat_scan - lr_scan * g

        phi_scan = phi_flat_scan.reshape((3, Nx, Ny))
        phi_scan = phi_scan.at[:,1:-1,1:-1].set(
            (1 - smooth_weight) * phi_scan[:,1:-1,1:-1] +
            0.25 * smooth_weight * (
                phi_scan[:,2:,1:-1]   + phi_scan[:,:-2,1:-1] +
                phi_scan[:,1:-1,2:]   + phi_scan[:,1:-1,:-2]
            )
        )
        phi_flat_scan = phi_scan.reshape(-1)

        if step % 100 == 0:
            E_hist_scan.append(float(energy_m(phi_flat_scan)))

    final_E_m = float(energy_m(phi_flat_scan))
    chi_m = cfg["chi"]

    E1_m = final_E_m / chi_m
    S_m  = chi_m * E1_m
    S_IIM_m = S_m
    suppression_m = math.exp(-S_IIM_m)

    rho_Pl  = 1e76
    rho_EW  = 3.7e9
    rho_QCD = 1e-3
    rho_bare = rho_Pl + rho_EW + rho_QCD
    rho_eff_m = rho_bare * suppression_m

    print(f"Final E[{key}] =", final_E_m)
    print("E1 =", E1_m, " S =", S_m)
    print("exp(-S) =", suppression_m)
    print("rho_eff ≈", rho_eff_m)

    results.append((key, final_E_m, E1_m, S_m, suppression_m, rho_eff_m))

print("\n=== Summary over 7 manifolds ===")
for (key, Efin, E1, S, sup, rhoeff) in results:
    print(f"{key:20s}  E={Efin:.4f}  E1={E1:.4f}  S={S:.4f}  exp(-S)={sup:.2e}  rho_eff={rhoeff:.2e}")

# ============================================
# CELL 3: STABILIZATION VIA TUNED PARAMETERS
# ============================================

# Import variables from previous cells
SCALE_FACTOR = 35.7  # From Cell 1b

# EW-scale parameters (from rescaling)
m2_EW = 0.5 * SCALE_FACTOR
lam4_EW = 0.5 * SCALE_FACTOR
g6_EW = 0.1 * SCALE_FACTOR
Lambda0_EW = 1.0 * SCALE_FACTOR
alpha_exp = 0.3

# Grid and geometry (from Cell 1)
Nx = 96
Ny = 96
L = 10.0
chi = 215

xs = jnp.linspace(-L, L, Nx)
ys = jnp.linspace(-L, L, Ny)
dx = xs[1] - xs[0]
dy = ys[1] - ys[0]
X, Y = jnp.meshgrid(xs, ys, indexing='ij')

# Manifold config
cfg = {
    "weights": (1,1,1,4),
    "degree": 172,
    "chi": 215
}

# Rebuild geometry
def conformal_factor(x, y, weights, degree):
    r2 = x**2 + y**2
    wsum = sum(weights)
    p = 1.0 + 0.05*(wsum - 7) + 0.001*(degree - 172)
    return 1.0 / (1.0 + r2)**p

Omega = conformal_factor(X, Y, cfg["weights"], cfg["degree"])
Omega = jnp.array(Omega)

def compute_ricci_2d(Omega, dx, dy):
    logO = jnp.log(Omega)
    def laplacian(field):
        f = field
        lap = jnp.zeros_like(f)
        lap = lap.at[1:-1,1:-1].set(
            (f[2:,1:-1] - 2*f[1:-1,1:-1] + f[:-2,1:-1]) / (dx*dx) +
            (f[1:-1,2:] - 2*f[1:-1,1:-1] + f[1:-1,:-2]) / (dy*dy)
        )
        lap = lap.at[0,:].set(lap[1,:])
        lap = lap.at[-1,:].set(lap[-2,:])
        lap = lap.at[:,0].set(lap[:,1])
        lap = lap.at[:,-1].set(lap[:,-2])
        return lap
    lap_logO = laplacian(logO)
    R = - lap_logO / Omega
    return R

R_2D = compute_ricci_2d(Omega, dx, dy)

def initial_phi():
    phi0 = jnp.tanh(X / 2.0)
    phi1 = 0.1 * jnp.tanh(Y / 2.0)
    phi2 = 0.05 * jnp.tanh((X + Y)/3.0)
    return jnp.stack([phi0, phi1, phi2], axis=0)

smooth_weight = 0.02

# Laplacian operator (from Cell 1 fluctuation section)
N = Nx * Ny
dx2 = float(dx*dx)
dy2 = float(dy*dy)
main_diag = -2.0/dx2 - 2.0/dy2
off_x = 1.0/dx2
off_y = 1.0/dy2

diag_main = np.full(N, main_diag)
diag_xp = np.zeros(N)
diag_xm = np.zeros(N)
diag_yp = np.zeros(N)
diag_ym = np.zeros(N)

for ix in range(Nx):
    for iy in range(Ny - 1):
        idx = ix*Ny + iy
        diag_xp[idx] = off_x
        diag_xm[idx+1] = off_x

for ix in range(Nx - 1):
    for iy in range(Ny):
        idx = ix*Ny + iy
        diag_yp[idx] = off_y
        diag_ym[idx+Ny] = off_y

L_op = diags(
    [diag_main, diag_xp, diag_xm, diag_yp, diag_ym],
    [0, 1, -1, Ny, -Ny],
    shape=(N, N),
    format='csr'
)

print("="*70)
print("FIXING INSTABILITY: Tuning κ and ξ to eliminate negative modes")
print("="*70)

# Strategy: Scan over (kappa_cross, xi_curv) parameter space
# Find combination that gives all-positive eigenspectrum

import itertools

kappa_values = [0.0, 0.01, 0.02, 0.05, 0.1]
xi_values = [0.05, 0.1, 0.2, 0.5, 1.0]

stable_configs = []

for kappa_test, xi_test in itertools.product(kappa_values, xi_values):
    print(f"\nTesting: κ = {kappa_test:.3f}, ξ = {xi_test:.3f}")

    # Rebuild potential with test parameters
    kappa_cross_test = kappa_test * SCALE_FACTOR
    xi_curv_test = xi_test

    # ... rest of Cell 3 code continues ...

###############################################
#   IIM ON χ=215 WEIGHTED PROJECTIVE SURFACE
#   Exact Kähler Geometry + SUSY Operators
#   Full Mathematical Appendix (Symbolic)
#
#   Author: ChatGPT (Mathematical Mode)
# #############################################

import sympy as sp

############################################################
# 0. Coordinates on WP^3(1,1,1,4)
############################################################

# Local affine patch z0 != 0  →  u1=z1/z0, u2=z2/z0, u3=z3/z0^4
u1, u2, u3 = sp.symbols('u1 u2 u3', complex=True)
u1b, u2b, u3b = sp.symbols('u1b u2b u3b', complex=True)  # conjugates

# We treat conjugates as algebraically independent for complex derivatives
coords = (u1, u2, u3)
coords_bar = (u1b, u2b, u3b)

############################################################
# 1. Weighted Fubini–Study Kähler potential on WP^3(1,1,1,4)
############################################################

# Exact weighted FS Kähler potential:
#   K = log( |z0|^2 + |z1|^2 + |z2|^2 + |z3|^(2/4) )
# On patch z0=1 → z1 = u1, z2 = u2, z3 = u3
# Note exponent = 1/2 for weight 4

K = sp.log(1 + u1*u1b + u2*u2b + (u3*u3b)**sp.Rational(1,4))

print("\n=== Weighted Fubini–Study Kähler Potential K(u,ubar) ===")
sp.pprint(K)

############################################################
# 2. Compute exact ambient-space Kähler metric g_{i\bar{j}}
############################################################

g = sp.Matrix(3,3, lambda i,j: sp.diff(sp.diff(K, coords[i]), coords_bar[j]))

print("\n=== Ambient WP^3(1,1,1,4) Kähler metric g_{i\\bar j} ===")
sp.pprint(g)

############################################################
# 3. Hypersurface χ=215: F = 0, pullback metric
############################################################

# Defining polynomial for the hypersurface:
# WP^3(1,1,1,4), degree = 172 → quasi-homogeneous
# In affine patch: F(u1,u2,u3) = 1 + u1^172 + u2^172 + u3^43
F = 1 + u1**172 + u2**172 + u3**43

print("\n=== Hypersurface equation F = 0 ===")
sp.pprint(F)

# Compute ∂F/∂u_i
dF = sp.Matrix([sp.diff(F, var) for var in coords])

print("\n=== Gradient dF on ambient WP patch ===")
sp.pprint(dF)

# Pullback metric via:
#   g_ind = g - (1/|dF|^2) (dF ⊗ dF†)
# This projects out the normal direction to the hypersurface.

norm_dF_sq = sum([dF[i]*sp.conjugate(dF[i]) for i in range(3)])

g_ind = g - (1/norm_dF_sq) * (dF * dF.H)

print("\n=== Induced metric g_ind on hypersurface M (χ=215) ===")
sp.pprint(g_ind)

############################################################
# 4. Instanton Euler–Lagrange equations on M
############################################################

# Scalar fields φ take values in M. Their action:
#   S = ∫ sqrt(det g_ind) [ g_ind^{i\bar{j}} ∂μφ^i ∂μφ^bar_j + V(φ) ] d^4x
#
# Euler–Lagrange:
#   g_ind^{i\bar j} ∇_μ ∂^μ φ^i - ∂V/∂φ^i = 0

# Compute inverse metric symbolically
g_ind_inv = sp.simplify(g_ind.inv())

print("\n=== Inverse induced metric g_ind^{-1} ===")
sp.pprint(g_ind_inv)

# Generic potential V(φ) (symbolic)
V = sp.Function("V")(u1,u2,u3,u1b,u2b,u3b)

# Symbolic gradient of the potential
gradV = sp.Matrix([sp.diff(V, var) for var in coords])

print("\n=== ∂V/∂φ^i (symbolic) ===")
sp.pprint(gradV)

print("\n=== Euler–Lagrange equations on M ===")
print("g_ind^{i\\bar j} ∇_μ ∂^μ φ^i - ∂V/∂φ^i = 0   (symbolic form)")

############################################################
# 5. Fermionic fluctuation operator (Dirac operator)
############################################################

# SUSY fermions ψ^i couple via Dirac operator:
#   D_F ψ = γ^μ ( ∂_μ ψ + ω_μ ψ + Γ^i_{jk} ∂_μ φ^j ψ^k )
#
# Here we compute Γ^i_{jk} from g_ind.

# Compute Christoffel symbols on M:
Gamma = [[[ None for k in range(3)] for j in range(3)] for i in range(3)]

for i in range(3):
    for j in range(3):
        for k in range(3):
            # Γ^i_{jk} = g_ind^{i\bar m} ∂_j g_ind_{k \bar m}
            Gamma[i][j][k] = sp.simplify(
                sum([
                    g_ind_inv[i,m] * sp.diff(g_ind[k,m], coords[j])
                    for m in range(3)
                ])
            )

print("\n=== Christoffel symbols Γ^i_{jk} on M ===")
for i in range(3):
    for j in range(3):
        for k in range(3):
            print(f"Gamma[{i}][{j}][{k}] = {Gamma[i][j][k]}")

print("\n=== Fermionic Dirac operator structure ===")
print("D_F ψ = γ^μ ( ∂_μ ψ^i + Γ^i_{jk} ∂_μ φ^j ψ^k )")

############################################################
# 6. SUSY determinant structure
############################################################

print("\n=== SUSY determinant ratio structure ===")
print(r"""
For bosons:
    H_B = -Δ + (∂^2 V / ∂φ ∂φ†)

For fermions:
    H_F = D_F† D_F

SUSY cancellation:
    log det(H_B) - 2 log det(H_F)  (up to zero-mode structure)

""")

############################################################
# 7. Classical stability conditions
############################################################

print("\n=== Stability conditions ===")
print(r"""
1. Positive definiteness of mass matrix:
     M^2_{i\bar j} = ∂^2 V / ∂φ^i ∂φ^{\bar j}  > 0

2. No tachyonic eigenvalues of H_B:
     spectrum(H_B) ≥ 0 except one negative mode for instanton.

3. Dirac operator should have only Goldstino zero modes.

4. Normal projection condition:
     dF(φ) = 0  always satisfied along the hypersurface.

""")


print("\n=== SCRIPT COMPLETE ===\n")

# ============================================================
# SECTION A — Fourier-based Poisson Solver (always stable)
# ============================================================

import numpy as np
import matplotlib.pyplot as plt

# Grid
Nx, Ny = 128, 128
Lx, Ly = 2.0, 2.0
dx, dy = Lx/Nx, Ly/Ny

x = np.linspace(-Lx/2, Lx/2, Nx)
y = np.linspace(-Ly/2, Ly/2, Ny)   # FIXED GRID !!!
X, Y = np.meshgrid(x, y, indexing='ij')

# Target density
rho = 1.0 + 0.1*np.exp(-(X**2 + Y**2))

# Subtract mean to satisfy Poisson solvability
rhs = rho - rho.mean()

# Fourier frequencies
kx = 2*np.pi*np.fft.fftfreq(Nx, d=dx)
ky = 2*np.pi*np.fft.fftfreq(Ny, d=dy)
KX, KY = np.meshgrid(kx, ky, indexing='ij')

# Fourier-domain Laplacian
lap = -(KX**2 + KY**2)
lap[0,0] = 1.0   # avoid division by zero

# Solve Poisson: -Δφ = rhs  →  φ = FFT^{-1}( FFT(rhs)/lap )
rhs_hat = np.fft.fft2(rhs)
phi_hat = rhs_hat / lap
phi_hat[0,0] = 0.0

phi = np.real(np.fft.ifft2(phi_hat))

# scale the amplitude
phi *= 0.3

Omega = np.exp(2*phi)

plt.imshow(Omega, extent=[-1,1,-1,1])
plt.colorbar()
plt.title("Fourier-Poisson Ricci Potential  Ω(x,y)")
plt.show()

print("Ω stats:", Omega.min(), Omega.max(), Omega.mean())

# =============================
# SECTION B — 2D Dirac Spectrum
# =============================

import numpy as np
import scipy.sparse as sp
import scipy.sparse.linalg as spla

# Use same grid (Nx, Ny, dx, dy)
spin = 2
Nsites = Nx * Ny
N = spin * Nsites

# 2D Euclidean gamma matrices
gamma1 = np.array([[0,1],[1,0]],dtype=np.complex128)
gamma2 = np.array([[0,-1j],[1j,0]],dtype=np.complex128)

def idx(ix,iy,s):
    return s + spin*(ix + Nx*iy)

phi_sol = np.zeros((Nx,Ny))   # replace with your actual kink background
m0 = 1.0

rows, cols, vals = [], [], []

for ix in range(Nx):
    for iy in range(Ny):
        for s in range(spin):

            # Mass term
            row = idx(ix,iy,s)
            for t in range(spin):
                col = idx(ix, iy, t)
                mass_term = m0*(1 + phi_sol[ix,iy]**2)
                rows.append(row); cols.append(col); vals.append(mass_term*(s==t))

            # Kinetic X-direction
            for sign,shift,gamma in [(1,1,gamma1),(-1,-1,gamma1)]:
                jx = (ix + shift) % Nx
                for t in range(spin):
                    row = idx(ix,iy,s)
                    col = idx(jx,iy,t)
                    coeff = (sign/(2*dx))*gamma[s,t]
                    rows.append(row); cols.append(col); vals.append(coeff)

            # Kinetic Y-direction
            for sign,shift,gamma in [(1,1,gamma2),(-1,-1,gamma2)]:
                jy = (iy + shift) % Ny
                for t in range(spin):
                    row = idx(ix,iy,s)
                    col = idx(ix,jy,t)
                    coeff = (sign/(2*dy))*gamma[s,t]
                    rows.append(row); cols.append(col); vals.append(coeff)

D = sp.coo_matrix((vals,(rows,cols)),shape=(N,N)).tocsr()
DFD = (D.conjugate().transpose()) @ D

# Smallest eigenvalues = fermionic spectrum
evals, _ = spla.eigsh(DFD, k=10, sigma=0.0)
evals = np.sort(np.real(evals))

print("Lowest fermionic eigenvalues λ²:")
print(evals)

# ============================================
# SECTION C — Chern Classes + χ = 215
# ============================================

import sympy as sp

H = sp.Symbol('H')
w0,w1,w2,w3 = 1,1,1,4
d = 172  # degree of hypersurface

# Ambient WP^3 Chern class
cP = (1 + w0*H)*(1 + w1*H)*(1 + w2*H)*(1 + w3*H)
cP = sp.expand(cP)

# Adjunction: c(T_M) = c(T_P)/(1 + dH)
# Expand denominator inverse up to H^2 (surface)
c_den_inv = sp.series(1/(1 + d*H), H, 0, 3).removeO()
cM = sp.expand(cP * c_den_inv)

print("c(T_P) =", cP)
print("c(T_M) =", cM)

c1 = cM.coeff(H,1)
c2 = cM.coeff(H,2)
print("c1 =", c1)
print("c2 =", c2)

# unknown intersection number and orbifold correction
H2 = sp.Symbol('H2')
delta = sp.Symbol('delta')

chi = c2*H2 + delta
print("\nχ(M) =", chi)

# Solve χ=215 for delta
sol = sp.solve(sp.Eq(chi, 215), delta)
print("\nOrbifold correction δ required for χ=215:")
print(sol)

# ============================================
# CELL 4 — 2D IIM kink on Ω(x,y) background
# ============================================

import jax
import jax.numpy as jnp

# Use the Omega from Fourier-Poisson cell
Omega_j = jnp.array(Omega)
X_j = jnp.array(X)
Y_j = jnp.array(Y)

# Parameters (toy; you can tune)
m2 = 1.0
lam = 1.0
g = 0.2
kappa = 0.1

Nx, Ny = Omega_j.shape
dx = Lx / Nx
dy = Ly / Ny

def grad_sq(phi):
    """|∇φ|^2 using central differences, periodic BCs."""
    dphi_dx = (jnp.roll(phi, -1, 0) - jnp.roll(phi, 1, 0)) / (2*dx)
    dphi_dy = (jnp.roll(phi, -1, 1) - jnp.roll(phi, 1, 1)) / (2*dy)
    return dphi_dx**2 + dphi_dy**2

def potential(phi0, phi1, phi2):
    V0 = m2*phi0**2 - lam*phi0**4 + g*phi0**8
    V1 = m2*phi1**2 - lam*phi1**4 + g*phi1**8
    V2 = m2*phi2**2 - lam*phi2**4 + g*phi2**8
    Vcross = kappa*(phi0**2*phi1**2 + phi1**2*phi2**2 + phi2**2*phi0**2)
    return V0 + V1 + V2 + Vcross

def energy(phi_all):
    """phi_all has shape (3, Nx, Ny)."""
    phi0, phi1, phi2 = phi_all[0], phi_all[1], phi_all[2]
    grad_term = 0.5*(grad_sq(phi0) + grad_sq(phi1) + grad_sq(phi2))
    V = potential(phi0, phi1, phi2)
    density = Omega_j * (grad_term + V)
    return jnp.sum(density) * dx * dy

# Initial kink-like configuration:
# φ0 ~ tanh in x, φ1=φ2=0
phi0_init = jnp.tanh(2.0 * X_j)   # width parameter 2.0 (tweakable)
phi1_init = jnp.zeros_like(phi0_init)
phi2_init = jnp.zeros_like(phi0_init)

phi_all = jnp.stack([phi0_init, phi1_init, phi2_init], axis=0)

energy_grad = jax.grad(energy)

@jax.jit
def step(phi_all, lr=5e-3):
    return phi_all - lr * energy_grad(phi_all)

for it in range(200):
    phi_all = step(phi_all)
    if it % 50 == 0:
        print(f"iter {it}, E =", float(energy(phi_all)))

phi0_sol, phi1_sol, phi2_sol = phi_all[0], phi_all[1], phi_all[2]

# Quick visualization of φ0 kink
import matplotlib.pyplot as plt
plt.imshow(np.array(phi0_sol), extent=[-1,1,-1,1])
plt.title("φ₀ kink on Ω background")
plt.colorbar()
plt.show()

# ============================================
# CELL 5 — Bosonic fluctuation operator
# ============================================

import numpy as np
import scipy.sparse as sp
import scipy.sparse.linalg as spla

phi0_sol_np = np.array(phi0_sol)
phi1_sol_np = np.array(phi1_sol)
phi2_sol_np = np.array(phi2_sol)

Nx, Ny = phi0_sol_np.shape
Nsites = Nx * Ny

def idx(ix, iy):
    return ix + Nx * iy

# Mass-squared M^2(φ0,φ1,φ2)
def M2_from_fields(phi0, phi1, phi2):
    return (2*m2
            - 12*lam*phi0**2
            + 56*g*phi0**6
            + 2*kappa*(phi1**2 + phi2**2))

M2_sol = M2_from_fields(phi0_sol_np, phi1_sol_np, phi2_sol_np)
M2_vac = M2_from_fields(np.zeros_like(phi0_sol_np),
                        np.zeros_like(phi1_sol_np),
                        np.zeros_like(phi2_sol_np))

# Build Laplacian with periodic BCs
rows, cols, vals = [], [], []

for ix in range(Nx):
    for iy in range(Ny):
        p = idx(ix, iy)
        # center
        rows.append(p); cols.append(p); vals.append(-4.0/(dx*dx))
        # neighbors (x)
        rows.append(p); cols.append(idx((ix+1)%Nx, iy)); vals.append(1.0/(dx*dx))
        rows.append(p); cols.append(idx((ix-1)%Nx, iy)); vals.append(1.0/(dx*dx))
        # neighbors (y)
        rows.append(p); cols.append(idx(ix, (iy+1)%Ny)); vals.append(1.0/(dx*dx))
        rows.append(p); cols.append(idx(ix, (iy-1)%Ny)); vals.append(1.0/(dx*dx))

L = sp.coo_matrix((vals, (rows, cols)), shape=(Nsites, Nsites)).tocsr()

# Add M^2 to get H_sol and H_vac
H_sol = -L + sp.diags(M2_sol.reshape(-1), 0)
H_vac = -L + sp.diags(M2_vac.reshape(-1), 0)

# Compute lowest eigenvalues
k = 20
evals_sol, _ = spla.eigsh(H_sol, k=k, sigma=0.0)
evals_vac, _ = spla.eigsh(H_vac, k=k, sigma=0.0)

evals_sol = np.sort(np.real(evals_sol))
evals_vac = np.sort(np.real(evals_vac))

print("Lowest bosonic eigenvalues (soliton):")
print(evals_sol)
print("\nLowest bosonic eigenvalues (vacuum):")
print(evals_vac)

# ============================================
# CELL 6 — 2D Dirac spectrum with kink background
# ============================================

import scipy.sparse as sp
import scipy.sparse.linalg as spla

Nx, Ny = phi0_sol_np.shape
dx = Lx / Nx
dy = Ly / Ny

spin = 2
Nsites = Nx * Ny
N = spin * Nsites

gamma1 = np.array([[0,1],[1,0]],dtype=np.complex128)
gamma2 = np.array([[0,-1j],[1j,0]],dtype=np.complex128)

def idx_spin(ix, iy, s):
    return s + spin*(ix + Nx*iy)

yukawa = 0.5   # Yukawa coupling (tunable)
m0_F = 1.0     # baseline fermion mass

rows, cols, vals = [], [], []

for ix in range(Nx):
    for iy in range(Ny):
        mF = m0_F + yukawa * phi0_sol_np[ix,iy]

        for s in range(spin):
            row = idx_spin(ix,iy,s)

            # on-site mass term
            for t in range(spin):
                col = idx_spin(ix,iy,t)
                rows.append(row); cols.append(col); vals.append(mF*(s==t))

            # kinetic X
            for sign,shift,gamma in [(1,1,gamma1),(-1,-1,gamma1)]:
                jx = (ix + shift) % Nx
                for t in range(spin):
                    row = idx_spin(ix,iy,s)
                    col = idx_spin(jx,iy,t)
                    coeff = (sign/(2*dx))*gamma[s,t]
                    rows.append(row); cols.append(col); vals.append(coeff)

            # kinetic Y
            for sign,shift,gamma in [(1,1,gamma2),(-1,-1,gamma2)]:
                jy = (iy + shift) % Ny
                for t in range(spin):
                    row = idx_spin(ix,iy,s)
                    col = idx_spin(ix,jy,t)
                    coeff = (sign/(2*dy))*gamma[s,t]
                    rows.append(row); cols.append(col); vals.append(coeff)

D = sp.coo_matrix((vals,(rows,cols)),shape=(N,N)).tocsr()
DFD = (D.conjugate().transpose()) @ D

k = 20
evals_F, _ = spla.eigsh(DFD, k=k, sigma=0.0)
evals_F = np.sort(np.real(evals_F))

print("Lowest fermionic eigenvalues λ_F² (kink background):")
print(evals_F)

#######################################################################
#   COMPLETE χ=215 IIM NUMERICAL PIPELINE
#   curvature Ω(x,y) + kink + spectra + determinants + rescaling
#######################################################################

import jax
import jax.numpy as jnp
import numpy as np
from scipy.sparse.linalg import eigsh
from scipy.sparse import diags, kron, identity

#######################################################################
# 0. GRID + CURVATURE BACKGROUND Ω(x,y) + DISCRETE LAPLACIAN
#######################################################################

Nx = 64
Ny = 64
Lx = 6.0
Ly = 6.0

x = jnp.linspace(-Lx, Lx, Nx)
y = jnp.linspace(-Ly, Ly, Ny)
dx = float(x[1] - x[0])
dy = float(y[1] - y[0])

X, Y = jnp.meshgrid(x, y, indexing='ij')

# Example curvature potential Φ → Ω = e^(−Φ)
Phi = 0.06*(X**2 + 2.1*Y**2) - 0.13*jnp.sin(2*jnp.pi*X/Lx) - 0.11*jnp.cos(2*jnp.pi*Y/Ly)
Omega = jnp.exp(-Phi)

# 2D Laplacian using Kronecker structure
ex = np.ones(Nx)
Lx_mat = diags([1,-2,1],[ -1,0,1 ], shape=(Nx,Nx)) / dx**2

ey = np.ones(Ny)
Ly_mat = diags([1,-2,1],[ -1,0,1 ], shape=(Ny,Ny)) / dy**2

Δ2 = kron(Lx_mat, identity(Ny)) + kron(identity(Nx), Ly_mat)
Δ2 = Δ2.tocsr()


#######################################################################
# 1. KINK RELAXATION (3 scalar fields φ0, φ1, φ2)
#######################################################################

m2 = 1.0
lam4 = 1.0
g6 = 0.2
kappa = 0.25

def V(phi):
    phi0, phi1, phi2 = phi
    quad = m2*(phi0**2 + phi1**2 + phi2**2)
    quart = lam4*(phi0**4 + phi1**4 + phi2**4)
    sextic = g6*(phi0**6 + phi1**6 + phi2**6)
    cross = kappa*(phi0**2*phi1**2 + phi1**2*phi2**2 + phi2**2*phi0**2)
    return quad + quart + sextic + cross

def energy(phi_flat):
    phi = phi_flat.reshape((3,Nx,Ny))
    phi_x = (phi[:,:,2:] - phi[:,:,:-2])/(2*dx)
    phi_y = (phi[:,2:,:] - phi[:,:-2,:])/(2*dy)
    # pad
    phi_x = jnp.pad(phi_x, ((0,0),(0,0),(1,1)), mode='edge')
    phi_y = jnp.pad(phi_y, ((0,0),(1,1),(0,0)), mode='edge')

    kin = 0.5*jnp.sum(phi_x**2 + phi_y**2, axis=0)
    pot = V(phi)
    dens = Omega*(kin + pot)
    return jnp.sum(dens)*dx*dy

grad_energy = jax.grad(energy)

# Initial condition
phi0_init = jnp.tanh(X)
phi1_init = 0.02*jnp.ones_like(X)
phi2_init = -0.02*jnp.ones_like(X)

phi_init = jnp.stack([phi0_init, phi1_init, phi2_init])
phi_flat = phi_init.reshape(-1)

lr = 0.02

for it in range(200):
    g = grad_energy(phi_flat)
    phi_flat -= lr*g
    if it % 50 == 0:
        print(f"iter {it}, E = {float(energy(phi_flat)):.4f}")

phi_sol = phi_flat.reshape((3,Nx,Ny))
S_old = float(energy(phi_flat))
print("\nFinal kink energy S_old =", S_old)


#######################################################################
# 2. BOSONIC SPECTRUM: Build Hessian H_B = -Δ + M²
#######################################################################

phi0 = np.array(phi_sol[0])
phi1 = np.array(phi_sol[1])
phi2 = np.array(phi_sol[2])

# Second derivative wrt φ0 only (take φ0 as tunneling field)
d2V_dphi0 = (
    2*m2
    + 12*lam4*phi0**2
    + 30*g6*phi0**4
    + 2*kappa*(phi1**2 + phi2**2)
)

# Flatten
M2_diag = d2V_dphi0.reshape(-1)
H_B = -Δ2 + diags(M2_diag, 0)

# Eigenvalues
vals_sol, vecs_sol = eigsh(H_B, k=20, sigma=0.0)
print("\nBosonic eigenvalues (soliton):\n", vals_sol)


#######################################################################
# 3. VACUUM BOSONIC OPERATOR
#######################################################################

phi0_vac = np.zeros((Nx,Ny))
phi1_vac = np.zeros((Nx,Ny))
phi2_vac = np.zeros((Nx,Ny))

d2V_vac = 2*m2 + 2*kappa*(0+0)
M2_vac = d2V_vac*np.ones_like(phi0_vac).reshape(-1)

H_B_vac = -Δ2 + diags(M2_vac, 0)
vals_vac, _ = eigsh(H_B_vac, k=20, sigma=0.0)
print("\nBosonic eigenvalues (vacuum):\n", vals_vac)


#######################################################################
# 4. FERMIONIC SPECTRUM: Dirac → D†D
#######################################################################

# Simple Yukawa mass: M_F = c * phi0
cF = 1.0
M_F = cF*phi0.reshape(-1)

H_FD = -Δ2 + diags(M_F**2, 0)
vals_F_sol, _ = eigsh(H_FD, k=20, sigma=0.0)

M_Fvac = cF*0.0
H_FDvac = -Δ2 + diags((M_Fvac**2)*np.ones_like(M2_vac),0)
vals_F_vac, _ = eigsh(H_FDvac, k=20, sigma=0.0)

print("\nFermionic eigenvalues (soliton):\n", vals_F_sol)
print("\nFermionic eigenvalues (vacuum):\n", vals_F_vac)


#######################################################################
# 5. DETERMINANT DIFFERENCES
#######################################################################

# Remove mode 0 (negative mode), keep first 10 non-negatives
boson_sol_nonneg = vals_sol[1:11]
boson_vac_nonneg = vals_vac[0:10]

Δlogdet_B = np.sum(np.log(np.abs(boson_sol_nonneg))) - np.sum(np.log(boson_vac_nonneg))

ferm_sol = vals_F_sol[0:10]
ferm_vac = vals_F_vac[0:10]

Δlogdet_F = 0.5*(np.sum(np.log(ferm_sol)) - np.sum(np.log(ferm_vac)))

Δlogdet_SUSY = Δlogdet_B - 2*Δlogdet_F

print("\nΔ log(det) bosonic =", Δlogdet_B)
print("Δ log(det) fermionic =", Δlogdet_F)
print("Δ log(det) SUSY combined =", Δlogdet_SUSY)

print("\nFractional loop B:", Δlogdet_B/S_old)
print("Fractional loop SUSY:", Δlogdet_SUSY/S_old)


#######################################################################
# 6. RESCALE TO HIT E1 = 1.32
#######################################################################

chi = 215
E1_old = S_old/chi
E1_target = 1.32
alpha = E1_target/E1_old

print("\n==== RESCALING ====")
print("Old E1 =", E1_old)
print("Target E1 =", E1_target)
print("Rescale factor alpha =", alpha)

S_new = alpha*S_old
print("New total action S_new =", S_new)
print("New E1 =", S_new/chi)

# New fractional loops:
print("\nBosonic loop fraction (new) =", Δlogdet_B/S_new)
print("SUSY loop fraction (new) =", Δlogdet_SUSY/S_new)


#######################################################################
# 7. FINAL REPORT (print for PRD)
#######################################################################

print("\n==================== FINAL REPORT ====================\n")
print(f"Kink action S_old = {S_old:.3f}")
print(f"E1_old = {E1_old:.4f}")
print(f"Rescale α = {alpha:.3f}")
print(f"S_new = {S_new:.3f}  (target ~284)")
print(f"E1_new = {S_new/chi:.4f}  (target = 1.32)")
print("\nSpectrum (soliton):\n", vals_sol)
print("\nSpectrum (vacuum):\n", vals_vac)
print("\nΔlogdet_B =", Δlogdet_B)
print("Δlogdet_F =", Δlogdet_F)
print("Δlogdet_SUSY =", Δlogdet_SUSY)
print("\nLoop fractions (unscaled, scaled):")
print(f"  Bosonic: {Δlogdet_B/S_old:.4f}   → {Δlogdet_B/S_new:.4f}")
print(f"  SUSY    : {Δlogdet_SUSY/S_old:.4f} → {Δlogdet_SUSY/S_new:.4f}")
print("\n======================================================")

##############################################
# IIM NUMERICAL INSTANTON SOLVER (2D REDUCTION)
# - One χ=215 "cell" in a curved Ω(x,y) background
# - Kink instanton x(x,y)
# - Bosonic and fermionic fluctuation spectra
# - 1-loop determinant ratios and IIM scaling
#
# Requires: jax, numpy, scipy, matplotlib
##############################################

import numpy as np
import matplotlib.pyplot as plt

import jax
import jax.numpy as jnp

import scipy.sparse as sp
import scipy.sparse.linalg as spla

##############################################
# 0. GLOBAL CONSTANTS / IIM TARGET
##############################################

CHI = 215                    # |χ| of the internal manifold
E1_TARGET = 284.0 / 215.0    # target E1 ≈ 1.32

##############################################
# 1. GRID + CURVED BACKGROUND Ω(x,y)
##############################################

# Choose a moderate grid so eigenvalue problems are tractable
Nx, Ny = 64, 64
Lx, Ly = 2.0, 2.0           # physical box size
dx, dy = Lx / Nx, Ly / Ny

x = np.linspace(-Lx/2, Lx/2, Nx)
y = np.linspace(-Ly/2, Ly/2, Ny)
X, Y = np.meshgrid(x, y, indexing='ij')

# Target "curvature density" ρ(x,y) (Gaussian bump)
rho = 1.0 + 0.1*np.exp(-(X**2 + Y**2))
rhs = rho - rho.mean()      # zero-mean for Poisson solvability

# Fourier Poisson solve: -Δφ = rhs → φ
kx = 2*np.pi*np.fft.fftfreq(Nx, d=dx)
ky = 2*np.pi*np.fft.fftfreq(Ny, d=dy)
KX, KY = np.meshgrid(kx, ky, indexing='ij')
lap = -(KX**2 + KY**2)
lap[0,0] = 1.0              # avoid division by zero

rhs_hat = np.fft.fft2(rhs)
phi_hat = rhs_hat / lap
phi_hat[0,0] = 0.0          # fix constant mode
phi = np.real(np.fft.ifft2(phi_hat))

# scale φ to keep Ω close to 1 but nontrivial
phi *= 0.3
Omega = np.exp(2*phi)

print("Ω stats (min, max, mean):", Omega.min(), Omega.max(), Omega.mean())

plt.imshow(Omega, extent=[-Lx/2, Lx/2, -Ly/2, Ly/2])
plt.title("Curved background Ω(x,y)")
plt.colorbar()
plt.show()

##############################################
# 2. IIM EFFECTIVE POTENTIAL (2D REDUCTION)
##############################################

# The IIM effective scalar sector in 2D reduction:
#
#   L_Eucl = Ω(x,y) * [ 1/2 (∇x)^2 + V_eff(x) ]
#
# We use a polynomial piece (from SUSY W) and optionally an
# exponential IIM tail. For the numerics, the polynomial part
# dominates the shape, and we interpret the overall action scaling
# afterward.

# Toy SUSY-inspired coefficients (you can tune these)
m2 = 1.0
lam = 1.0
g = 0.2

# Optional exponential tail (IIM topological piece)
ALPHA = 1.0
KAPPA_EXP = 0.1

def V_eff(x_field):
    """
    Effective potential V_eff(x) on the 2D patch.
    x_field: jnp.array (Nx, Ny)
    """
    poly = m2 * x_field**2 - lam * x_field**4 + g * x_field**8
    exp_part = KAPPA_EXP * jnp.exp(-ALPHA * x_field)
    return poly + exp_part

##############################################
# 3. INSTANTON / KINK SOLVER VIA GRADIENT DESCENT
##############################################

Omega_j = jnp.array(Omega)
X_j = jnp.array(X)
Y_j = jnp.array(Y)

def grad_sq(field):
    """|∇field|^2 using central differences, periodic BCs."""
    dfdx = (jnp.roll(field, -1, 0) - jnp.roll(field, 1, 0)) / (2*dx)
    dfdy = (jnp.roll(field, -1, 1) - jnp.roll(field, 1, 1)) / (2*dy)
    return dfdx**2 + dfdy**2

def energy(x_field):
    """
    Euclidean action/energy functional:
      S = ∫ Ω [ 1/2 (∇x)^2 + V_eff(x) ] dx dy
    """
    grad_term = 0.5 * grad_sq(x_field)
    Vloc = V_eff(x_field)
    density = Omega_j * (grad_term + Vloc)
    return jnp.sum(density) * dx * dy

# Initial kink-like guess: tanh in x-direction
x_init = jnp.tanh(2.0 * X_j)  # width parameter 2.0

x_field = x_init
energy_grad = jax.grad(energy)

@jax.jit
def step(x_field, lr=5e-3):
    return x_field - lr * energy_grad(x_field)

print("\n=== Solving for instanton / kink configuration x(x,y) ===")
for it in range(200):
    x_field = step(x_field)
    if it % 50 == 0:
        print(f"iter {it}, S (unscaled) = {float(energy(x_field)):.6f}")

S_old = float(energy(x_field))
print(f"Final unscaled action S_old = {S_old:.6f}")

x_sol = np.array(x_field)

plt.imshow(x_sol, extent=[-Lx/2, Lx/2, -Ly/2, Ly/2])
plt.title("Instanton / kink profile x(x,y)")
plt.colorbar()
plt.show()

##############################################
# 4. BOSONIC FLUCTUATION OPERATOR H_B
##############################################

# H_B = -Δ + M^2(x) acting on scalar fluctuations δx.

Nx, Ny = x_sol.shape
Nsites = Nx * Ny

def idx(ix, iy):
    return ix + Nx*iy

# Mass-squared from second derivative of V_eff with respect to x
def M2_from_field(x_field):
    # V = m2 x^2 - lam x^4 + g x^8 + k_exp e^{-α x}
    # dV/dx = 2m2 x - 4 lam x^3 + 8 g x^7 - α k_exp e^{-α x}
    # d2V/dx2 = 2m2 - 12 lam x^2 + 56 g x^6 + α^2 k_exp e^{-α x}
    x = x_field
    return (2*m2
            - 12*lam*x**2
            + 56*g*x**6
            + (ALPHA**2)*KAPPA_EXP*np.exp(-ALPHA*x))

M2_sol = M2_from_field(x_sol)
M2_vac = M2_from_field(np.zeros_like(x_sol))

# Build Laplacian with periodic BCs
rows, cols, vals = [], [], []

for ix in range(Nx):
    for iy in range(Ny):
        p = idx(ix, iy)
        # center
        rows.append(p); cols.append(p); vals.append(-4.0/(dx*dx))
        # neighbors in x
        rows.append(p); cols.append(idx((ix+1)%Nx, iy)); vals.append(1.0/(dx*dx))
        rows.append(p); cols.append(idx((ix-1)%Nx, iy)); vals.append(1.0/(dx*dx))
        # neighbors in y
        rows.append(p); cols.append(idx(ix, (iy+1)%Ny)); vals.append(1.0/(dx*dx))
        rows.append(p); cols.append(idx(ix, (iy-1)%Ny)); vals.append(1.0/(dx*dx))

L = sp.coo_matrix((vals, (rows, cols)), shape=(Nsites, Nsites)).tocsr()

H_sol = -L + sp.diags(M2_sol.reshape(-1), 0)
H_vac = -L + sp.diags(M2_vac.reshape(-1), 0)

print("\n=== Computing bosonic fluctuation spectra (H_B) ===")
k_b = 20   # number of lowest modes

evals_sol_B, _ = spla.eigsh(H_sol, k=k_b, sigma=0.0)
evals_vac_B, _ = spla.eigsh(H_vac, k=k_b, sigma=0.0)

evals_sol_B = np.sort(np.real(evals_sol_B))
evals_vac_B = np.sort(np.real(evals_vac_B))

print("Lowest bosonic eigenvalues (soliton):")
print(evals_sol_B)
print("\nLowest bosonic eigenvalues (vacuum):")
print(evals_vac_B)

# Δ log det_B from the lowest k_b non-negative modes
# (ignore negative mode if present)
sol_pos = evals_sol_B[evals_sol_B > 0]
vac_pos = evals_vac_B[evals_vac_B > 0]

Delta_logdet_B = np.sum(np.log(sol_pos)) - np.sum(np.log(vac_pos))
print(f"\nΔ log det_B (from lowest {len(sol_pos)} positive modes) = {Delta_logdet_B:.6f}")

##############################################
# 5. FERMIONIC DIRAC OPERATOR AND SPECTRUM
##############################################

# Dirac operator:
#   D_F ψ = γ^μ (∂_μ + ...) ψ + m_F(x) ψ
#
# We discretize a simple 2D Euclidean Dirac operator on the grid
# with periodic BCs, and include a Yukawa mass
#
#   m_F(x) = m0 + y * x(x,y)
#
# Then we study eigenvalues of D_F† D_F.

spin = 2
N = spin * Nsites

gamma1 = np.array([[0, 1],[1, 0]], dtype=np.complex128)
gamma2 = np.array([[0,-1j],[1j,0]], dtype=np.complex128)

def idx_spin(ix, iy, s):
    return s + spin*(ix + Nx*iy)

yukawa = 0.5   # Yukawa coupling
m0_F = 1.0     # baseline Dirac mass

def build_D(phi_background):
    rows, cols, vals = [], [], []
    for ix in range(Nx):
        for iy in range(Ny):
            x_val = phi_background[ix,iy]
            mF = m0_F + yukawa * x_val
            for s in range(spin):
                row = idx_spin(ix,iy,s)

                # On-site mass term
                for t in range(spin):
                    col = idx_spin(ix,iy,t)
                    rows.append(row); cols.append(col); vals.append(mF*(s==t))

                # Kinetic X
                for sign, shift, gamma in [(1,1,gamma1),(-1,-1,gamma1)]:
                    jx = (ix + shift) % Nx
                    for t in range(spin):
                        col = idx_spin(jx,iy,t)
                        coeff = (sign/(2*dx)) * gamma[s,t]
                        rows.append(row); cols.append(col); vals.append(coeff)

                # Kinetic Y
                for sign, shift, gamma in [(1,1,gamma2),(-1,-1,gamma2)]:
                    jy = (iy + shift) % Ny
                    for t in range(spin):
                        col = idx_spin(ix,jy,t)
                        coeff = (sign/(2*dy)) * gamma[s,t]
                        rows.append(row); cols.append(col); vals.append(coeff)

    D = sp.coo_matrix((vals,(rows,cols)),shape=(N,N)).tocsr()
    return D

print("\n=== Building Dirac operators for kink and vacuum ===")
D_kink = build_D(x_sol)
D_vac  = build_D(np.zeros_like(x_sol))

DFD_kink = (D_kink.conjugate().transpose()) @ D_kink
DFD_vac  = (D_vac.conjugate().transpose())  @ D_vac

k_f = 20
print("Computing lowest fermionic eigenvalues ...")
evals_kink_F, _ = spla.eigsh(DFD_kink, k=k_f, sigma=0.0)
evals_vac_F, _  = spla.eigsh(DFD_vac,  k=k_f, sigma=0.0)

evals_kink_F = np.sort(np.real(evals_kink_F))
evals_vac_F  = np.sort(np.real(evals_vac_F))

print("Lowest fermionic eigenvalues λ_F² (kink):")
print(evals_kink_F)
print("\nLowest fermionic eigenvalues λ_F² (vacuum):")
print(evals_vac_F)

# Δ log det_F from these modes
kink_pos = evals_kink_F[evals_kink_F > 0]
vac_pos  = evals_vac_F[evals_vac_F > 0]

Delta_logdet_F = np.sum(np.log(kink_pos)) - np.sum(np.log(vac_pos))
print(f"\nΔ log det_F (from lowest {len(kink_pos)} positive modes) = {Delta_logdet_F:.6f}")

##############################################
# 6. IIM SCALING AND LOOP FRACTIONS
##############################################

print("\n=== IIM scaling and loop fractions ===")

# Unscaled instanton action
S_old = float(S_old)
E1_old = S_old / CHI

print(f"Unscaled S_old = {S_old:.6f}")
print(f"Unscaled E1_old = S_old/χ = {E1_old:.6f}")

# Scaling factor needed to hit E1_target
kappa_action = E1_TARGET / E1_old
S_new = kappa_action * S_old

print(f"\nIIM target E1_target = {E1_TARGET:.6f}")
print(f"Required action scaling κ_action = {kappa_action:.6f}")
print(f"Scaled action S_new = κ_action * S_old = {S_new:.6f}")

# Bosonic and SUSY-combined loop corrections
Delta_logdet_B = float(Delta_logdet_B)
Delta_logdet_F = float(Delta_logdet_F)

Delta_logdet_SUSY = Delta_logdet_B - 2.0 * Delta_logdet_F

print(f"\nΔ log det_B  = {Delta_logdet_B:.6f}")
print(f"Δ log det_F  = {Delta_logdet_F:.6f}")
print(f"Δ log det_SUSY = Δ_B - 2 Δ_F = {Delta_logdet_SUSY:.6f}")

# Fractions relative to unscaled and scaled actions
print("\nLoop fractions (bosonic only):")
print(f"  Δ log det_B / S_old = {Delta_logdet_B / S_old:.4f}")
print(f"  Δ log det_B / S_new = {Delta_logdet_B / S_new:.4f}")

print("\nLoop fractions (SUSY combined):")
print(f"  Δ log det_SUSY / S_old = {Delta_logdet_SUSY / S_old:.4f}")
print(f"  Δ log det_SUSY / S_new = {Delta_logdet_SUSY / S_new:.4f}")

print("\n=== DONE ===")
print("You now have:")
print(" - A curved Ω(x,y) patch")
print(" - An instanton x(x,y) with action S_old")
print(" - Bosonic and fermionic spectra and 1-loop determinants")
print(" - The IIM scaling κ_action needed to hit E1 = 284/215")

# ============================================
# SECTION A — Balanced metric for χ=215 CY
# ============================================
import numpy as np

weights = np.array([1,1,1,4], dtype=int)
d = 172  # hypersurface degree

# Hypersurface: F(z0,z1,z2,z3) = z0^172 + z1^172 + z2^172 + z3^43
# Work in affine patch z0 = 1 ⇒ F = 1 + z1^172 + z2^172 + z3^43

def F_affine(z1,z2,z3):
    return 1 + z1**172 + z2**172 + z3**43

# ---- FIXED SAMPLING ----
# Instead of naive sampling, sample random points on CP^3,
# then project them onto hypersurface by Newton step.

def sample_points_CP3(n):
    """Uniform-ish sampling on CP^3 via normal Gaussian then projective divide."""
    Z = np.random.normal(size=(n,4)) + 1j*np.random.normal(size=(n,4))
    Z /= np.linalg.norm(Z, axis=1)[:,None]
    return Z

def project_onto_hypersurface(Z, n_iter=5):
    """Perform a few Newton correction steps onto F=0 in affine patch."""
    pts=[]
    for z in Z:
        z0,z1,z2,z3 = z
        if abs(z0)==0: continue
        u1=u2=u3=z1/z0, z2/z0, z3/z0  # not used; rewriting below
    pts=[]

    for z0,z1,z2,z3 in Z:
        if abs(z0)==0: continue
        u1,u2,u3 = z1/z0, z2/z0, z3/z0
        for _ in range(n_iter):
            F = F_affine(u1,u2,u3)
            if abs(F)<1e-6: break
            # derivative in affine patch
            dF_u1 = 172*u1**171
            dF_u2 = 172*u2**171
            dF_u3 = 43*u3**42
            denom = abs(dF_u1)**2 + abs(dF_u2)**2 + abs(dF_u3)**2 + 1e-12
            # projective Newton update
            u1 -= F*np.conjugate(dF_u1)/denom
            u2 -= F*np.conjugate(dF_u2)/denom
            u3 -= F*np.conjugate(dF_u3)/denom
        if abs(F_affine(u1,u2,u3))<1e-3:
            pts.append([u1,u2,u3])
    return np.array(pts)

print("Sampling CP^3...")
Z0 = sample_points_CP3(6000)
print("Projecting onto F=0...")
Z_samples = project_onto_hypersurface(Z0, n_iter=8)
print("Accepted:", Z_samples.shape[0], "points")

# ---- Holomorphic basis ----
def monomial_basis(z, max_deg=2):
    u1,u2,u3 = z
    mons=[]
    for a in range(max_deg+1):
        for b in range(max_deg+1-a):
            for c in range(max_deg+1-a-b):
                mons.append((u1**a)*(u2**b)*(u3**c))
    return np.array(mons, dtype=complex)

basis_vals=[]
for z in Z_samples:
    basis_vals.append(monomial_basis(z,max_deg=2))
basis_vals=np.array(basis_vals)
N_pts,N_basis=basis_vals.shape
print("Basis size:",N_basis," points:",N_pts)

# ---- Balanced metric iteration ----
h=np.eye(N_basis,dtype=complex)

def compute_K_and_M(h,basis_vals):
    N_pts,N_basis=basis_vals.shape
    M=np.zeros((N_basis,N_basis),dtype=complex)
    Kvals=np.zeros(N_pts)
    for i in range(N_pts):
        s=basis_vals[i]
        denom=np.conjugate(s)@(h@s)
        Kvals[i]=np.log(abs(denom))
        M+=np.outer(s,np.conjugate(s))/denom
    M/=N_pts
    return Kvals,M

for it in range(5):
    Kvals,M = compute_K_and_M(h,basis_vals)
    h_new=np.linalg.inv(M)
    h_new*=N_basis/np.trace(h_new)
    h=0.5*(h+h_new)
    print(f"iter {it}: mean(K)={Kvals.mean():.5f}, std(K)={Kvals.std():.5f}")

K_CY_eff=float(Kvals.mean())
print("\nEffective <K_CY> =",K_CY_eff)

# ======================================================
# SECTION B+C (REPLACEMENT)
# Full SUGRA-style IIM potential + 4D O(4) instanton
# ======================================================
import jax
import jax.numpy as jnp
import numpy as onp

# ---- Use K_CY_eff from Section A ----
K_CY_eff_j = jnp.array(K_CY_eff)

# ========= SUGRA single-field truncation =========

def K_4D(X):
    """
    4D Kähler potential for the effective single chiral field X.
    We use: K_total = <K_CY> + 1/2 X^2
    (dimensionless, in Planck units).
    """
    return K_CY_eff_j + 0.5 * X**2

def W_4D(X):
    """
    Toy IIM-inspired superpotential for the instanton direction.
    Parameters chosen small to keep V bounded and numerically tame.
    """
    W0  = 0.02      # small constant term
    m   = 0.15
    lam = 0.03
    g   = 0.002
    return W0 + m*X - lam*X**3 + g*X**5

def V_eff_4D(X):
    """
    Full SUGRA-like IIM effective potential:
      V = e^K ( |D_X W|^2 - 3 |W|^2 ) + kappa_top e^{-zeta X}
    with:
      D_X W = dW/dX + (dK/dX) W
    Single real field truncation, so |...|^2 -> square.
    """
    W   = W_4D(X)
    dW  = jax.grad(W_4D)(X)
    K   = K_4D(X)
    dK  = jax.grad(K_4D)(X)
    DXW = dW + dK * W
    eK  = jnp.exp(K)

    # SUGRA F-term potential
    V_F = eK * (DXW**2 - 3.0 * W**2)

    # IIM topological/exponential tail
    # We keep zeta ~ O(1) here; the χ-dependent exponent
    # is handled by the κ_action scaling at the end.
    zeta  = 1.0
    kappa_top = 0.02
    V_top = kappa_top * jnp.exp(-zeta * X)

    return V_F + V_top

# --------- Diagnostics: check shape of V(X) ---------
X_test = jnp.linspace(-3.0, 3.0, 400)
V_test = jax.vmap(V_eff_4D)(X_test)
print("V(X) diagnostics:")
print("  min V =", float(jnp.min(V_test)),
      "at X ≈", float(X_test[jnp.argmin(V_test)]))
print("  max V over scan =", float(jnp.max(V_test)))

# ======================================================
# 4D O(4)-symmetric instanton solver (with safe integrator)
# ======================================================

Nr    = 800
R_max = 10.0
r     = jnp.linspace(0.0, R_max, Nr)
dr    = r[1] - r[0]

def trapz_jax(y, x):
    """JAX-safe trapezoidal integration."""
    return jnp.sum((y[:-1] + y[1:]) * (x[1:] - x[:-1]) * 0.5)

def action_4D(Xprof):
    """
    Euclidean 4D O(4)-symmetric action:
      S = 2π^2 ∫ dr r^3 [ 1/2 (X')^2 + V_eff(X) ].
    """
    # Derivative X'(r)
    Xp = (jnp.roll(Xprof, -1) - jnp.roll(Xprof, 1)) / (2 * dr)
    Xp = Xp.at[0].set((Xprof[1] - Xprof[0]) / dr)
    Xp = Xp.at[-1].set((Xprof[-1] - Xprof[-2]) / dr)

    Vloc = jax.vmap(V_eff_4D)(Xprof)
    integrand = r**3 * (0.5 * Xp**2 + Vloc)
    S = 2.0 * (jnp.pi**2) * trapz_jax(integrand, r)
    return S

S_grad = jax.grad(action_4D)

# ---- Initial guess: smooth bubble between false and true 'vacua' ----
V_vals = jax.vmap(V_eff_4D)(X_test)
X_min  = float(X_test[jnp.argmin(V_vals)])   # location of (approx) deeper minimum
X_false = 0.0

X0 = X_false + 0.5 * (X_min - X_false) * (1.0 - jnp.tanh((r - 3.0)/1.0))
print("Initial action S_0 =", float(action_4D(X0)))

# ---- Safe gradient descent (step clipping to avoid NaNs) ----
@jax.jit
def relax_safe(Xprof, lr=3e-5, max_step=1e-3):
    """
    Gradient descent with global step-size clipping:
      ΔX = -lr * grad S
      if ||ΔX||_∞ > max_step, scale it down.
    """
    g = S_grad(Xprof)
    step = -lr * g
    max_abs = jnp.max(jnp.abs(step))
    scale = jnp.minimum(1.0, max_step / (max_abs + 1e-12))
    step = step * scale
    return Xprof + step

Xprof = X0
for it in range(2000):
    Xprof = relax_safe(Xprof)
    if it % 200 == 0:
        S_val = float(action_4D(Xprof))
        print(f"iter {it}, S = {S_val:.6f}")

S_unscaled = float(action_4D(Xprof))
print("\nFinal unscaled 4D instanton action S_unscaled =", S_unscaled)

# Quick sanity check on profile shape
import matplotlib.pyplot as plt
plt.plot(onp.array(r), onp.array(Xprof))
plt.xlabel("r")
plt.ylabel("X(r)")
plt.title("O(4) IIM instanton profile (Option 2 SUGRA)")
plt.show()

# ============================================
# SECTION D+E — Radial spectra + IIM scaling
# (Corrected: no r=0 singularities, stable eigen-solvers)
# ============================================
from scipy.sparse import diags
from scipy.sparse.linalg import eigsh
import numpy as onp
import jax
import jax.numpy as jnp

# ----------------------------------------------------
# 0. Remove the r=0 singularity (CRUCIAL FIX)
# ----------------------------------------------------
r_min = 1e-3        # small nonzero radius
Rmax  = float(r[-1])
Nr    = len(r)

r = jnp.linspace(r_min, Rmax, Nr)
dr = float(r[1] - r[0])

# ----------------------------------------------------
# 1. Second derivative of the potential on profile
# ----------------------------------------------------
d2V = jax.jacfwd(jax.grad(V_eff_4D))
V2_sol = onp.array(jax.vmap(d2V)(Xprof))      # instanton
V2_vac = onp.array(jax.vmap(d2V)(jnp.full_like(Xprof, X_false)))

# ----------------------------------------------------
# 2. Build radial Laplacian with regular boundary
# ----------------------------------------------------
# -d^2/dr^2
main = onp.full(Nr, -2.0/dr**2)
off  = onp.full(Nr-1, 1.0/dr**2)
L = diags([main, off, off], [0, 1, -1])

# regularity at r_min instead of true r=0
# -(3/r) d/dr term
rp = onp.array(r)
off_plus  = -3.0/(2.0*rp[1:]*dr)   # +1 diagonal
off_minus =  3.0/(2.0*rp[:-1]*dr)  # -1 diagonal
D1 = diags([off_plus, off_minus], [1, -1])

# ----------------------------------------------------
# 3. Build fluctuation operators
# ----------------------------------------------------
H_B_sol = -(L + D1) + diags([V2_sol], [0])
H_B_vac = -(L + D1) + diags([V2_vac], [0])

# Fermionic operator H_F = D_F^† D_F
dW = jax.grad(W_4D)
Wprime_sol = onp.array(jax.vmap(dW)(Xprof))
Wprime_vac = onp.array(jax.vmap(dW)(jnp.full_like(Xprof, X_false)))

H_F_sol = -(L + D1) + diags([Wprime_sol**2], [0])
H_F_vac = -(L + D1) + diags([Wprime_vac**2], [0])

# ----------------------------------------------------
# 4. Safe ARPACK call with shift-invert (very stable)
# ----------------------------------------------------
def lowest_eigs(A, k=12, sigma=0.0):
    """Robust small-eigenvalue solver."""
    return eigsh(A, k=k, sigma=sigma, which='LM', return_eigenvectors=False)

k_modes = 12

evals_B_sol = lowest_eigs(H_B_sol, k=k_modes)
evals_B_vac = lowest_eigs(H_B_vac, k=k_modes)
evals_F_sol = lowest_eigs(H_F_sol, k=k_modes)
evals_F_vac = lowest_eigs(H_F_vac, k=k_modes)

print("Bosonic eigenvalues (soliton):", evals_B_sol)
print("Bosonic eigenvalues (vacuum):", evals_B_vac)
print("\nFermionic λ_F^2 (soliton):", evals_F_sol)
print("Fermionic λ_F^2 (vacuum):", evals_F_vac)

# ----------------------------------------------------
# 5. Determinant differences
# ----------------------------------------------------
def delta_logdet(e_sol, e_vac, eps=1e-12):
    sol = onp.sort(e_sol)
    vac = onp.sort(e_vac)

    # keep only positive
    sol = sol[sol > eps]
    vac = vac[vac > eps]
    n = min(len(sol), len(vac))
    sol = sol[:n]
    vac = vac[:n]
    return float(onp.sum(onp.log(sol+eps) - onp.log(vac+eps)))

Δ_logdet_B = delta_logdet(evals_B_sol, evals_B_vac)
Δ_logdet_F = delta_logdet(evals_F_sol, evals_F_vac)
Δ_logdet_SUSY = Δ_logdet_B - 2.0 * Δ_logdet_F

print("\nΔ log det_B =", Δ_logdet_B)
print("Δ log det_F =", Δ_logdet_F)
print("Δ log det_SUSY =", Δ_logdet_SUSY)

# ----------------------------------------------------
# 6. IIM scaling (χ=215, S_new=284)
# ----------------------------------------------------
CHI = 215.0
S_old = S_unscaled
E1_old = S_old / CHI
E1_target = 284.0 / CHI
κ_action = E1_target / E1_old
S_new = κ_action * S_old

print("\n=== IIM SCALING ===")
print("S_old =", S_old)
print("E1_old =", E1_old)
print("E1_target =", E1_target)
print("κ_action =", κ_action)
print("S_new =", S_new)

print("\nLoop fractions:")
print("Δ log det_B / S_new =", Δ_logdet_B / S_new)
print("Δ log det_SUSY / S_new =", Δ_logdet_SUSY / S_new)

# ============================================================
# SECTION F — Higher-k Donaldson CY metric on χ=215 hypersurface
# ============================================================
import numpy as np
import sympy as sp
from numpy.random import default_rng

rng = default_rng(1234)

# ----- 1. Geometry: same χ=215 hypersurface in WP^3(1,1,1,4) -----

u1, u2, u3 = sp.symbols('u1 u2 u3', complex=True)
u1b, u2b, u3b = sp.symbols('u1b u2b u3b', complex=True)

# Hypersurface: F = 1 + u1^172 + u2^172 + u3^43
F_expr = 1 + u1**172 + u2**172 + u3**43
dF_u1 = sp.diff(F_expr, u1)
dF_u2 = sp.diff(F_expr, u2)
dF_u3 = sp.diff(F_expr, u3)

F_num   = sp.lambdify((u1,u2,u3), F_expr, 'numpy')
dF1_num = sp.lambdify((u1,u2,u3), dF_u1, 'numpy')
dF2_num = sp.lambdify((u1,u2,u3), dF_u2, 'numpy')
dF3_num = sp.lambdify((u1,u2,u3), dF_u3, 'numpy')

def project_to_M(u1z, u2z, u3z, tol=1e-10, max_iter=10):
    """
    Simple Newton projection onto F=0 in the local WP^3 patch z0≠0.
    Uses a crude 1D normal step defined by the gradient.
    """
    for _ in range(max_iter):
        Fv = F_num(u1z, u2z, u3z)
        if not np.isfinite(Fv):
            break
        if abs(Fv) < tol:
            return u1z, u2z, u3z, True
        g1 = dF1_num(u1z, u2z, u3z)
        g2 = dF2_num(u1z, u2z, u3z)
        g3 = dF3_num(u1z, u2z, u3z)
        denom = abs(g1)**2 + abs(g2)**2 + abs(g3)**2 + 1e-24
        step = Fv / denom
        u1z -= step*np.conjugate(g1)
        u2z -= step*np.conjugate(g2)
        u3z -= step*np.conjugate(g3)
    return u1z, u2z, u3z, False

def sample_points_on_M(n_pts=2000, radius=0.7):
    pts = []
    attempts = 0
    while len(pts) < n_pts and attempts < 50*n_pts:
        attempts += 1
        u1z = radius*(rng.normal()+1j*rng.normal())
        u2z = radius*(rng.normal()+1j*rng.normal())
        u3z = radius*(rng.normal()+1j*rng.normal())
        u1p, u2p, u3p, ok = project_to_M(u1z,u2z,u3z)
        if ok and np.isfinite(F_num(u1p,u2p,u3p)):
            pts.append((u1p,u2p,u3p))
    print(f"Accepted: {len(pts)} / {attempts} attempts")
    return np.array(pts, dtype=np.complex128)

# ----- 2. Holomorphic basis sections (higher-k Bergman basis) -----

def monomial_exponents(max_deg):
    """
    Generate exponents (a,b,c) for monomials u1^a u2^b u3^c
    up to total degree max_deg. Weighted/quasi-homogeneity constraints
    from WP^3(1,1,1,4) can be added later.
    """
    exps = []
    for a in range(max_deg+1):
        for b in range(max_deg+1-a):
            for c in range(max_deg+1-a-b):
                exps.append((a,b,c))
    return exps

def build_basis_matrix(points, exps):
    """
    Matrix of shape (N_pts, N_basis) with s_alpha(z_i).
    """
    u1_vals = points[:,0]
    u2_vals = points[:,1]
    u3_vals = points[:,2]
    N_pts = len(points)
    N_basis = len(exps)
    S = np.zeros((N_pts, N_basis), dtype=np.complex128)
    for j,(a,b,c) in enumerate(exps):
        S[:,j] = (u1_vals**a)*(u2_vals**b)*(u3_vals**c)
    return S

# Weighted FS Kähler potential on WP^3(1,1,1,4)
def K_FS(u1z,u2z,u3z):
    # as before: K = log(1+|u1|^2+|u2|^2 + |u3|^{1/2})
    return np.log(1.0 + np.abs(u1z)**2 + np.abs(u2z)**2 + np.abs(u3z)**0.5)

# Balanced-metric iteration
def donaldson_balance(S, n_iter=10):
    """
    Given S_{iα} = s_α(z_i), run Donaldson's iteration
    on the N_basis×N_basis hermitian matrix h.
    """
    N_pts, N_basis = S.shape
    # Start with identity hermitian form
    h = np.eye(N_basis, dtype=np.complex128)
    for it in range(n_iter):
        # Compute fiber norms ||s(z_i)||_h^2 = s† h s
        Sh = S @ h
        norms2 = np.einsum('ij,ij->i', np.conjugate(S), Sh).real + 1e-24
        # Moment matrix M
        M = np.zeros_like(h)
        for i in range(N_pts):
            v = S[i,:][:,None]  # column
            M += (v @ v.conj().T) / norms2[i]
        M /= N_pts
        # Update h ← (M^{-1}) N_basis / Tr(M^{-1})
        Minv = np.linalg.inv(M + 1e-12*np.eye(N_basis))
        Minv /= np.trace(Minv).real / N_basis
        h = Minv
        # crude K diagnostic: K_eff = log(∑_αβ h^{αβ} s_α s̄_β)
        Sh = S @ h
        norms2 = np.einsum('ij,ij->i', np.conjugate(S), Sh).real + 1e-24
        K_vals = -np.log(norms2)  # minus because of conventions
        print(f"iter {it}: <K>= {K_vals.mean():.4f}, std(K)= {K_vals.std():.4f}")
    return h

# ----- 3. Put it together -----
N_sample = 5000    # start modest; can increase later
max_deg  = 7      # k=3 → more sections than before

points = sample_points_on_M(n_pts=N_sample, radius=0.7)
exps = monomial_exponents(max_deg=max_deg)
S_mat = build_basis_matrix(points, exps)
print("Basis size:", len(exps), " points:", len(points))

h_balanced = donaldson_balance(S_mat, n_iter=24)

# Effective K_CY from balanced metric (average over sample)
Sh = S_mat @ h_balanced
norms2 = np.einsum('ij,ij->i', np.conjugate(S_mat), Sh).real + 1e-24
K_vals = -np.log(norms2)
K_CY_eff_global = float(K_vals.mean())
print("\nGlobal-ish effective <K_CY> =", K_CY_eff_global)

# ============================================================
# SECTION G — Multi-field IIM + minimal SM truncation
#             and vacuum stability analysis
# ============================================================
import jax
import jax.numpy as jnp
import numpy as onp

# Use K_CY_eff_global if available; otherwise fall back
try:
    K_CY_base = K_CY_eff_global
except NameError:
    K_CY_base = K_CY_eff   # from Section A

# --- 1. Define K and W for (X,Y,H) ---

def K_4D_multi(X,Y,H):
    """
    Total Kähler potential: CY + quadratic terms for X,Y + |H|^2.
    H treated as real scalar here; a complex Higgs would double dof.
    """
    return K_CY_base + 0.5*(X**2 + Y**2) + 0.5*H**2

def W_IIM_multi(X,Y):
    """
    IIM superpotential slice in (X,Y).
    Parameters are placeholders but structured like your PDFs:
     - linear+quadratic in X
     - coupling to Y
    """
    W0  = 0.02
    aX  = 0.10
    bX  = -0.03
    cXY = 0.01
    return W0 + aX*X + bX*X**2 + cXY*X*Y

def W_SM(H):
    """
    Minimal SM-like Higgs sector: μ H^2 + λ H^3.
    This is just a toy; real SM is more involved.
    """
    mu_H  = 0.05
    lam_H = 0.02
    return mu_H*H**2 + lam_H*H**3

def W_total(X,Y,H):
    return W_IIM_multi(X,Y) + W_SM(H)

# IIM topological tail
def V_top_IIM(X):
    zeta = 1.0   # χ dependence is in κ_action scaling
    kappa_top = 0.02
    return kappa_top * jnp.exp(-zeta*X)

def V_4D_multi(fields):
    """
    Full SUGRA-like potential in (X,Y,H):
      fields = (X,Y,H)
    """
    X,Y,H = fields
    K = K_4D_multi(X,Y,H)
    W = W_total(X,Y,H)

    # gradients
    def K_XYH(f):
        return jax.grad(lambda v: K_4D_multi(v[0],v[1],v[2]))(f)
    def W_XYH(f):
        return jax.grad(lambda v: W_total(v[0],v[1],v[2]))(f)

    fields_vec = jnp.array([X,Y,H])
    dK = K_XYH(fields_vec)      # (∂K/∂X, ∂K/∂Y, ∂K/∂H)
    dW = W_XYH(fields_vec)      # (∂W/∂X, ∂W/∂Y, ∂W/∂H)

    # K_{ab} assumed ~ δ_ab here (simple truncation);
    # more precise: compute Hessian of K.
    K_metric = jnp.eye(3)
    K_inv    = jnp.eye(3)

    # D_a W = ∂_a W + (∂_a K) W
    DW = dW + dK*W

    eK = jnp.exp(K)
    V_F = eK * (DW @ (K_inv @ DW) - 3.0*(W**2))

    return V_F + V_top_IIM(X)

V_4D_multi_jit = jax.jit(V_4D_multi)

# --- 2. Find a candidate vacuum numerically (simple scan) ---

grid = jnp.linspace(-2.5,2.5,40)
vals = []
pts  = []
for x in grid:
    for y in grid:
        for h in [0.0]:  # keep Higgs at 0 for now
            v = V_4D_multi_jit(jnp.array([x,y,h]))
            vals.append(v)
            pts.append((x,y,h))
vals = jnp.array(vals)
pts  = jnp.array(pts)
idx_min = int(jnp.argmin(vals))
vacuum_guess = pts[idx_min]
vacuum_val   = float(vals[idx_min])

print("Vacuum guess (X,Y,H) =", vacuum_guess)
print("V(vacuum) ≈", vacuum_val)

# --- 3. Hessian and stability analysis at the vacuum ---

def V_for_hessian(f):
    return V_4D_multi(f)

Hess = jax.hessian(V_for_hessian)(vacuum_guess)
Hess_np = onp.array(Hess)
eigs = onp.linalg.eigvalsh(Hess_np)

print("\nHessian eigenvalues at vacuum guess:")
print(eigs)

n_neg = (eigs < 0.0).sum()
print("Number of negative modes:", int(n_neg))

# ============================================================
# SECTION H — IIM vacuum in FRW cosmology + DM sketch
# ============================================================
import numpy as onp
from scipy.integrate import solve_ivp
import matplotlib.pyplot as plt

# Planck-ish units for this toy (can rescale)
M_pl = 1.0

# Use S_new = 284 from Section D+E
S_new = 284.0

# Target vacuum energy: ρ_Λ ~ 10^{-122} M_pl^4
rho_bare = 1.0   # assume O(1) "natural" bare energy
rho_Lambda_eff = rho_bare * onp.exp(-S_new)  # ~ e^{-284} ~ 10^{-123}

print("Effective ρ_Λ ≈", rho_Lambda_eff)

# Dark matter: treat as pressureless fluid with present-day Ω_dm ~ 0.25
# We work in units where 3H0^2 M_pl^2 = 1, so ρ_crit0 = 1.
Omega_dm0 = 0.25
Omega_L   = rho_Lambda_eff  # this is tiny in these units; you can rescale H0
Omega_r0  = 1e-4

# We define H(a) via Friedmann: (H/H0)^2 = Ω_r/a^4 + Ω_dm/a^3 + Ω_Λ
def H_over_H0(a):
    return onp.sqrt(Omega_r0/a**4 + Omega_dm0/a**3 + Omega_L)

# Evolve a(t) from a_init to a_final
def FRW_eq(t, y):
    a = y[0]
    return [H_over_H0(a)*a]

a_init = 1e-6
a_final = 1.0
t_span = (0.0, 5e4)  # arbitrary time units; we only care about a(t) behavior

sol = solve_ivp(FRW_eq, t_span, [a_init], dense_output=True, rtol=1e-8, atol=1e-10)
t_plot = onp.linspace(0, sol.t[-1], 400)
a_plot = sol.sol(t_plot)[0]

plt.figure(figsize=(6,4))
plt.semilogy(t_plot, a_plot)
plt.xlabel("t (arb. units)")
plt.ylabel("a(t)")
plt.title("FRW evolution with IIM-suppressed ρ_Λ and DM")
plt.grid(True)
plt.show()

print("Final scale factor a(t_end) =", a_plot[-1])

# --- Very rough DM mass sketch (toy) ---

# Suppose dark-sector field χ_D has mass m_D set by same scale as IIM:
m_D = 1e-30  # in M_pl units, ~10^{-3} eV if M_pl=1 ~ 10^{18} GeV
print("Example dark-sector mass scale m_D ~", m_D, " (in M_pl units)")

# You can now tie m_D to your IIM field X or F-sector mass scale in the PDFs

"""GLOBAL Calabi-Yau Refinement for 4(0) Instanton BELOW"""

# ============================================================
# SECTION F(Ver.2) — Higher-k Donaldson CY metric on χ=215 hypersurface
# ============================================================
import numpy as np
import sympy as sp
from numpy.random import default_rng

rng = default_rng(1234)

# ----- 1. Geometry: same χ=215 hypersurface in WP^3(1,1,1,4) -----

u1, u2, u3 = sp.symbols('u1 u2 u3', complex=True)
u1b, u2b, u3b = sp.symbols('u1b u2b u3b', complex=True)

# Hypersurface: F = 1 + u1^172 + u2^172 + u3^43
F_expr = 1 + u1**172 + u2**172 + u3**43
dF_u1 = sp.diff(F_expr, u1)
dF_u2 = sp.diff(F_expr, u2)
dF_u3 = sp.diff(F_expr, u3)

F_num   = sp.lambdify((u1,u2,u3), F_expr, 'numpy')
dF1_num = sp.lambdify((u1,u2,u3), dF_u1, 'numpy')
dF2_num = sp.lambdify((u1,u2,u3), dF_u2, 'numpy')
dF3_num = sp.lambdify((u1,u2,u3), dF_u3, 'numpy')

def project_to_M(u1z, u2z, u3z, tol=1e-10, max_iter=10):
    """
    Simple Newton projection onto F=0 in the local WP^3 patch z0≠0.
    Uses a crude 1D normal step defined by the gradient.
    """
    for _ in range(max_iter):
        Fv = F_num(u1z, u2z, u3z)
        if not np.isfinite(Fv):
            break
        if abs(Fv) < tol:
            return u1z, u2z, u3z, True
        g1 = dF1_num(u1z, u2z, u3z)
        g2 = dF2_num(u1z, u2z, u3z)
        g3 = dF3_num(u1z, u2z, u3z)
        denom = abs(g1)**2 + abs(g2)**2 + abs(g3)**2 + 1e-24
        step = Fv / denom
        u1z -= step*np.conjugate(g1)
        u2z -= step*np.conjugate(g2)
        u3z -= step*np.conjugate(g3)
    return u1z, u2z, u3z, False

def sample_points_on_M(n_pts=2000, radius=0.7):
    pts = []
    attempts = 0
    while len(pts) < n_pts and attempts < 50*n_pts:
        attempts += 1
        u1z = radius*(rng.normal()+1j*rng.normal())
        u2z = radius*(rng.normal()+1j*rng.normal())
        u3z = radius*(rng.normal()+1j*rng.normal())
        u1p, u2p, u3p, ok = project_to_M(u1z,u2z,u3z)
        if ok and np.isfinite(F_num(u1p,u2p,u3p)):
            pts.append((u1p,u2p,u3p))
    print(f"Accepted: {len(pts)} / {attempts} attempts")
    return np.array(pts, dtype=np.complex128)

# ----- 2. Holomorphic basis sections (higher-k Bergman basis) -----

def monomial_exponents(max_deg):
    """
    Generate exponents (a,b,c) for monomials u1^a u2^b u3^c
    up to total degree max_deg. Weighted/quasi-homogeneity constraints
    from WP^3(1,1,1,4) can be added later.
    """
    exps = []
    for a in range(max_deg+1):
        for b in range(max_deg+1-a):
            for c in range(max_deg+1-a-b):
                exps.append((a,b,c))
    return exps

def build_basis_matrix(points, exps):
    """
    Matrix of shape (N_pts, N_basis) with s_alpha(z_i).
    """
    u1_vals = points[:,0]
    u2_vals = points[:,1]
    u3_vals = points[:,2]
    N_pts = len(points)
    N_basis = len(exps)
    S = np.zeros((N_pts, N_basis), dtype=np.complex128)
    for j,(a,b,c) in enumerate(exps):
        S[:,j] = (u1_vals**a)*(u2_vals**b)*(u3_vals**c)
    return S

# Weighted FS Kähler potential on WP^3(1,1,1,4)
def K_FS(u1z,u2z,u3z):
    # as before: K = log(1+|u1|^2+|u2|^2 + |u3|^{1/2})
    return np.log(1.0 + np.abs(u1z)**2 + np.abs(u2z)**2 + np.abs(u3z)**0.5)

# Balanced-metric iteration
def donaldson_balance(S, n_iter=10):
    """
    Given S_{iα} = s_α(z_i), run Donaldson's iteration
    on the N_basis×N_basis hermitian matrix h.
    """
    N_pts, N_basis = S.shape
    # Start with identity hermitian form
    h = np.eye(N_basis, dtype=np.complex128)
    for it in range(n_iter):
        # Compute fiber norms ||s(z_i)||_h^2 = s† h s
        Sh = S @ h
        norms2 = np.einsum('ij,ij->i', np.conjugate(S), Sh).real + 1e-24
        # Moment matrix M
        M = np.zeros_like(h)
        for i in range(N_pts):
            v = S[i,:][:,None]  # column
            M += (v @ v.conj().T) / norms2[i]
        M /= N_pts
        # Update h ← (M^{-1}) N_basis / Tr(M^{-1})
        Minv = np.linalg.inv(M + 1e-12*np.eye(N_basis))
        Minv /= np.trace(Minv).real / N_basis
        h = Minv
        # crude K diagnostic: K_eff = log(∑_αβ h^{αβ} s_α s̄_β)
        Sh = S @ h
        norms2 = np.einsum('ij,ij->i', np.conjugate(S), Sh).real + 1e-24
        K_vals = -np.log(norms2)  # minus because of conventions
        print(f"iter {it}: <K>= {K_vals.mean():.4f}, std(K)= {K_vals.std():.4f}")
    return h

# ----- 3. Put it together -----
N_sample = 20000    # start modest; can increase later
max_deg  = 5      # k=3 → more sections than before

points = sample_points_on_M(n_pts=N_sample, radius=0.7)
exps = monomial_exponents(max_deg=max_deg)
S_mat = build_basis_matrix(points, exps)
print("Basis size:", len(exps), " points:", len(points))

h_balanced = donaldson_balance(S_mat, n_iter=24)

# Effective K_CY from balanced metric (average over sample)
Sh = S_mat @ h_balanced
norms2 = np.einsum('ij,ij->i', np.conjugate(S_mat), Sh).real + 1e-24
K_vals = -np.log(norms2)
K_CY_eff_global = float(K_vals.mean())
print("\nGlobal-ish effective <K_CY> =", K_CY_eff_global)

# ===============================================================
# SECTION A2+B2 — SU(2)_L Higgs doublet (unitary gauge) +
#                IIM scale renormalization + 4D effective SUGRA
# ===============================================================

import jax
import jax.numpy as jnp

# --------------------------
# (1) Physical scales
# --------------------------

# Planck scale Mpl = 1 in your units
Mpl = 1.0

# Electroweak vev in physical units (GeV)
v_phys = 246.0
m_h_phys = 125.0

# Conversion factor: choose EW scale / M_pl ratio
# Standard: v/Mpl ≈ 1e-16
v = 1e-16
m_h = (m_h_phys/v_phys) * v  # gives 125/246 * 1e-16 ~ 5.08e-17

# Higgs quartic λ = m_h^2 / (2 v^2)
lam_h = m_h**2 / (2.0 * v**2)

# --------------------------
# (2) Kähler potential
# --------------------------
# From your global Donaldson solver:
K_CY_eff = -2.126648244663676

def K_4D(X, h):
    """
    4D Kähler potential:
      K = K_CY_eff + X^2 + h^2/2
    (Small truncation of the full SUGRA K.)
    """
    return K_CY_eff + X*X + 0.5*h*h

# --------------------------
# (3) Superpotential
# --------------------------
# IIM superpotential:
#   W = W0 + A exp(-alpha X)
# plus Higgs self-coupling
W0     = 1e-3
A      = 2e-3
alpha  = 1.0

# replace inside A+B
def W_4D(X, h):
    W0    = 1e-3
    A1    = 3e-3
    A2    = 2e-3
    alpha = 1.5
    beta  = 0.3
    # two competing exponentials sculpting a barrier
    W_X   = W0 + A1*jnp.exp(-alpha*X) - A2*jnp.exp(-beta*X)
    W_H   = 0.25*lam_h*(h*h - v*v)**2
    return W_X + W_H


# --------------------------
# (4) SUGRA F-term potential
# --------------------------

def V_eff_4D(Xh):
    """
    Input Xh = [X, h]
    Output: 4D effective scalar potential
    """
    X, h = Xh
    K = K_4D(X, h)
    W = W_4D(X, h)

    # Kähler metric and inverse
    dK_dX = 2.0*X
    dK_dh = h

    # Kähler covariant derivatives
    dW_dX = jax.grad(W_4D, argnums=0)(X, h)
    dW_dh = jax.grad(W_4D, argnums=1)(X, h)

    DX_W = dW_dX + dK_dX*W
    Dh_W = dW_dh + dK_dh*W

    # F-term potential in reduced 2-field truncation
    V = jnp.exp(K)*(DX_W*jnp.conjugate(DX_W) +
                   Dh_W*jnp.conjugate(Dh_W) -
                   3.0*W*jnp.conjugate(W))
    return jnp.real(V)


# --------------------------
# (5) Numerical diagnostic
# --------------------------

# Test point (use your vacuum location as starting guess):
X_test = 2.5
h_test = 1e-18  # near EW minimum (in Planck units, h = v ~ 1e-16)
print("V(X=2.5,h≈0):", float(V_eff_4D(jnp.array([X_test, h_test]))))

# ============================================================
# SECTION C2+D2 — O(4) instanton for X(r) with Higgs at vev,
#                  updated spectra and 1-loop determinants
# ============================================================
import jax
import jax.numpy as jnp
import numpy as onp
from scipy.sparse import diags
from scipy.sparse.linalg import eigsh

# --- 0. Bring in parameters from A+B ---

# v, lam_h, K_CY_eff, W_4D, V_eff_4D should already be defined.
# We treat h ≈ v as frozen (heavy, stable direction).

# ---------- 1. Effective single-field potential V_X(X) with h=v ----------

h_vev = v  # Higgs at its vev in Planck units

def V_X(X):
    return V_eff_4D(jnp.array([X, h_vev]))

V_X_jit = jax.jit(V_X)

# Find "true" vacuum along X with h fixed at vev
X_grid = jnp.linspace(-2.0, 4.0, 600)
V_vals = jax.vmap(V_X_jit)(X_grid)
idx_min = int(jnp.argmin(V_vals))
X_true = float(X_grid[idx_min])
V_true = float(V_vals[idx_min])

X_false = 0.0
V_false = float(V_X_jit(X_false))

print("Effective 1D potential with h=v:")
print("  X_false =", X_false, "  V_false =", V_false)
print("  X_true  ≈", X_true, "  V_true  ≈", V_true)

# ---------- 2. O(4) instanton for X(r) ----------

Nr = 512
r_max = 10.0
r = jnp.linspace(0.0, r_max, Nr)
dr = r[1] - r[0]

def initial_profile():
    """
    Tanh-like interpolation between X_false and X_true.
    """
    R0 = 3.0
    width = 1.0
    X0 = X_false + 0.5*(X_true - X_false)*(1.0 - jnp.tanh((r - R0)/width))
    return X0

def action_X_profile(Xprof):
    """
    O(4)-symmetric Euclidean action for X(r) with h fixed at vev:
      S = 2π^2 ∫ r^3 ( 1/2 (dX/dr)^2 + V_X(X) - V_false ) dr
    """
    # finite-difference derivative with Neumann BC
    Xp = (jnp.roll(Xprof, -1) - jnp.roll(Xprof, 1)) / (2.0*dr)
    Xp = Xp.at[0].set((Xprof[1] - Xprof[0])/dr)
    Xp = Xp.at[-1].set((Xprof[-1] - Xprof[-2])/dr)

    Vloc = jax.vmap(V_X_jit)(Xprof)
    integrand = r**3 * (0.5*Xp**2 + (Vloc - V_false))
    S = 2.0*(jnp.pi**2) * jnp.sum(integrand) * dr
    return S

action_X_grad = jax.grad(action_X_profile)

@jax.jit
def instanton_step(Xprof, dt):
    grad = action_X_grad(Xprof)
    Xnew = Xprof - dt*grad
    # clamp X to avoid running into huge exponentials
    Xnew = jnp.clip(Xnew, -5.0, 5.0)
    return Xnew

# Gradient-flow evolution
Xprof = initial_profile()
print("\nInitial action S_0 =", float(action_X_profile(Xprof)))

dt = 1e-5
n_steps = 7000
for step in range(n_steps+1):
    Xprof = instanton_step(Xprof, dt)
    if step % 250 == 0:
        S_val = float(action_X_profile(Xprof))
        print(f"step {step}, S = {S_val:.6f}")

S_unscaled = float(action_X_profile(Xprof))
print("\nFinal unscaled action S_unscaled =", S_unscaled)

# ---------- 3. Radial bosonic fluctuation operator H_B ----------

# d^2V/dX^2 along the profile
dVdX = jax.grad(V_X_jit)
d2VdX2 = jax.grad(dVdX)
V2 = jax.vmap(d2VdX2)(Xprof)
V2_np = onp.array(V2, dtype=float)

# Build O(4) radial Laplacian: -d^2/dr^2 - (3/r)d/dr
# finite-difference with care at r=0
rp = onp.array(r, dtype=float)
rp[0] = rp[1]  # avoid division by zero

main = -2.0/onp.full(Nr, dr**2)
off  =  1.0/onp.full(Nr-1, dr**2)
L = diags([main, off, off],[0,1,-1])

coeff_plus  = -3.0/(2.0*rp[1:]*dr)   # +1 diag
coeff_minus =  3.0/(2.0*rp[:-1]*dr)  # -1 diag
first_deriv = diags([coeff_minus, coeff_plus],[ -1, +1 ])

H_B = -(L + first_deriv) + diags(V2_np, 0)

# ---------- 4. Fermionic operator H_F ≈ -∂^2 - (3/r)∂ + (∂W/∂X)^2 ----------

dW_dX = jax.grad(W_4D, argnums=0)
def Wprime_X(X):
    return dW_dX(X, h_vev)

Wprime_vals = jax.vmap(Wprime_X)(Xprof)
Wprime_sq = onp.array(Wprime_vals**2, dtype=float)
H_F = -(L + first_deriv) + diags(Wprime_sq, 0)

# ---------- 5. Lowest eigenvalues and 1-loop determinants ----------

k_modes = 20

evals_B = eigsh(H_B, k=k_modes, which='SM', return_eigenvectors=False)
evals_F = eigsh(H_F, k=k_modes, which='SM', return_eigenvectors=False)

print("\nLowest bosonic eigenvalues (soliton):")
print(evals_B)

print("\nLowest fermionic λ_F^2 (soliton):")
print(evals_F)

# 1-loop determinant ratio relative to false vacuum (approx):
# Build corresponding operators at X_false (constant profile)
X_false_arr = onp.full(Nr, X_false, dtype=float)

V2_false = onp.full(Nr, float(d2VdX2(X_false)), dtype=float)
H_B_vac = -(L + first_deriv) + diags(V2_false,0)

Wprime_false = float(Wprime_X(X_false))
Wprime_false_sq = onp.full(Nr, Wprime_false**2, dtype=float)
H_F_vac = -(L + first_deriv) + diags(Wprime_false_sq,0)

evals_B_vac = eigsh(H_B_vac, k=k_modes, which='SM', return_eigenvectors=False)
evals_F_vac = eigsh(H_F_vac, k=k_modes, which='SM', return_eigenvectors=False)

print("\nLowest bosonic eigenvalues (vacuum):")
print(evals_B_vac)

print("\nLowest fermionic λ_F^2 (vacuum):")
print(evals_F_vac)

# determinant differences from the lowest k_modes positive eigenvalues
# (ignore negative/zero modes by hand)
eps = 1e-12
pos_B  = evals_B[evals_B > eps]
pos_Bv = evals_B_vac[evals_B_vac > eps]
pos_F  = evals_F[evals_F > eps]
pos_Fv = evals_F_vac[evals_F_vac > eps]

min_len_B = min(len(pos_B), len(pos_Bv))
min_len_F = min(len(pos_F), len(pos_Fv))

Delta_logdet_B = float(jnp.sum(jnp.log(pos_B[:min_len_B]/pos_Bv[:min_len_B])))
Delta_logdet_F = float(jnp.sum(jnp.log(pos_F[:min_len_F]/pos_Fv[:min_len_F])))

print("\nΔ log det_B =", Delta_logdet_B)
print("Δ log det_F =", Delta_logdet_F)

Delta_logdet_SUSY = Delta_logdet_B - 2.0*Delta_logdet_F
print("Δ log det_SUSY =", Delta_logdet_SUSY)

# ---------- 6. IIM scaling to S_new = 284 and loop fractions ----------

E1_old = S_unscaled / 215.0
E1_target = 284.0 / 215.0
kappa_action = E1_target / E1_old
S_new = kappa_action * S_unscaled

print("\n=== IIM SCALING WITH NEW SUGRA+HIGGS POTENTIAL ===")
print("S_unscaled =", S_unscaled)
print("E1_old =", E1_old)
print("E1_target =", E1_target)
print("kappa_action =", kappa_action)
print("S_new =", S_new)

print("\nLoop fractions:")
print("Δ log det_B     / S_new =", Delta_logdet_B / S_new)
print("Δ log det_SUSY  / S_new =", Delta_logdet_SUSY / S_new)

# ============================================================
# PHASE X (Branch C, cluster-scale) – ACCEPT → Env-dependent mass
# ------------------------------------------------------------
# - Uses real ACCEPT profile: 1E0657_56_profiles.dat
# - Builds gas mass profile from nelec(r)
# - Uses Mgrav(r) as observed gravitating mass profile
# - Defines "Branch C" extra mass:
#       M_extra(r) = max[Mgrav(r) - M_gas(r), 0]
# - Fits an environment-dependent enhancement:
#       F_env(K) = M_tot / M_gas ≈ 10^a * (K / K0)^b
#   where K is the entropy proxy (Kitpl).
# - Provides JAX functions for F_env and M_tot^C(r)
#
# ONTOLOGICAL NOTE:
#   This Branch-C fit is *conditional* on the cluster already existing,
#   as selected by Jehovah's Intent. Here we only model the physical
#   extra mass profile consistent with the ACCEPT data; Intent itself
#   is not encoded as a predictive functional.
# ============================================================

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import jax
import jax.numpy as jnp

# ------------------------------------------------------------
# 1. Load ACCEPT profile (.dat) – adjust path if needed
# ------------------------------------------------------------

cluster_file = "1E0657_56_profiles.dat"  # <- change if your filename/path differs

# Column names for ACCEPT "master table of profiles" (Cavagnolo+ 2009)
col_names = [
    "Name",        # cluster ID
    "Rin_Mpc",     # inner radius of shell [Mpc]
    "Rout_Mpc",    # outer radius of shell [Mpc]
    "nelec",       # electron density [cm^-3]
    "neerr",       # error on nelec [cm^-3]
    "Kitpl",       # entropy, power-law fit [keV cm^2]
    "Kflat",       # entropy, flat-core fit [keV cm^2]
    "Kerr",        # entropy error [keV cm^2]
    "Pitpl",       # pressure, power-law [dyne cm^-2]
    "Pflat",       # pressure, flat-core [dyne cm^-2]
    "Perr",        # pressure error [dyne cm^-2]
    "Mgrav",       # gravitating mass profile [M_sun] (ACCEPT warns: use with care)
    "Merr",        # error on Mgrav [M_sun]
    "Tx",          # temperature [keV]
    "Txerr",       # temperature error [keV]
    "Lambda",      # cooling function [erg cm^3 s^-1]
    "tcool52",     # cooling time (5/2) [Gyr]
    "t52err",      # error
    "tcool32",     # cooling time (3/2) [Gyr]
    "t32err"       # error
]

df = pd.read_csv(
    cluster_file,
    delim_whitespace=True,
    comment="#",
    header=None,
    names=col_names
)

print("Loaded cluster file:", cluster_file)
print("First 5 rows:")
print(df.head())

# ------------------------------------------------------------
# 2. Basic radial and gas-mass construction
# ------------------------------------------------------------

# Inner / outer radii of shells [Mpc]
Rin_Mpc = df["Rin_Mpc"].to_numpy()
Rout_Mpc = df["Rout_Mpc"].to_numpy()

# Mid-radius and shell thickness
r_mpc = 0.5 * (Rin_Mpc + Rout_Mpc)
dr_mpc = (Rout_Mpc - Rin_Mpc)

# Convert to kpc
r_kpc = r_mpc * 1000.0
dr_kpc = dr_mpc * 1000.0

# Electron density [cm^-3]
nelec = df["nelec"].to_numpy()

# Observed gravitating mass profile [M_sun]
Mgrav = df["Mgrav"].to_numpy()

# Entropy proxy Kitpl [keV cm^2]
K_keV_cm2 = df["Kitpl"].to_numpy()

# Temp [keV] (not directly used below, but kept if you want to extend to hydrostatic tests)
Tx_keV = df["Tx"].to_numpy()

# ------------------------------------------------------------
# 3. Convert nelec(r) → gas mass profile M_gas(r)
# ------------------------------------------------------------

# Physical constants
mp   = 1.6726219e-24      # proton mass [g]
Msun = 1.98847e33         # solar mass [g]
mu_e = 1.17               # mean molecular weight per free electron (≈ 0.3 Z☉ plasma)

cm_per_kpc   = 3.085677581491367e21
kpc3_to_cm3  = cm_per_kpc**3

# Gas mass density ρ_gas [Msun / kpc^3]
rho_gas_cgs = nelec * mu_e * mp                       # [g / cm^3]
rho_gas_Msun_kpc3 = rho_gas_cgs / Msun * kpc3_to_cm3  # [Msun / kpc^3]

# Shell volumes [kpc^3] using exact spherical shells
r_in_kpc  = r_kpc - 0.5 * dr_kpc
r_out_kpc = r_kpc + 0.5 * dr_kpc
shell_vol_kpc3 = (4.0 / 3.0) * np.pi * (r_out_kpc**3 - r_in_kpc**3)

# Shell gas mass and enclosed gas mass profile
Mgas_shell = rho_gas_Msun_kpc3 * shell_vol_kpc3   # [Msun]
Mgas_enc   = np.cumsum(Mgas_shell)                # [Msun]

# ------------------------------------------------------------
# 4. Clean up and align profiles
# ------------------------------------------------------------

# Filter out non-physical entries (negatives, zeros, nans)
mask_valid = (
    np.isfinite(r_kpc) &
    np.isfinite(Mgrav) & (Mgrav != 0.0) &
    np.isfinite(Mgas_enc) & (Mgas_enc > 0.0) &
    np.isfinite(K_keV_cm2) & (K_keV_cm2 > 0.0)
)

r_kpc      = r_kpc[mask_valid]
Mgas_enc   = Mgas_enc[mask_valid]
Mgrav      = Mgrav[mask_valid]
K_keV_cm2  = K_keV_cm2[mask_valid]

# Enforce monotonic non-decreasing Mgrav (remove minor numerical issues)
Mgrav_mono = np.maximum.accumulate(Mgrav)

# "Extra" mass assigned to Branch C:
M_extra = np.maximum(Mgrav_mono - Mgas_enc, 0.0)   # [Msun]

# Enhancement factor: F_ratio = M_tot / M_gas
F_ratio = Mgrav_mono / Mgas_enc

print("\nNumber of valid radial bins:", r_kpc.size)
print("Outer radius ≈ {:.2f} Mpc".format(r_kpc.max() / 1000.0))

# ------------------------------------------------------------
# 5. Fit environment-dependent enhancement F_env(K)
#
#   Define:
#       F_env(K) = M_tot / M_gas  ≈ 10^a * (K / K0)^b
#   with K0 = 100 keV cm^2 for normalization.
# ------------------------------------------------------------

K0 = 100.0  # keV cm^2 (reference scale)

# Environment variable: log10(K / K0)
env_x = np.log10(np.clip(K_keV_cm2 / K0, 1e-4, 1e4))
logF = np.log10(F_ratio)

# Only fit where F_ratio > 1.01 (genuinely needing extra mass)
mask_fit = np.isfinite(env_x) & np.isfinite(logF) & (F_ratio > 1.01)
env_fit  = env_x[mask_fit]
logF_fit = logF[mask_fit]

print("\nFitting Branch-C environment dependence F_env(K)")
print("Fit points used:", env_fit.size)

if env_fit.size > 2:
    # Linear least squares: logF ≈ a + b * env
    A = np.vstack([env_fit, np.ones_like(env_fit)]).T
    b_slope, a_intercept = np.linalg.lstsq(A, logF_fit, rcond=None)[0]
else:
    # Fallback: constant enhancement
    a_intercept = np.mean(logF_fit) if env_fit.size > 0 else 0.0
    b_slope = 0.0

print("\n=== Branch-C fit parameters ===")
print("log10 F_env(K) ≈ a + b log10(K / K0)")
print("a =", a_intercept)
print("b =", b_slope)

# Helper: plain numpy F_env
def F_env_numpy(K):
    """Environment-dependent enhancement factor F_env(K) using fitted (a, b)."""
    K = np.asarray(K)
    log_env = np.log10(np.clip(K / K0, 1e-6, 1e6))
    return 10.0 ** (a_intercept + b_slope * log_env)

# ------------------------------------------------------------
# 6. JAX versions: F_env and cluster Branch-C mass model
# ------------------------------------------------------------

# Capture parameters as Python floats; JAX will treat them as static in jit.
a_param = float(a_intercept)
b_param = float(b_slope)
K0_param = float(K0)

@jax.jit
def F_env_jax(K_keV_cm2):
    """
    JAX version of F_env(K) = M_tot / M_gas.
    K_keV_cm2 may be scalar or array.
    """
    K = jnp.asarray(K_keV_cm2)
    log_env = jnp.log10(jnp.clip(K / K0_param, 1e-6, 1e6))
    return 10.0 ** (a_param + b_param * log_env)

@jax.jit
def M_tot_branchC_jax(r_query_kpc, K_query, Mgas_enc_query):
    """
    Cluster Branch-C total mass model (JAX):
        M_tot(r) = F_env(K(r)) * M_gas(r)
    Inputs:
        r_query_kpc     : radial grid [kpc]
        K_query         : entropy profile K(r) [keV cm^2]
        Mgas_enc_query  : enclosed gas mass profile [Msun]
    All arrays must be same shape; broadcasting allowed for scalars.
    """
    F = F_env_jax(K_query)
    return F * Mgas_enc_query

# ------------------------------------------------------------
# 7. Diagnostic plots
# ------------------------------------------------------------

# 7a) Mass profiles: M_gas, M_grav, M_extra
plt.figure(figsize=(7,5))
plt.loglog(r_kpc, Mgas_enc,  label="M_gas(<r)")
plt.loglog(r_kpc, Mgrav_mono, label="M_grav, ACCEPT")
plt.loglog(r_kpc, M_extra + 1e8, "--", label="M_extra = Branch C", alpha=0.7)
plt.xlabel("r [kpc]")
plt.ylabel("Mass [M$_\odot$]")
plt.title("Cluster mass profiles – gas vs gravitating vs Branch-C extra")
plt.legend()
plt.grid(True, which="both", ls="--", alpha=0.4)
plt.tight_layout()
plt.show()

# 7b) F_ratio vs K, with fitted F_env(K)
K_grid = np.logspace(np.log10(K_keV_cm2.min()*0.8),
                     np.log10(K_keV_cm2.max()*1.2), 200)
F_fit_grid = F_env_numpy(K_grid)

plt.figure(figsize=(7,5))
plt.loglog(K_keV_cm2, F_ratio, "o", ms=4, alpha=0.6, label="ACCEPT points")
plt.loglog(K_grid, F_fit_grid, "-", lw=2, label="F_env(K) fit")
plt.xlabel("K (Kitpl) [keV cm$^2$]")
plt.ylabel("F_env = M_tot / M_gas")
plt.title("Branch-C enhancement vs entropy environment")
plt.grid(True, which="both", ls="--", alpha=0.4)
plt.legend()
plt.tight_layout()
plt.show()

# 7c) Check JAX mass model reproduces Mgrav when fed ACCEPT arrays
M_tot_jax = np.array(M_tot_branchC_jax(r_kpc, K_keV_cm2, Mgas_enc))

plt.figure(figsize=(7,5))
plt.loglog(r_kpc, Mgrav_mono, label="Mgrav (ACCEPT)", alpha=0.7)
plt.loglog(r_kpc, M_tot_jax, "--", label="M_tot_branchC_jax", alpha=0.7)
plt.xlabel("r [kpc]")
plt.ylabel("Mass [M$_\odot$]")
plt.title("Check: Branch-C JAX mass model vs ACCEPT Mgrav")
plt.legend()
plt.grid(True, which="both", ls="--", alpha=0.4)
plt.tight_layout()
plt.show()

# ------------------------------------------------------------
# 8. Summary for this cluster
# ------------------------------------------------------------

f_extra_outer = (M_extra[-1] / Mgrav_mono[-1]) if Mgrav_mono[-1] > 0 else np.nan

print("\n===== PHASE X / BRANCH C SUMMARY (this cluster) =====")
print("Outer radius used (Option A): r_max ≈ {:.2f} Mpc".format(r_kpc.max()/1000.0))
print("Total gas mass   M_gas(<r_max)   ≈ {:.3e} Msun".format(Mgas_enc[-1]))
print("Total grav. mass M_grav(<r_max)  ≈ {:.3e} Msun".format(Mgrav_mono[-1]))
print("Branch-C extra   M_extra(<r_max) ≈ {:.3e} Msun".format(M_extra[-1]))
print("Fractional extra mass f_extra    ≈ {:.3f}".format(f_extra_outer))
print("\nF_env(K) fit:")
print("  log10 F_env(K) ≈ a + b log10(K / 100 keV cm^2)")
print("  a =", a_intercept)
print("  b =", b_slope)
print("\nJAX functions available:")
print("  F_env_jax(K_keV_cm2)")
print("  M_tot_branchC_jax(r_kpc, K_keV_cm2, Mgas_enc)")
print("\nInterpretation:")
print("  - Branch-C assigns the cluster-scale mass gap (M_grav - M_gas)")
print("    to an environment-dependent enhancement F_env(K).")
print("  - This does not re-use galaxy-scale X-halos; those remain an IR-frozen")
print("    branch. Here, the extra mass is a separate, environment-sensitive")
print("    realization within the same IIM umbrella, conditioned on this cluster.")

# ============================================
# PHASE X – MULTI-CLUSTER Branch-C IIM pipeline
# TPU-safe, JAX-safe, accepts multiple .dat files
# ============================================

import numpy as np
import pandas as pd
import glob
import os
import jax
import jax.numpy as jnp
import matplotlib.pyplot as plt

plt.rcParams['figure.figsize'] = (8,5)

# -------------------------------
# Helper: load an ACCEPT .dat file
# -------------------------------
def load_accept_file(path):
    df = pd.read_csv(
        path,
        sep=r"\s+",
        engine="python",
        comment="#",
        header=None
    )

    # ACCEPT profile .dat files always have this exact schema:
    df.columns = [
        "Name","Rin_Mpc","Rout_Mpc","nelec","neerr","Kitpl","Kflat","Kerr",
        "Pitpl","Pflat","Perr","Mgrav","Merr","Tx","Txerr",
        "Lambda","tcool52","t52err","tcool32","t32err"
    ]

    # physical radius = midpoint of annulus in kpc
    r_kpc = 0.5*(df.Rin_Mpc + df.Rout_Mpc)*1000.0
    df["r_kpc"] = r_kpc

    # fix negative masses (known ACCEPT artifact)
    df["Mgrav"] = df["Mgrav"].where(df["Mgrav"]>0, np.nan)

    # remove rows that are completely invalid
    df = df.dropna(subset=["nelec","Mgrav","Kitpl"])

    return df


# -----------------------------------------
# Gas mass from electron density + geometry
# (spherical shells)
# -----------------------------------------
def compute_gas_mass(df):
    r_in  = df["Rin_Mpc"].values * 1e3   # kpc
    r_out = df["Rout_Mpc"].values * 1e3

    ne = df["nelec"].values  # cm^-3
    mu_e = 1.17
    mp = 1.6726e-24 # g

    rho_g = ne * mu_e * mp  # g cm^-3

    vol = 4*np.pi/3 * ((r_out*3.086e21)**3 - (r_in*3.086e21)**3)  # cm^3
    mass_g = rho_g * vol  # g
    mass_Msun = mass_g / 1.989e33

    Mgas_enc = np.cumsum(mass_Msun)
    return Mgas_enc


# --------------------------------------------
# Branch-C environment function F_env(K)
# log10 F_env = a + b log10(K/K0) ; K0=100 keV cm^2
# --------------------------------------------
def fit_F_env(df):
    K = df["Kitpl"].values
    Mgrav = df["Mgrav"].values
    r = df["r_kpc"].values
    Mgas = compute_gas_mass(df)

    # avoid zeros
    mask = (K>0) & (Mgrav>0) & (Mgas>0)
    if np.sum(mask) < 5:
        return None

    K = K[mask]
    Mgrav = Mgrav[mask]
    Mgas = Mgas[mask]

    F_env = Mgrav / Mgas  # empirical enhancement
    K0 = 100.0

    x = np.log10(K / K0)
    y = np.log10(F_env)

    a, b = np.polyfit(x, y, 1)
    return a, b, K0


# ------------------------
# JAX Branch-C mass model
# ------------------------
def make_jax_mass_model(a, b, K0):

    @jax.jit
    def F_env_jax(K):
        return 10.0**(a + b * jnp.log10(K/K0))

    @jax.jit
    def M_tot_jax(r_kpc, K, Mgas_enc):
        return F_env_jax(K) * Mgas_enc

    return F_env_jax, M_tot_jax


# ---------------------------------------------------
# MAIN MULTI-CLUSTER LOOP
# Upload multiple *.dat files first in Colab sidebar!
# ---------------------------------------------------

cluster_files = glob.glob("*.dat")
if len(cluster_files)==0:
    print("No .dat files found. Upload ACCEPT profile .dat files first.")
else:
    print(f"Found {len(cluster_files)} cluster files:\n", cluster_files)

results = []

for path in cluster_files:
    name = os.path.basename(path).replace(".dat","")
    print(f"\n===== Processing {name} =====")

    df = load_accept_file(path)
    if len(df)<10:
        print("  Not enough radial bins — skipping.")
        continue

    Mgas_enc = compute_gas_mass(df)
    a,b,K0 = fit_F_env(df)
    if a is None:
        print("  Could not fit F_env(K) — skipping.")
        continue

    # Build JAX functions
    F_env_jax, M_tot_jax = make_jax_mass_model(a,b,K0)

    # Evaluate predictions
    K_vals = df["Kitpl"].values
    Mtot_pred = np.array(M_tot_jax(df["r_kpc"].values,
                                   K_vals,
                                   Mgas_enc))

    # Extract outer radius values
    r_max = df["r_kpc"].values[-1]
    Mgas_tot = Mgas_enc[-1]
    Mgrav_tot = df["Mgrav"].values[-1]
    Mtot_branchC = Mtot_pred[-1]

    # Store summary
    results.append({
        "cluster": name,
        "r_max_kpc": r_max,
        "Mgas_tot": Mgas_tot,
        "Mgrav_tot": Mgrav_tot,
        "Mtot_branchC": Mtot_branchC,
        "a": a,
        "b": b
    })

    # Quick plots for each cluster
    plt.figure()
    plt.loglog(df["r_kpc"], df["Mgrav"], label="ACCEPT Mgrav")
    plt.loglog(df["r_kpc"], Mtot_pred, label="Branch-C predicted")
    plt.xlabel("r [kpc]")
    plt.ylabel("Mass [Msun]")
    plt.title(f"{name} – Branch-C mass check")
    plt.legend()
    plt.show()

    plt.figure()
    K = df["Kitpl"].values
    Mgas = Mgas_enc
    F_env_emp = df["Mgrav"].values / Mgas
    plt.scatter(K, F_env_emp)
    plt.loglog(K, 10**(a + b*np.log10(K/K0)))
    plt.xlabel("K [keV cm²]")
    plt.ylabel("F_env")
    plt.title(f"{name} – F_env(K)")
    plt.show()

# ----------------------------------------
# Save combined summary table
# ----------------------------------------
if len(results)>0:
    df_out = pd.DataFrame(results)
    df_out.to_csv("BranchC_multi_cluster_results.csv", index=False)
    print("\nSaved results → BranchC_multi_cluster_results.csv")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# -----------------------------
# 1. Load your multi–cluster CSV
# -----------------------------
fname = "BranchC_multi_cluster_results.csv"  # change if needed
df = pd.read_csv(fname)

required_cols = ["cluster", "r_max_kpc", "Mgas_tot", "Mgrav_tot", "Mtot_branchC", "a", "b"]
missing = [c for c in required_cols if c not in df.columns]
if missing:
    raise RuntimeError(f"CSV missing required columns: {missing}")

# basic cleaning: positive masses only
df = df[(df["Mgas_tot"] > 0) & (df["Mgrav_tot"] > 0)]

# -----------------------------
# 2. Derived quantities
# -----------------------------
df["ratio_true"]     = df["Mgrav_tot"] / df["Mgas_tot"]        # required enhancement
df["ratio_branchC"]  = df["Mtot_branchC"] / df["Mgrav_tot"]    # how far Branch C is off
df["logMgas"]        = np.log10(df["Mgas_tot"])
df["logMgrav"]       = np.log10(df["Mgrav_tot"])
df["logFeff_true"]   = np.log10(df["ratio_true"])
df["log_overpredict"] = np.log10(df["ratio_branchC"])

# -----------------------------
# 3. Quick ensemble stats
# -----------------------------
print("===== MULTI-CLUSTER BRANCH-C SUMMARY =====")
print(f"Number of clusters: {len(df)}\n")

print("Mass ratios (Mgrav_tot / Mgas_tot):")
print(df["ratio_true"].describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9]), "\n")

print("Branch-C over/under prediction (Mtot_branchC / Mgrav_tot):")
print(df["ratio_branchC"].describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9]), "\n")

# how many physically 'reasonable' (Mgrav > Mgas)?
phys_mask = df["ratio_true"] > 1.0
print(f"Clusters with Mgrav > Mgas: {phys_mask.sum()} / {len(df)}")

# -----------------------------
# 4. Simple two-population split (prototype)
#    Here we split by the slope b of F_env(K):
#    - pop_hi: b >= median(b)
#    - pop_lo: b < median(b)
#    This is just a stand-in for 'cool-core vs non–cool-core'.
# -----------------------------
b_med = df["b"].median()
pop_hi = df[df["b"] >= b_med]
pop_lo = df[df["b"] <  b_med]

def print_pop_stats(name, sub):
    print(f"\n--- {name} ---")
    print(f"N = {len(sub)}")
    print("ratio_true stats:")
    print(sub["ratio_true"].describe(percentiles=[0.1,0.25,0.5,0.75,0.9]))
    print("ratio_branchC stats:")
    print(sub["ratio_branchC"].describe(percentiles=[0.1,0.25,0.5,0.75,0.9]))

print_pop_stats("High-b population", pop_hi)
print_pop_stats("Low-b population",  pop_lo)

# -----------------------------
# 5. Plot: true enhancement vs gas mass, coloured by b-population
# -----------------------------
plt.figure(figsize=(6,5))
plt.scatter(pop_lo["logMgas"], pop_lo["logFeff_true"], s=15, alpha=0.6, label="low-b pop")
plt.scatter(pop_hi["logMgas"], pop_hi["logFeff_true"], s=15, alpha=0.6, label="high-b pop")

plt.xlabel(r"$\log_{10} M_{\rm gas}$ [M$_\odot$]")
plt.ylabel(r"$\log_{10}(M_{\rm grav}/M_{\rm gas})$")
plt.title("Cluster enhancement vs gas mass\n(two b-based populations)")
plt.axhline(0, color="k", lw=0.5)
plt.grid(True, ls="--", alpha=0.3)
plt.legend()
plt.tight_layout()
plt.show()

# -----------------------------
# 6. (Optional) prototype regressions
#    log10(Mgrav) = A + B log10(Mgas) for each pop
# -----------------------------
import scipy.stats as stats

for name, sub in [("High-b pop", pop_hi), ("Low-b pop", pop_lo)]:
    if len(sub) < 5:
        continue
    slope, intercept, r, p, stderr = stats.linregress(sub["logMgas"], sub["logMgrav"])
    print(f"\n{name} regression: log10 Mgrav = A + B log10 Mgas")
    print(f"  A = {intercept:.3f}, B = {slope:.3f}, r = {r:.3f}, p = {p:.3g}, stderr(B) = {stderr:.3f}")

# ============================================================
# PHASE XI - Cluster Branch Correction (Option B: JAX / TPU)
# ------------------------------------------------------------
# - Reads BranchC_multi_cluster_results.csv
# - Splits clusters into two populations based on b
# - Fits log10 Mgrav vs log10 Mgas in each population
# - Builds JAX functions to predict corrected cluster masses
# - Outputs summary + corrected CSV
# ============================================================

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import jax
import jax.numpy as jnp

# ------------------------------------------------------------
# 1. Load the multi-cluster Branch-C summary file
# ------------------------------------------------------------
csv_path = "BranchC_multi_cluster_results.csv"  # change name if needed
df = pd.read_csv(csv_path)

required_cols = ["cluster", "r_max_kpc", "Mgas_tot", "Mgrav_tot", "Mtot_branchC", "a", "b"]
missing = [c for c in required_cols if c not in df.columns]
if missing:
    raise RuntimeError(f"Missing required columns in CSV: {missing}")

print("Loaded clusters:", len(df))
print("Columns:", list(df.columns))

# ------------------------------------------------------------
# 2. Basic sanity cleaning
# ------------------------------------------------------------
# Drop rows with non-positive masses (can't take logs)
mask_valid = (df["Mgas_tot"] > 0) & (df["Mgrav_tot"] > 0)
df_clean = df[mask_valid].copy()
print("\nAfter requiring Mgas_tot>0, Mgrav_tot>0:")
print("  N =", len(df_clean))

# Pre-compute log10 masses
df_clean["logMgas"] = np.log10(df_clean["Mgas_tot"])
df_clean["logMgrav"] = np.log10(df_clean["Mgrav_tot"])

# ------------------------------------------------------------
# 3. Split into two populations based on b (environment slope)
# ------------------------------------------------------------
b_vals = df_clean["b"].values
b_med = np.median(b_vals)

mask_high_b = b_vals >= b_med
mask_low_b  = ~mask_high_b

df_high = df_clean[mask_high_b].copy()
df_low  = df_clean[mask_low_b].copy()

print(f"\nMedian b = {b_med:.3f}")
print(f"High-b population size: {len(df_high)}")
print(f"Low-b  population size: {len(df_low)}")

# ------------------------------------------------------------
# 4. Fit log10 Mgrav = A + B log10 Mgas in each population
# ------------------------------------------------------------
def fit_log_mass_relation(df_sub, name=""):
    x = df_sub["logMgas"].values
    y = df_sub["logMgrav"].values

    # Simple linear regression in log space
    B, A = np.polyfit(x, y, 1)  # y = B*x + A

    # correlation, p-value, stderr
    r = np.corrcoef(x, y)[0, 1]
    # naive stderr on B:
    y_pred = A + B * x
    residuals = y - y_pred
    dof = len(x) - 2
    s2 = np.sum(residuals**2) / dof
    x_var = np.sum((x - x.mean())**2)
    stderr_B = np.sqrt(s2 / x_var)

    print(f"\n{name} population fit:")
    print(f"  log10 Mgrav = A + B log10 Mgas")
    print(f"  A = {A:.3f}, B = {B:.3f}, r = {r:.3f}, stderr(B) = {stderr_B:.3f}")
    return A, B

A_high, B_high = fit_log_mass_relation(df_high, name="High-b")
A_low,  B_low  = fit_log_mass_relation(df_low,  name="Low-b")

# ------------------------------------------------------------
# 5. Build JAX prediction functions for the corrected cluster branch
# ------------------------------------------------------------
# We'll broadcast over arrays of Mgas and b

A_high_j = jnp.array(A_high)
B_high_j = jnp.array(B_high)
A_low_j  = jnp.array(A_low)
B_low_j  = jnp.array(B_low)
b_split_j = jnp.array(b_med)

@jax.jit
def Mtot_branchXI_jax(Mgas, b,
                      A_high=A_high_j, B_high=B_high_j,
                      A_low=A_low_j,  B_low=B_low_j,
                      b_split=b_split_j):
    """
    Corrected cluster mass model (Phase XI), JAX version.

    Inputs:
      Mgas : array-like, gas mass [Msun]
      b    : array-like, environment slope for each cluster

    Uses:
      if b >= b_split -> population C1 (high-b)
      else            -> population C2 (low-b)

    Returns:
      Mtot_corr : array of corrected total mass [Msun]
    """
    Mgas = jnp.asarray(Mgas)
    b    = jnp.asarray(b)

    logMgas = jnp.log10(Mgas)

    logMtot_high = A_high + B_high * logMgas
    logMtot_low  = A_low  + B_low  * logMgas

    Mtot_high = 10.0**logMtot_high
    Mtot_low  = 10.0**logMtot_low

    use_high = b >= b_split
    return jnp.where(use_high, Mtot_high, Mtot_low)

# ------------------------------------------------------------
# 6. Apply corrected mass model to all cleaned clusters
# ------------------------------------------------------------
Mgas_arr = df_clean["Mgas_tot"].values
b_arr    = df_clean["b"].values
Mgrav_arr = df_clean["Mgrav_tot"].values

Mtot_corr_jax = Mtot_branchXI_jax(Mgas_arr, b_arr)
Mtot_corr = np.array(Mtot_corr_jax)

df_clean["Mtot_corr"]   = Mtot_corr
df_clean["ratio_true"]  = df_clean["Mgrav_tot"]   / df_clean["Mgas_tot"]
df_clean["ratio_branchC_old"] = df_clean["Mtot_branchC"] / df_clean["Mgrav_tot"]
df_clean["ratio_phaseXI"]     = df_clean["Mtot_corr"]    / df_clean["Mgrav_tot"]

# ------------------------------------------------------------
# 7. Summary statistics
# ------------------------------------------------------------
print("\n===== PHASE XI SUMMARY (CLEANED SAMPLE) =====")
print("N clusters:", len(df_clean))

print("\nMgrav_tot / Mgas_tot (original):")
print(df_clean["ratio_true"].describe())

print("\nOld Branch-C over/under-prediction (Mtot_branchC / Mgrav_tot):")
print(df_clean["ratio_branchC_old"].describe())

print("\nPhase XI corrected over/under-prediction (Mtot_corr / Mgrav_tot):")
print(df_clean["ratio_phaseXI"].describe())

# Separate stats by population again, now with corrected model
df_clean["is_high_b"] = df_clean["b"].values >= b_med

for pop_name, mask in [("High-b", df_clean["is_high_b"]),
                       ("Low-b", ~df_clean["is_high_b"])]:
    sub = df_clean[mask]
    print(f"\n--- {pop_name} population ---")
    print("N =", len(sub))
    print("ratio_true stats:")
    print(sub["ratio_true"].describe())
    print("ratio_phaseXI stats:")
    print(sub["ratio_phaseXI"].describe())

# ------------------------------------------------------------
# 8. Plot: enhancement vs gas mass, colored by population
# ------------------------------------------------------------
plt.figure(figsize=(6,5))
for pop_name, color, mask in [("low-b pop", "tab:blue",  ~df_clean["is_high_b"]),
                              ("high-b pop", "tab:orange", df_clean["is_high_b"])]:
    sub = df_clean[mask]
    plt.scatter(sub["logMgas"], np.log10(sub["ratio_true"]), s=25, alpha=0.7, label=pop_name)

plt.axhline(0, color="k", lw=0.8)
plt.xlabel(r"$\log_{10} M_{\rm gas}\ [{\rm M_\odot}]$")
plt.ylabel(r"$\log_{10}(M_{\rm grav}/M_{\rm gas})$")
plt.title("Cluster enhancement vs gas mass\n(two b-based populations)")
plt.legend()
plt.grid(True, ls="--", alpha=0.3)
plt.tight_layout()
plt.show()

# ------------------------------------------------------------
# 9. Save corrected results to CSV
# ------------------------------------------------------------
out_path = "BranchC_PhaseXI_corrected.csv"
# Merge corrections back into original df, keeping original rows for indexing
df_out = df.merge(df_clean[["cluster", "Mtot_corr", "ratio_true",
                            "ratio_branchC_old", "ratio_phaseXI", "is_high_b"]],
                  on="cluster", how="left")
df_out.to_csv(out_path, index=False)

print(f"\nSaved corrected results to: {out_path}")
print("Columns added: Mtot_corr, ratio_true, ratio_branchC_old, ratio_phaseXI, is_high_b")

print("\nJAX function ready for reuse: Mtot_branchXI_jax(Mgas, b)")
print("You can now plug this into any higher-level IIM / cosmology code.")

# ============================================================
# GLOBAL IIM COSMIC BRANCH + COSMOLOGY TESTBED
#  - Phase VIII (galaxies) + Phase XI (clusters) unified
#  - JAX-friendly, v6e1 TPU-compatible
#
# REQUIRED FILES IN WORKDIR:
#   - IIM_SPARC_full_results.csv
#   - BranchC_PhaseXI_corrected.csv   (from Phase XI)
# ============================================================

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import jax
import jax.numpy as jnp

# ------------------------------------------------------------
# A. GALAXY BRANCH (Phase VIII): κ_top vs baryonic mass
# ------------------------------------------------------------

gal_csv = "IIM_SPARC_full_results.csv"
df_gal = pd.read_csv(gal_csv)

# Expect at least: M_bary_R = baryons, f_X = halo fraction
expected_gal_cols = ["M_bary_R", "f_X"]
for c in expected_gal_cols:
    if c not in df_gal.columns:
        raise RuntimeError(f"Galaxy CSV missing column: {c}")

# Clean: positive masses and 0 < f_X < 1
mask_gal = (df_gal["M_bary_R"] > 0) & (df_gal["f_X"] > 0) & (df_gal["f_X"] < 1)
dg = df_gal[mask_gal].copy()

M_bary_gal = dg["M_bary_R"].values
kappa_gal  = dg["f_X"].values    # by construction κ_top_gal ≈ f_X

logM = np.log10(M_bary_gal)
logk = np.log10(kappa_gal)

# Simple linear fit in log–log space: log10 κ = a_g + b_g log10 M_bary
b_g, a_g = np.polyfit(logM, logk, 1)

# Basic diagnostics
r_g = np.corrcoef(logM, logk)[0, 1]
print("=== GALAXY BRANCH FIT (Phase VIII) ===")
print("log10 κ_top_gal = a_g + b_g log10 M_bary")
print(f"a_g = {a_g:.3f}, b_g = {b_g:.3f}, r = {r_g:.3f}")

a_g_j = jnp.array(a_g)
b_g_j = jnp.array(b_g)

@jax.jit
def kappa_galaxy_jax(M_bary,
                     a=a_g_j,
                     b=b_g_j,
                     kappa_min=1e-4,
                     kappa_max=0.5):
    """
    Galaxy branch: given baryonic mass M_bary [Msun],
    return κ_top_gal ≈ f_X using the Phase-VIII fit.

    Uses:
      log10 κ = a + b log10 M_bary
    with simple floor / ceiling for physical behavior.
    """
    M_bary = jnp.asarray(M_bary)
    logM   = jnp.log10(M_bary)
    logk   = a + b * logM
    kappa  = 10.0**logk
    kappa  = jnp.clip(kappa, kappa_min, kappa_max)
    return kappa


# ------------------------------------------------------------
# B. CLUSTER BRANCH (Phase XI): two-population mass law
# ------------------------------------------------------------

cl_csv = "BranchC_PhaseXI_corrected.csv"
df_cl = pd.read_csv(cl_csv)

needed_cl_cols = ["cluster", "Mgas_tot", "Mgrav_tot", "b"]
for c in needed_cl_cols:
    if c not in df_cl.columns:
        raise RuntimeError(f"Cluster CSV missing column: {c}")

# Clean: positive masses
mask_cl = (df_cl["Mgas_tot"] > 0) & (df_cl["Mgrav_tot"] > 0)
dc = df_cl[mask_cl].copy()

Mgas_cl = dc["Mgas_tot"].values
Mgrav_cl = dc["Mgrav_tot"].values
b_env = dc["b"].values

dc["logMgas"] = np.log10(Mgas_cl)
dc["logMgrav"] = np.log10(Mgrav_cl)

# Split by median b (same definition as Phase XI)
b_med = np.median(b_env)
dc["is_high_b"] = dc["b"].values >= b_med

d_high = dc[dc["is_high_b"]].copy()
d_low  = dc[~dc["is_high_b"]].copy()

print("\n=== CLUSTER BRANCH DATA ===")
print(f"Total clusters (cleaned): {len(dc)}")
print(f"Median b = {b_med:.3f}")
print(f"High-b population size: {len(d_high)}")
print(f"Low-b  population size: {len(d_low)}")

def fit_log_relation(df_sub, label=""):
    x = df_sub["logMgas"].values
    y = df_sub["logMgrav"].values
    B, A = np.polyfit(x, y, 1)  # y = B x + A
    r = np.corrcoef(x, y)[0, 1]
    # naive stderr on B:
    y_pred = A + B * x
    resid = y - y_pred
    dof = len(x) - 2
    s2 = np.sum(resid**2) / dof
    x_var = np.sum((x - x.mean())**2)
    stderr_B = np.sqrt(s2 / x_var)
    print(f"{label}: log10 Mgrav = A + B log10 Mgas")
    print(f"  A = {A:.3f}, B = {B:.3f}, r = {r:.3f}, stderr(B) = {stderr_B:.3f}")
    return A, B

A_high, B_high = fit_log_relation(d_high, "High-b")
A_low,  B_low  = fit_log_relation(d_low,  "Low-b")

# JAX parameters
A_high_j = jnp.array(A_high)
B_high_j = jnp.array(B_high)
A_low_j  = jnp.array(A_low)
B_low_j  = jnp.array(B_low)
b_split_j = jnp.array(b_med)

@jax.jit
def Mtot_cluster_jax(Mgas, b,
                     A_hi=A_high_j, B_hi=B_high_j,
                     A_lo=A_low_j,  B_lo=B_low_j,
                     b_split=b_split_j):
    """
    Phase-XI cluster branch: corrected total mass.

    Inputs:
      Mgas : gas/baryon mass [Msun]
      b    : env. slope from ACCEPT fit

    Uses:
      if b >= b_split -> high-b law
      else            -> low-b law
    """
    Mgas = jnp.asarray(Mgas)
    b    = jnp.asarray(b)

    logMgas = jnp.log10(Mgas)

    logM_hi = A_hi + B_hi * logMgas
    logM_lo = A_lo + B_lo * logMgas

    M_hi = 10.0**logM_hi
    M_lo = 10.0**logM_lo

    use_hi = b >= b_split
    return jnp.where(use_hi, M_hi, M_lo)

@jax.jit
def kappa_cluster_jax(Mgas, b):
    """
    Cluster branch κ_top-like quantity:
      κ_cl ≡ 1 - Mgas / Mtot_cluster
    (fraction of mass in the extra branch vs baryons)
    """
    M_tot = Mtot_cluster_jax(Mgas, b)
    return 1.0 - Mgas / M_tot


# ------------------------------------------------------------
# C. Cosmic averages from the two branches
# ------------------------------------------------------------

# Galaxy: mass-weighted mean κ
kappa_gal_vals = kappa_galaxy_jax(M_bary_gal)
M_gal_sum = np.sum(M_bary_gal)
kappa_gal_mean_mass_weighted = float(np.sum(M_bary_gal * kappa_gal_vals) / M_gal_sum)

# Cluster: mass-weighted mean κ_cl (using Phase XI)
kappa_cl_vals = kappa_cluster_jax(Mgas_cl, b_env)
M_cl_sum = np.sum(Mgas_cl)
kappa_cl_mean_mass_weighted = float(np.sum(Mgas_cl * kappa_cl_vals) / M_cl_sum)

print("\n=== COSMIC BRANCH AVERAGES (mass-weighted) ===")
print(f"Galaxy branch <κ_top>_mass ≈ {kappa_gal_mean_mass_weighted:.3f}")
print(f"Cluster branch <κ_cl>_mass ≈ {kappa_cl_mean_mass_weighted:.3f}")

# Simple combined effective κ (you can weight by cosmic baryon budget if desired)
kappa_eff = 0.5 * (kappa_gal_mean_mass_weighted + kappa_cl_mean_mass_weighted)
print(f"\nEffective cosmic κ_eff (toy) ≈ {kappa_eff:.3f}")


# ------------------------------------------------------------
# D. Cosmology sandbox – growth factor and lensing
# ------------------------------------------------------------

# cosmological parameters (flat ΛCDM)
H0 = 70.0          # km/s/Mpc
h  = H0 / 100.0
c  = 299792.458    # km/s
Omega_m = 0.3
Omega_L = 0.7

def E_of_a(a, Omega_m=Omega_m, Omega_L=Omega_L):
    """H(a)/H0 for flat ΛCDM."""
    return np.sqrt(Omega_m / a**3 + Omega_L)

def growth_LCDM(a_array, Omega_m=Omega_m, Omega_L=Omega_L):
    """
    Linear growth factor D(a) normalized to D(1)=1.
    Uses standard integral approximation:
      D(a) ∝ H(a) ∫_0^a da' / [a'^3 H(a')^3]
    """
    a_array = np.asarray(a_array)
    # fine grid for integration
    a_grid = np.linspace(1e-3, 1.0, 2000)
    E_grid = E_of_a(a_grid, Omega_m, Omega_L)
    integrand = 1.0 / (a_grid**3 * E_grid**3)
    integral = np.cumsum(integrand) * (a_grid[1] - a_grid[0])

    # growth up to each a_grid
    D_grid = E_grid * integral
    # normalize to D(a=1)=1
    D_grid /= D_grid[-1]

    # interpolate onto requested a_array
    return np.interp(a_array, a_grid, D_grid)

def growth_IIM(a_array, kappa_eff=kappa_eff):
    """
    Toy IIM-modified growth:
      treat κ_eff as an effective rescaling of Ω_m:
        Ω_m_eff = Ω_m * (1 + κ_eff)
    and recompute the ΛCDM-like growth with Ω_m_eff.
    This is *not* a rigorous derivation; it's a sandbox.
    """
    Omega_m_eff = Omega_m * (1.0 + kappa_eff)
    Omega_L_eff = 1.0 - Omega_m_eff
    return growth_LCDM(a_array, Omega_m=Omega_m_eff, Omega_L=Omega_L_eff)

# Example growth curves
a_plot = np.linspace(0.05, 1.0, 100)
D_LCDM = growth_LCDM(a_plot)
D_IIM  = growth_IIM(a_plot)

plt.figure(figsize=(6,4))
plt.plot(a_plot, D_LCDM, label="ΛCDM")
plt.plot(a_plot, D_IIM,  label="IIM (Ω_m→Ω_m_eff)", ls="--")
plt.xlabel("a")
plt.ylabel("D(a) (normalized to 1 at a=1)")
plt.title("Toy growth factor: ΛCDM vs IIM-effective")
plt.grid(True, ls="--", alpha=0.3)
plt.legend()
plt.tight_layout()
plt.show()


# ------------------------------------------------------------
# E. Simple lensing kernel sandbox
# ------------------------------------------------------------

def comoving_distance(z, nz=1000):
    """Comoving distance χ(z) for flat ΛCDM [Mpc]."""
    z_grid = np.linspace(0.0, z, nz)
    a_grid = 1.0 / (1.0 + z_grid)
    E_grid = E_of_a(a_grid)
    chi_grid = c / H0 * np.cumsum(1.0 / E_grid) * (z_grid[1] - z_grid[0])
    return chi_grid[-1]

def ang_diam_distance(z1, z2=None):
    """
    Angular diameter distance D_A.
      If z2 is None: D_A(0,z1)
      Else: D_A(z1,z2) for z2>z1
    """
    if z2 is None:
        chi = comoving_distance(z1)
        return chi / (1.0 + z1)
    else:
        if z2 <= z1:
            return 0.0
        chi1 = comoving_distance(z1)
        chi2 = comoving_distance(z2)
        return (chi2 - chi1) / (1.0 + z2)

def lens_Einstein_radius_SIS(M_tot, z_l, z_s, R_scale_kpc=200.0):
    """
    Very rough lensing sandbox:
      - treat lens as an effective SIS whose velocity dispersion
        is estimated from M_tot within a scale radius R_scale.
      - Returns θ_E in arcseconds.

    This is *only* to see the *relative* effect of changing M_tot
    between ΛCDM-like and IIM-like branches.
    """
    # Mass within R_scale used only to set sigma_v
    G_SI = 6.67430e-11          # m^3 kg^-1 s^-2
    Msun_SI = 1.98847e30        # kg
    kpc_m = 3.085677581e19      # m

    M_SI = M_tot * Msun_SI
    R_m  = R_scale_kpc * kpc_m

    # circular velocity
    v_c2 = G_SI * M_SI / R_m
    sigma_v2 = 0.5 * v_c2

    # distances
    D_l  = ang_diam_distance(z_l) * 1e6 * kpc_m    # Mpc->m
    D_s  = ang_diam_distance(z_s) * 1e6 * kpc_m
    D_ls = ang_diam_distance(z_l, z_s) * 1e6 * kpc_m

    if D_l <= 0 or D_s <= 0 or D_ls <= 0:
        return 0.0

    theta_E_rad = 4.0 * np.pi * sigma_v2 / c**2 * D_ls / D_s
    theta_E_arcsec = theta_E_rad * (180.0/np.pi) * 3600.0
    return theta_E_arcsec

def effective_lens_mass_IIM(M_bary, branch="galaxy", b=None):
    """
    Given a baryonic mass M_bary and choice of branch:
      - 'galaxy': use kappa_galaxy_jax
      - 'cluster': use kappa_cluster_jax (needs b)
    returns an effective total mass M_tot.
    """
    if branch == "galaxy":
        k = float(kappa_galaxy_jax(M_bary))
        return M_bary / (1.0 - k)
    elif branch == "cluster":
        if b is None:
            raise ValueError("Cluster branch needs b")
        M_tot = float(Mtot_cluster_jax(M_bary, b))
        return M_tot
    else:
        raise ValueError("branch must be 'galaxy' or 'cluster'")

# Example: compare Einstein radius for a typical cluster using
# gas mass vs IIM effective mass.
example_idx = np.argmax(Mgas_cl)  # most massive in gas
Mgas_example = Mgas_cl[example_idx]
b_example    = b_env[example_idx]

z_l_example = 0.3
z_s_example = 1.0

M_LCDM_like = Mgas_example / (1.0 - kappa_eff)  # toy "DM fraction" using κ_eff
M_IIM       = effective_lens_mass_IIM(Mgas_example, branch="cluster", b=b_example)

theta_LCDM = lens_Einstein_radius_SIS(M_LCDM_like, z_l_example, z_s_example)
theta_IIM  = lens_Einstein_radius_SIS(M_IIM,        z_l_example, z_s_example)

print("\n=== LENSING SANDBOX EXAMPLE ===")
print(f"Example cluster gas mass: Mgas ≈ {Mgas_example:.3e} Msun")
print(f"Env slope b ≈ {b_example:.3f}")
print(f"Toy ΛCDM-like total mass (using κ_eff): M_tot ≈ {M_LCDM_like:.3e} Msun")
print(f"IIM Branch-XI total mass (cluster branch): M_tot ≈ {M_IIM:.3e} Msun")
print(f"Einstein radius (toy SIS):")
print(f"  θ_E_LCDM ≈ {theta_LCDM:.3f} arcsec")
print(f"  θ_E_IIM  ≈ {theta_IIM:.3f} arcsec")

print("\nREADY:")
print("  - kappa_galaxy_jax(M_bary) for galaxy halos")
print("  - Mtot_cluster_jax(Mgas, b), kappa_cluster_jax(Mgas, b) for clusters")
print("  - growth_LCDM(a) and growth_IIM(a) for toy large-scale structure tests")
print("  - lens_Einstein_radius_SIS + effective_lens_mass_IIM for lensing sandbox")

import numpy as np
import pandas as pd
import math
from scipy import stats

# =========================
# 1. Load data
# =========================

gal_file = "IIM_SPARC_full_results.csv"
cl_file  = "BranchC_multi_cluster_results.csv"

gal = pd.read_csv(gal_file)
cl  = pd.read_csv(cl_file)

print("GALAXIES:", len(gal), "rows")
print("CLUSTERS:", len(cl), "rows")

# =========================
# 2. Galaxy branch (Phase VIII-like)
# =========================
# Columns: 'M_bary_R' (baryon mass), 'f_X' (halo fraction), 'chi2_red'

M_bary = gal["M_bary_R"].values
f_X    = gal["f_X"].values
chi2r  = gal["chi2_red"].values

mask_base = (
    np.isfinite(M_bary) &
    np.isfinite(f_X) &
    np.isfinite(chi2r) &
    (M_bary > 0) &
    (f_X > 0) & (f_X < 1) &
    (chi2r > 0) & (chi2r < 10.0)  # chi2_red cut
)

M_b_clean = M_bary[mask_base]
kappa_clean = f_X[mask_base]

print("\nGalaxy clean sample N =", len(M_b_clean))
print("f_X stats (clean): min={:.3e}, max={:.3f}, median={:.3f}, mean={:.3f}".format(
    kappa_clean.min(), kappa_clean.max(),
    np.median(kappa_clean), np.mean(kappa_clean))
)

# Optional: remove very tiny kappa for the log fit (log10 κ > -4)
logM  = np.log10(M_b_clean)
logk  = np.log10(kappa_clean)
mask_log = (logk > -4)

logM_fit = logM[mask_log]
logk_fit = logk[mask_log]

slope_g, intercept_g, r_g, p_g, stderr_g = stats.linregress(logM_fit, logk_fit)

print("\n=== Galaxy Branch Fit (Phase VIII-like) ===")
print("Fit: log10 kappa_gal = a_g + b_g log10(M_bary)")
print("a_g = {:.3f}, b_g = {:.3f}, r = {:.3f}, stderr(b_g) = {:.3f}".format(
    intercept_g, slope_g, r_g, stderr_g
))

# Galaxy helper functions
def log10_kappa_galaxy(M_bary_in):
    """Compute log10 κ_gal from baryon mass in Msun."""
    M_bary_in = np.asarray(M_bary_in)
    return intercept_g + slope_g * np.log10(M_bary_in)

def kappa_galaxy(M_bary_in):
    """Compute κ_gal from baryon mass in Msun."""
    return 10.0 ** log10_kappa_galaxy(M_bary_in)

# Mass-weighted <kappa>
mass_weighted_kappa = np.sum(kappa_clean * M_b_clean) / np.sum(M_b_clean)
print("Mass-weighted <kappa_gal> ≈ {:.4f}".format(mass_weighted_kappa))

# =========================
# 3. Cluster branch (Phase XI-like)
# =========================
# Columns: 'Mgas_tot', 'Mgrav_tot', 'b' (slope from F_env fit)

# Clean: require positive total gas and grav mass
cl_clean = cl[(cl["Mgas_tot"] > 0) & (cl["Mgrav_tot"] > 0)].copy().reset_index(drop=True)

print("\nCluster clean sample N =", len(cl_clean))

b_med = cl_clean["b"].median()
cl_clean["is_high_b"] = cl_clean["b"] > b_med

def fit_cluster_pop(df):
    logMgas = np.log10(df["Mgas_tot"].values)
    logMgrav = np.log10(df["Mgrav_tot"].values)
    slope, intercept, r, p, stderr = stats.linregress(logMgas, logMgrav)
    return intercept, slope, r, p, stderr

high = cl_clean[cl_clean["is_high_b"]]
low  = cl_clean[~cl_clean["is_high_b"]]

A_high, B_high, r_high, p_high, seB_high = fit_cluster_pop(high)
A_low,  B_low,  r_low,  p_low,  seB_low  = fit_cluster_pop(low)

print("\n=== Cluster Branch Fits (Phase XI-like) ===")
print("Median b =", b_med)
print("High-b population: N =", len(high))
print("  log10 Mgrav = A_high + B_high log10 Mgas")
print("  A_high = {:.3f}, B_high = {:.3f}, r = {:.3f}, stderr(B_high) = {:.3f}".format(
    A_high, B_high, r_high, seB_high
))
print("Low-b population: N =", len(low))
print("  log10 Mgrav = A_low + B_low log10 Mgas")
print("  A_low  = {:.3f}, B_low  = {:.3f}, r = {:.3f}, stderr(B_low)  = {:.3f}".format(
    A_low, B_low, r_low, seB_low
))

def log10_Mgrav_cluster(Mgas, b):
    """
    Piecewise cluster mass law: choose high/low-b regression
    using the median b from the ACCEPT sample.
    """
    Mgas = np.asarray(Mgas)
    b_arr = np.asarray(b)

    # Broadcast
    Mgas_flat = Mgas.flatten()
    b_flat = b_arr.flatten()

    logMgas = np.log10(Mgas_flat)
    out = np.empty_like(logMgas, dtype=float)

    high_mask = (b_flat > b_med)
    low_mask  = ~high_mask

    out[high_mask] = A_high + B_high * logMgas[high_mask]
    out[low_mask]  = A_low  + B_low  * logMgas[low_mask]

    return out.reshape(Mgas.shape)

def Mgrav_cluster(Mgas, b):
    """Total gravitating mass from the Phase XI cluster branch fit."""
    return 10.0 ** log10_Mgrav_cluster(Mgas, b)

# For diagnostics: predicted vs original
pred_M = Mgrav_cluster(cl_clean["Mgas_tot"].values, cl_clean["b"].values)
cl_clean["Mtot_phaseXI"] = pred_M
cl_clean["ratio_phaseXI"] = cl_clean["Mtot_phaseXI"] / cl_clean["Mgrav_tot"]

print("\nCluster Phase XI ratio stats: Mtot_phaseXI / Mgrav_tot:")
print(cl_clean["ratio_phaseXI"].describe())

# =========================
# 4. Simple “cosmic” bookkeeping (but NOT a global κ_eff)
# =========================

# Galaxy totals
M_b_total_gal = np.sum(M_b_clean)
M_X_total_gal = np.sum(kappa_clean * M_b_clean / (1.0 - kappa_clean))  # M_X = κ/(1-κ) * M_b
f_X_gal = M_X_total_gal / (M_X_total_gal + M_b_total_gal)

print("\n=== Cosmic bookkeeping (toy, not a real Ω_m) ===")
print("Total galaxy baryon mass   (clean sample) ≈ {:.3e} Msun".format(M_b_total_gal))
print("Total galaxy extra mass M_X               ≈ {:.3e} Msun".format(M_X_total_gal))
print("Sample-averaged galaxy f_X (mass-weighted)≈ {:.4f}".format(f_X_gal))

# Cluster sample crude stats (using measured Mgrav_tot, not physically robust)
M_gas_total_cl = np.sum(cl_clean["Mgas_tot"].values)
M_grav_total_cl = np.sum(cl_clean["Mgrav_tot"].values)

print("\nTotal cluster gas mass  (sample) ≈ {:.3e} Msun".format(M_gas_total_cl))
print("Total cluster grav mass (sample) ≈ {:.3e} Msun".format(M_grav_total_cl))

# =========================
# 5. Save unified summary CSV
# =========================

summary_rows = []

summary_rows.append({
    "branch": "galaxy_fit",
    "a_g": intercept_g,
    "b_g": slope_g,
    "r_g": r_g,
    "stderr_b_g": stderr_g,
    "mass_weighted_kappa_gal": mass_weighted_kappa,
    "total_M_bary_gal": M_b_total_gal,
    "total_M_X_gal": M_X_total_gal,
    "f_X_gal_massweighted": f_X_gal
})

summary_rows.append({
    "branch": "cluster_fit_high_b",
    "A": A_high,
    "B": B_high,
    "r": r_high,
    "stderr_B": seB_high,
    "N_clusters": len(high),
    "b_median": b_med
})

summary_rows.append({
    "branch": "cluster_fit_low_b",
    "A": A_low,
    "B": B_low,
    "r": r_low,
    "stderr_B": seB_low,
    "N_clusters": len(low),
    "b_median": b_med
})

summary_rows.append({
    "branch": "cluster_totals",
    "total_M_gas_cl": M_gas_total_cl,
    "total_M_grav_cl": M_grav_total_cl
})

summary_df = pd.DataFrame(summary_rows)
out_name = "PhaseXII_unified_results.csv"
summary_df.to_csv(out_name, index=False)
print("\nSaved unified summary to:", out_name)

print("\nREADY: functions available in this session:")
print("  kappa_galaxy(M_bary)")
print("  Mgrav_cluster(Mgas, b)")

# ============================================
#   IIM vs DATA — CLEAN SUMMARY CONFRONTATION
#   (One-cell Colab script)
# ============================================
import numpy as np
import scipy.integrate as si

# --------------------------------------------
# 1. IIM cosmological parameters (EDIT THESE)
# --------------------------------------------
params = {
    "H0":    70.0,   # km/s/Mpc
    "Om_b":  0.05,
    "Om_Xm": 0.25,   # X-matter (DM-like)
    "Om_XL": 0.70,   # X-Lambda (DE-like)
    "w_m":   0.0,    # X-fluid EOS (0 ~ CDM)
    "k_IIM": 0.7,    # suppression scale (h/Mpc)
    "alpha": 2.0,    # suppression exponent
    "beta":  0.6     # suppression exponent
}

h = params["H0"]/100.0
Om_tot = params["Om_b"] + params["Om_Xm"]

# --------------------------------------------
# 2. Background functions
# --------------------------------------------
def E(z):
    # Flat FRW: Om_tot a^-3 + OL
    OL = params["Om_XL"]
    return np.sqrt( Om_tot*(1+z)**3 + OL )

def H(z):
    return params["H0"] * E(z)

def r(z):
    # Comoving distance [Mpc]
    return si.quad(lambda zp: 299792.458/H(zp), 0, z)[0]

def DA(z):
    return r(z)/(1+z)

def DL(z):
    return (1+z)*r(z)

# --------------------------------------------
# 3. IIM small-scale suppression and S8
# --------------------------------------------
def S_k(k):
    # IIM suppression
    return (1 + (k/params["k_IIM"])**params["alpha"])**(-params["beta"])

sigma8_LCDM = 0.83

# Use k ~ 0.2 h/Mpc as effective σ8 scale
k_eff = 0.2
sigma8_IIM = sigma8_LCDM * S_k(k_eff)

# Correct S8 definition: S8 = σ8 * (Ωm/0.3)^0.5
S8_IIM = sigma8_IIM * np.sqrt(Om_tot/0.3)

# --------------------------------------------
# 4. Summary-level observational constraints
# --------------------------------------------

# 4.1 Planck-like background constraints
#     Ω_m = 0.315 ± 0.007, h = 0.674 ± 0.005 (Planck 2018 ΛCDM)
Om_planck = 0.315
Om_planck_err = 0.007
h_planck  = 0.674
h_planck_err = 0.005

chi2_planck = ((Om_tot - Om_planck)/Om_planck_err)**2 + ((h - h_planck)/h_planck_err)**2

# 4.2 BOSS BAO-like distance constraint (very rough)
#     Use DM(z) at 3 redshifts with approximate values & errors
z_boss   = np.array([0.38, 0.51, 0.61])
DM_data  = np.array([1512.0, 1975.0, 2307.0])  # Mpc (Planck-like best fit)
DM_err   = np.array([20.,    28.,    33.   ])  # rough

DM_model = np.array([r(z) for z in z_boss])
chi2_boss = np.sum(((DM_model - DM_data)/DM_err)**2)

# 4.3 Pantheon-like SN constraint (binned + marginalized absolute magnitude)
#     Simple 7-bin compressed (z, mu, sigma) data
pantheon_data = np.array([
    [0.05,  36.34, 0.12],
    [0.15,  38.25, 0.09],
    [0.25,  39.35, 0.08],
    [0.35,  40.25, 0.09],
    [0.45,  41.05, 0.12],
    [0.55,  41.55, 0.14],
    [0.65,  42.05, 0.15]
])

z_sn   = pantheon_data[:,0]
mu_obs = pantheon_data[:,1]
mu_err = pantheon_data[:,2]

def mu_th(z):
    # distance modulus (DL in Mpc)
    return 5.0*np.log10(DL(z)*1e6/10.0)

mu_model = np.array([mu_th(z) for z in z_sn])

# Marginalize over absolute magnitude (additive offset)
w = 1.0/mu_err**2
Delta = mu_obs - mu_model
M_best = np.sum(w*Delta)/np.sum(w)
chi2_sn = np.sum(w * (Delta - M_best)**2)

# 4.4 S8 constraint (DES-like)
S8_data = 0.776
S8_err  = 0.017
chi2_S8 = (S8_IIM - S8_data)**2 / S8_err**2

# --------------------------------------------
# 5. Print results
# --------------------------------------------
print("===== IIM vs Data: Summary Likelihoods =====")
print("IIM params:", params, "\n")

print("Background:")
print(f"  Ω_m (IIM) = {Om_tot:.3f} vs Planck 0.315±0.007")
print(f"  h   (IIM) = {h:.3f} vs Planck 0.674±0.005\n")

print("Derived clustering:")
print(f"  σ8_LCDM  ≈ {sigma8_LCDM:.3f}")
print(f"  σ8_IIM   ≈ {sigma8_IIM:.3f}")
print(f"  S8_IIM   ≈ {S8_IIM:.3f} (DES 0.776±0.017)\n")

print("χ² contributions (approximate Gaussian priors / summaries):")
print(f"  χ²_Planck_bg ≈ {chi2_planck:.2f}")
print(f"  χ²_BOSS      ≈ {chi2_boss:.2f}")
print(f"  χ²_SN        ≈ {chi2_sn:.2f}")
print(f"  χ²_S8        ≈ {chi2_S8:.2f}")
print("-------------------------------------------")
chi2_tot = chi2_planck + chi2_boss + chi2_sn + chi2_S8
print(f"  χ²_total (summary) ≈ {chi2_tot:.2f}")
print("===========================================")

# ============================================
#  IIM PARAMETER MINI-SCAN (one cell)
#  - Scans H0, Om_Xm, k_IIM
#  - Uses same summary likelihood as before
# ============================================
import numpy as np
import scipy.integrate as si

# ---------- fixed pieces ----------
Om_b_fixed = 0.049   # close to Planck
Om_XL_fixed = 1.0 - 0.049 - 0.266  # flatness with Om_Xm ~ 0.266 initially (will be updated below)

# Summary likelihood functions reused
def E(z, Om_m, Om_XL):
    return np.sqrt(Om_m*(1+z)**3 + Om_XL)

def H(z, H0, Om_m, Om_XL):
    return H0 * E(z, Om_m, Om_XL)

def r(z, H0, Om_m, Om_XL):
    return si.quad(lambda zp: 299792.458/H(zp, H0, Om_m, Om_XL), 0, z)[0]

def DA(z, H0, Om_m, Om_XL):
    return r(z, H0, Om_m, Om_XL)/(1+z)

def DL(z, H0, Om_m, Om_XL):
    return (1+z)*r(z, H0, Om_m, Om_XL)

def S_k(k, k_IIM, alpha, beta):
    return (1 + (k/k_IIM)**alpha)**(-beta)

sigma8_LCDM = 0.83
k_eff = 0.2

# Pantheon compressed bins
pantheon_data = np.array([
    [0.05,  36.34, 0.12],
    [0.15,  38.25, 0.09],
    [0.25,  39.35, 0.08],
    [0.35,  40.25, 0.09],
    [0.45,  41.05, 0.12],
    [0.55,  41.55, 0.14],
    [0.65,  42.05, 0.15]
])
z_sn   = pantheon_data[:,0]
mu_obs = pantheon_data[:,1]
mu_err = pantheon_data[:,2]

# DES-like S8
S8_data = 0.776
S8_err  = 0.017

# Planck summary
Om_planck = 0.315
Om_planck_err = 0.007
h_planck  = 0.674
h_planck_err = 0.005

# BOSS distances
z_boss  = np.array([0.38, 0.51, 0.61])
DM_data = np.array([1512.0, 1975.0, 2307.0])
DM_err  = np.array([20.,    28.,    33.   ])

def chi2_summary(H0, Om_b, Om_Xm, Om_XL, k_IIM, alpha=2.0, beta=0.6):
    h = H0/100.
    Om_m = Om_b + Om_Xm

    # Planck background
    chi2_planck = ((Om_m - Om_planck)/Om_planck_err)**2 + ((h - h_planck)/h_planck_err)**2

    # BOSS
    DM_model = np.array([r(z, H0, Om_m, Om_XL) for z in z_boss])
    chi2_boss = np.sum(((DM_model - DM_data)/DM_err)**2)

    # SN (marginalize absolute magnitude)
    mu_model = np.array([5*np.log10(DL(z, H0, Om_m, Om_XL)*1e6/10.0) for z in z_sn])
    w = 1.0/mu_err**2
    Delta = mu_obs - mu_model
    M_best = np.sum(w*Delta)/np.sum(w)
    chi2_sn = np.sum(w*(Delta - M_best)**2)

    # S8
    sigma8_IIM = sigma8_LCDM * S_k(k_eff, k_IIM, alpha, beta)
    S8_IIM = sigma8_IIM * np.sqrt(Om_m/0.3)
    chi2_S8 = (S8_IIM - S8_data)**2 / S8_err**2

    return chi2_planck, chi2_boss, chi2_sn, chi2_S8, S8_IIM

# ---------- parameter grid ----------
H0_vals    = np.linspace(66.5, 70.0, 8)   # try near Planck up to your 70
Om_Xm_vals = np.linspace(0.24, 0.28, 9)   # around 0.26
k_IIM_vals = np.linspace(0.4, 1.0, 7)     # suppression scale

results = []

for H0 in H0_vals:
    for Om_Xm in Om_Xm_vals:
        Om_b = Om_b_fixed
        Om_m = Om_b + Om_Xm
        Om_XL = 1.0 - Om_m  # flat
        for k_IIM in k_IIM_vals:
            chi2_P, chi2_B, chi2_SN, chi2_S8, S8_IIM = chi2_summary(
                H0, Om_b, Om_Xm, Om_XL, k_IIM, alpha=2.0, beta=0.6
            )
            chi2_tot = chi2_P + chi2_B + chi2_SN + chi2_S8
            results.append((chi2_tot, chi2_P, chi2_B, chi2_SN, chi2_S8,
                            H0, Om_b, Om_Xm, Om_XL, k_IIM, S8_IIM))

# sort by total chi2
results_sorted = sorted(results, key=lambda x: x[0])

print("Top 10 parameter sets by lowest χ²_total:\n")
for i in range(10):
    (chi2_tot, chi2_P, chi2_B, chi2_SN, chi2_S8,
     H0, Om_b, Om_Xm, Om_XL, k_IIM, S8_IIM) = results_sorted[i]
    print(f"#{i+1}: χ²_tot={chi2_tot:.2f} (P={chi2_P:.1f}, B={chi2_B:.1f}, SN={chi2_SN:.1f}, S8={chi2_S8:.1f})")
    print(f"     H0={H0:.2f}, Ω_b={Om_b:.3f}, Ω_Xm={Om_Xm:.3f}, Ω_XL={Om_XL:.3f}, k_IIM={k_IIM:.2f}, S8_IIM={S8_IIM:.3f}")
    print()

# ============================================
#  IIMBoltzmann: Minimal IIM "Boltzmann" Module
#  - Background H(a), E(a)
#  - Scale-dependent growth δ(a,k) with S(k)
#  - Linear matter power P(k,z)
# ============================================
import numpy as np
from dataclasses import dataclass
from typing import Dict, Tuple
from scipy.integrate import solve_ivp

# -------------------------
# 1. Parameter dataclass
# -------------------------
@dataclass
class IIMParams:
    H0: float = 67.5        # Hubble [km/s/Mpc]
    Om_b: float = 0.049     # baryon fraction today
    Om_Xm: float = 0.265    # X-matter fraction today
    Om_XL: float = 0.686    # X-Lambda fraction (flat: Om_b+Om_Xm+Om_XL=1)
    w_m: float = 0.0        # X-fluid EOS (0 ~ CDM)
    k_IIM: float = 0.5      # suppression scale [h/Mpc]
    alpha: float = 2.0      # suppression exponent
    beta: float = 0.6       # suppression exponent
    n_s: float = 0.965      # primordial tilt
    sigma8_LCDM: float = 0.83  # reference σ8 for LCDM


# -------------------------
# 2. IIMBoltzmann class
# -------------------------
class IIMBoltzmann:
    """
    Minimal linear growth + P(k) engine for the Irreducible Intent Model.

    - No graviton DOF.
    - Growth equation: δ'' + (3/a + H'/H) δ' - (3/2) Ω_m(a)/a^2 S(k) δ = 0
    - S(k) encodes instanton / X-sector suppression.
    """

    def __init__(self, params: IIMParams):
        self.p = params
        self.h = self.p.H0 / 100.0
        self.Om_m0 = self.p.Om_b + self.p.Om_Xm

    # ---------- background ----------
    def E(self, a: float) -> float:
        """Dimensionless E(a) = H(a)/H0 for flat matter+Λ (no rad for now)."""
        Om = self.Om_m0
        OL = self.p.Om_XL
        return np.sqrt(Om * a**(-3 * (1 + self.p.w_m)) + OL)

    def H(self, a: float) -> float:
        """H(a) in km/s/Mpc."""
        return self.p.H0 * self.E(a)

    def Omega_m_a(self, a: float) -> float:
        """Ω_m(a) = ρ_m(a)/ρ_crit(a)."""
        return self.Om_m0 * a**(-3 * (1 + self.p.w_m)) / self.E(a)**2

    # ---------- suppression ----------
    def S_k(self, k: float) -> float:
        """
        IIM suppression factor S(k).
        k in [h/Mpc]. For k << k_IIM -> S(k) ~ 1.
        For k >> k_IIM -> S(k) ~ (k/k_IIM)^(-alpha*beta).
        """
        return (1.0 + (k / self.p.k_IIM)**self.p.alpha)**(-self.p.beta)

    # ---------- growth ODE (in a) ----------
    def _growth_ode(self, a: float, y: np.ndarray, k: float) -> np.ndarray:
        """
        ODE: y[0] = δ, y[1] = dδ/da
        δ'' + (3/a + H'/H) δ' - (3/2) Ω_m(a)/a^2 S(k) δ = 0
        """
        δ, dδda = y
        # finite difference for H'/H wrt a
        da = 1e-4 * a
        Hp = self.H(a + da)
        Hm = self.H(a - da)
        dHda = (Hp - Hm) / (2 * da)
        H_val = self.H(a)
        A = (3.0 / a) + dHda / H_val
        B = -1.5 * self.Omega_m_a(a) * self.S_k(k) / (a**2)
        d2δda2 = -A * dδda - B * δ
        return np.array([dδda, d2δda2])

    def solve_growth(self,
                     k: float,
                     a_min: float = 1e-3,
                     a_max: float = 1.0,
                     n_steps: int = 400) -> Tuple[np.ndarray, np.ndarray]:
        """
        Solve δ(a,k) with IIM suppression from a_min to a_max.
        Return (a_array, D_array) with D(a=1,k)=1 normalized.
        """
        a_span = (a_min, a_max)
        a_eval = np.linspace(a_min, a_max, n_steps)

        # Initial conditions:
        # in matter domination δ ~ a ⇒ dδ/da ≈ 1 at small a.
        y0 = np.array([a_min, 1.0])

        sol = solve_ivp(lambda a, y: self._growth_ode(a, y, k),
                        a_span, y0, t_eval=a_eval, rtol=1e-6, atol=1e-9)

        δ = sol.y[0]
        # Normalize D(a,k) so that D(1,k) = 1
        D = δ / δ[-1]
        return a_eval, D

    # ---------- P(k,z) ----------
    def transfer_D_kz(self,
                      k: float,
                      z: float,
                      a_min: float = 1e-3) -> float:
        """
        Return D(k,z) normalized to D(k,z=0)=1.
        """
        a = 1.0 / (1.0 + z)
        a_arr, D_arr = self.solve_growth(k, a_min=a_min, a_max=1.0)
        # interpolation
        return np.interp(a, a_arr, D_arr)

    def P_lin(self,
              k: np.ndarray,
              z: float = 0.0,
              A_s: float = 2.1e-9) -> np.ndarray:
        """
        Very simple linear matter power spectrum:
            P(k,z) ∝ k^{n_s} D^2(k,z)
        This is *not* a full transfer function; it's the IIM growth imprint.
        """
        k = np.asarray(k)
        Dk = np.array([self.transfer_D_kz(ki, z) for ki in k])
        return A_s * k**self.p.n_s * Dk**2

    # ---------- σ8, S8 diagnostics ----------
    def sigma8_ratio(self, k_eff: float = 0.2) -> float:
        """
        Rough σ8_IIM / σ8_LCDM ratio using S_k at a representative scale k_eff.
        """
        return self.S_k(k_eff)

    def S8_IIM(self, k_eff: float = 0.2) -> float:
        σ8_IIM = self.p.sigma8_LCDM * self.sigma8_ratio(k_eff)
        return σ8_IIM * np.sqrt(self.Om_m0 / 0.3)


# ============================================
# 3. Example usage / diagnostics
# ============================================
if __name__ == "__main__":
    # Best-fit-like parameters from your grid scan
    p = IIMParams(
        H0=67.5,
        Om_b=0.049,
        Om_Xm=0.265,
        Om_XL=0.686,
        w_m=0.0,
        k_IIM=0.5,
        alpha=2.0,
        beta=0.6,
        n_s=0.965,
        sigma8_LCDM=0.83
    )

    iim = IIMBoltzmann(p)

    # Example: compute growth for a few k's at z=0
    ks = np.logspace(-3, 1, 20)  # h/Mpc
    a, Dk_small = iim.solve_growth(ks[0])
    a, Dk_mid   = iim.solve_growth(0.2)
    a, Dk_large = iim.solve_growth(1.0)

    print("Example growth values:")
    print(f"  D(a=1, k=0.001) = {Dk_small[-1]:.3f} (by definition ≈1.0)")
    print(f"  D(a=1, k=0.2)   = {Dk_mid[-1]:.3f}")
    print(f"  D(a=1, k=1.0)   = {Dk_large[-1]:.3f}")

    # σ8 and S8 diagnostics
    S8 = iim.S8_IIM(k_eff=0.2)
    print("\nS8 diagnostics:")
    print(f"  σ8_LCDM ≈ {p.sigma8_LCDM}")
    print(f"  S8_IIM  ≈ {S8:.3f} (DES ~ 0.776 ± 0.017)")

    # Optional: compute a toy P(k,z=0)
    k_grid = np.logspace(-3, 1, 50)
    Pk = iim.P_lin(k_grid, z=0.0)
    print("\nSample P(k) values at z=0:")
    for ki, Pi in zip(k_grid[::10], Pk[::10]):
        print(f"  k = {ki:.3e} h/Mpc,  P ~ {Pi:.3e}")
